{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a19dee-1441-4cbd-8c20-75b4ba6cd2db",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edb5cda-e19a-488b-911c-7f2070960879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected db /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/db/nflpa.duckdb\n",
      "base table step16_modeling_frame_nolookahead\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, HessianInversionWarning\n",
    "\n",
    "try:\n",
    "    import statsmodels.genmod.generalized_linear_model as glm\n",
    "    glm.SET_USE_BIC_LLF(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"The bic value is computed using the deviance formula.*\",\n",
    ")\n",
    "\n",
    "CWD = Path().resolve()\n",
    "\n",
    "REPO_ROOT = None\n",
    "DB_FILE = None\n",
    "\n",
    "for p in [CWD] + list(CWD.parents):\n",
    "    cand = p / \"db\" / \"nflpa.duckdb\"\n",
    "    if cand.exists():\n",
    "        REPO_ROOT = p\n",
    "        DB_FILE = cand\n",
    "        break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    for p in [CWD] + list(CWD.parents):\n",
    "        cand = p / \"nflpa.duckdb\"\n",
    "        if cand.exists():\n",
    "            REPO_ROOT = p\n",
    "            DB_FILE = cand\n",
    "            break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    raise RuntimeError(\"Could not find nflpa.duckdb, expected db or notebook parent folders to contain it\")\n",
    "\n",
    "con = duckdb.connect(str(DB_FILE), read_only=False)\n",
    "\n",
    "BASE_TABLE = \"step16_modeling_frame_nolookahead\"\n",
    "\n",
    "exists_df = con.execute(f\"\"\"\n",
    "SELECT COUNT(*) AS n\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name = '{BASE_TABLE}'\n",
    "  AND table_type IN ('BASE TABLE', 'VIEW')\n",
    "\"\"\").df()\n",
    "\n",
    "if int(exists_df[\"n\"].iloc[0]) == 0:\n",
    "    raise RuntimeError(f\"Missing {BASE_TABLE}, run notebook 16 first\")\n",
    "\n",
    "print(\"connected db\", str(DB_FILE))\n",
    "print(\"base table\", BASE_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb9d01-6b3e-4cc2-8dad-3b3bfb5dc617",
   "metadata": {},
   "source": [
    "We build a modeling table that adds rolling volatility and prior season to date volatility and prior cumulative shock, and construct 'ScoreLinked' and 'All' diagnostics without changing the main 'NonScore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21882fb2-3558-4226-902b-c9dbbc3c7478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote duckdb table step18_model_frame\n",
      "rows 5950\n"
     ]
    }
   ],
   "source": [
    "df = con.execute(f\"SELECT * FROM {BASE_TABLE}\").df()\n",
    "\n",
    "desc = con.execute(f\"DESCRIBE {BASE_TABLE}\").df()\n",
    "cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "def pick_col(candidates: list[str], available: set[str], label: str) -> str:\n",
    "    for c in candidates:\n",
    "        if c in available:\n",
    "            return c\n",
    "    raise RuntimeError(f\"Missing {label}, add its exact name into candidates, available columns include {sorted(list(available))[:40]}\")\n",
    "\n",
    "TEAM_COL = pick_col([\"team\", \"team_key\"], cols, \"team id column\")\n",
    "SEASON_COL = pick_col([\"season\"], cols, \"season column\")\n",
    "WEEK_COL = pick_col([\"week\"], cols, \"week column\")\n",
    "\n",
    "if \"season_week\" not in df.columns:\n",
    "    df[\"season_week\"] = (df[SEASON_COL].astype(int) * 100 + df[WEEK_COL].astype(int)).astype(int)\n",
    "\n",
    "if \"load_nonscore\" not in df.columns:\n",
    "    load_candidates = [\"ST_Load_NonScore_w\", \"ST_Load_NonScore\", \"ST_Load_NonScore_w\"]\n",
    "    load_col = pick_col(load_candidates, cols, \"NonScore load column for volatility construction\")\n",
    "    df[\"load_nonscore\"] = df[load_col].astype(float)\n",
    "\n",
    "if \"shock_nonscore\" not in df.columns:\n",
    "    shock_candidates = [\"ST_Shock_NonScore_w\", \"shock_nonscore\"]\n",
    "    shock_col = pick_col(shock_candidates, cols, \"NonScore shock column\")\n",
    "    df[\"shock_nonscore\"] = df[shock_col].fillna(0).astype(int)\n",
    "\n",
    "if \"blowout_flag_w\" not in df.columns:\n",
    "    raise RuntimeError(\"Missing blowout_flag_w in the step16 frame, rerun notebook 10 and 11 then rebuild step16\")\n",
    "\n",
    "df = df.sort_values([TEAM_COL, SEASON_COL, WEEK_COL]).reset_index(drop=True)\n",
    "g = df.groupby([TEAM_COL, SEASON_COL], sort=False)\n",
    "\n",
    "df[\"cum_shocks_nonscore_prior\"] = g[\"shock_nonscore\"].cumsum().shift(1).fillna(0).astype(int)\n",
    "\n",
    "df[\"vol_nonscore_s2d_prior\"] = (\n",
    "    g[\"load_nonscore\"]\n",
    "    .apply(lambda s: s.expanding().std(ddof=1).shift(1))\n",
    "    .reset_index(level=[0, 1], drop=True)\n",
    "    .fillna(0.0)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"vol_nonscore_roll4_prior\"] = (\n",
    "    g[\"load_nonscore\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(4, min_periods=2).std(ddof=1))\n",
    "    .reset_index(level=[0, 1], drop=True)\n",
    "    .fillna(df[\"vol_nonscore_s2d_prior\"])\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "for k in [1, 2, 3]:\n",
    "    col = f\"ST_Shock_NonScore_w_minus_{k}\"\n",
    "    if col not in df.columns:\n",
    "        df[col] = g[\"shock_nonscore\"].shift(k).fillna(0).astype(int)\n",
    "\n",
    "if \"shock_x_blowout\" not in df.columns:\n",
    "    df[\"shock_x_blowout\"] = (df[\"shock_nonscore\"] * df[\"blowout_flag_w\"].fillna(0).astype(int)).astype(int)\n",
    "\n",
    "MODEL_VIEW = \"team_week_panel_nextweek_model\"\n",
    "mv_exists = con.execute(f\"\"\"\n",
    "SELECT COUNT(*) AS n\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name = '{MODEL_VIEW}'\n",
    "  AND table_type IN ('BASE TABLE', 'VIEW')\n",
    "\"\"\").df()\n",
    "if int(mv_exists[\"n\"].iloc[0]) == 0:\n",
    "    raise RuntimeError(f\"Missing {MODEL_VIEW}, run notebook 11 to recreate it\")\n",
    "\n",
    "mv_desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "mv_cols = set(mv_desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "scorelinked_col = None\n",
    "all_col = None\n",
    "if \"ST_Load_ScoreLinked_w\" in cols:\n",
    "    scorelinked_col = \"ST_Load_ScoreLinked_w\"\n",
    "if \"ST_Load_All_w\" in cols:\n",
    "    all_col = \"ST_Load_All_w\"\n",
    "\n",
    "need_join = (scorelinked_col is None) or (all_col is None)\n",
    "if need_join:\n",
    "    if \"ST_Load_ScoreLinked_w\" in mv_cols:\n",
    "        scorelinked_col = \"ST_Load_ScoreLinked_w\"\n",
    "    if \"ST_Load_All_w\" in mv_cols:\n",
    "        all_col = \"ST_Load_All_w\"\n",
    "\n",
    "if scorelinked_col is not None or all_col is not None:\n",
    "    join_cols = [SEASON_COL, WEEK_COL, TEAM_COL]\n",
    "    sel = [f\"a.*\"]\n",
    "    if scorelinked_col is not None and scorelinked_col not in cols:\n",
    "        sel.append(f\"b.{scorelinked_col} AS {scorelinked_col}\")\n",
    "    if all_col is not None and all_col not in cols:\n",
    "        sel.append(f\"b.{all_col} AS {all_col}\")\n",
    "\n",
    "    if len(sel) > 1:\n",
    "        df = con.execute(f\"\"\"\n",
    "        SELECT {\", \".join(sel)}\n",
    "        FROM df a\n",
    "        LEFT JOIN {MODEL_VIEW} b\n",
    "        ON a.{SEASON_COL} = b.{SEASON_COL}\n",
    "        AND a.{WEEK_COL} = b.{WEEK_COL}\n",
    "        AND a.{TEAM_COL} = b.{TEAM_COL}\n",
    "        \"\"\").df()\n",
    "\n",
    "def add_diag_prefix(load_col: str, prefix: str):\n",
    "    df[f\"load_{prefix}\"] = df[load_col].astype(float)\n",
    "\n",
    "    mean_prior = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.expanding().mean().shift(1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "    sd_prior = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.expanding().std(ddof=1).shift(1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "\n",
    "    z_prior = (df[f\"load_{prefix}\"] - mean_prior) / sd_prior\n",
    "    df[f\"shock_{prefix}\"] = (z_prior >= 1).fillna(False).astype(int)\n",
    "    df[f\"shock_x_blowout_{prefix}\"] = (df[f\"shock_{prefix}\"] * df[\"blowout_flag_w\"].fillna(0).astype(int)).astype(int)\n",
    "\n",
    "    df[f\"vol_{prefix}_s2d_prior\"] = sd_prior.fillna(0.0).astype(float)\n",
    "    df[f\"vol_{prefix}_roll4_prior\"] = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.shift(1).rolling(4, min_periods=2).std(ddof=1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "        .fillna(df[f\"vol_{prefix}_s2d_prior\"])\n",
    "        .astype(float)\n",
    "    )\n",
    "    df[f\"cum_shocks_{prefix}_prior\"] = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"shock_{prefix}\"]\n",
    "        .cumsum()\n",
    "        .shift(1)\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "if scorelinked_col is not None and scorelinked_col in df.columns:\n",
    "    add_diag_prefix(scorelinked_col, \"scorelinked\")\n",
    "\n",
    "if all_col is not None and all_col in df.columns:\n",
    "    add_diag_prefix(all_col, \"all\")\n",
    "\n",
    "con.register(\"step18_model_frame_tmp\", df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step18_model_frame AS SELECT * FROM step18_model_frame_tmp\")\n",
    "con.unregister(\"step18_model_frame_tmp\")\n",
    "\n",
    "print(\"wrote duckdb table step18_model_frame\")\n",
    "print(\"rows\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b27d1-4905-45a6-80e5-0ac4b98cd80d",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that every candidate spec will use a consistent non missing modeling sample and the key exposure variables have variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3401807-bb5a-4ad2-ac87-3ecdc838e30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null counts in required columns\n",
      "shock_nonscore                 0\n",
      "shock_x_blowout                0\n",
      "cum_shocks_nonscore_prior      0\n",
      "vol_nonscore_s2d_prior         0\n",
      "vol_nonscore_roll4_prior       0\n",
      "ST_Shock_NonScore_w_minus_1    0\n",
      "ST_Shock_NonScore_w_minus_2    0\n",
      "ST_Shock_NonScore_w_minus_3    0\n",
      "blowout_flag_w                 0\n",
      "dtype: int64\n",
      "shock_nonscore value counts\n",
      "shock_nonscore\n",
      "0    4943\n",
      "1    1007\n",
      "Name: count, dtype: int64\n",
      "vol_nonscore_s2d_prior min max\n",
      "0.0 9.192388155425117\n",
      "cum_shocks_nonscore_prior min max\n",
      "0 7\n"
     ]
    }
   ],
   "source": [
    "df = con.execute(\"SELECT * FROM step18_model_frame\").df()\n",
    "\n",
    "required = [\n",
    "    \"shock_nonscore\",\n",
    "    \"shock_x_blowout\",\n",
    "    \"cum_shocks_nonscore_prior\",\n",
    "    \"vol_nonscore_s2d_prior\",\n",
    "    \"vol_nonscore_roll4_prior\",\n",
    "    \"ST_Shock_NonScore_w_minus_1\",\n",
    "    \"ST_Shock_NonScore_w_minus_2\",\n",
    "    \"ST_Shock_NonScore_w_minus_3\",\n",
    "    \"blowout_flag_w\",\n",
    "]\n",
    "\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing required step18 columns, {missing}\")\n",
    "\n",
    "nulls = df[required].isna().sum().sort_values(ascending=False)\n",
    "print(\"null counts in required columns\")\n",
    "print(nulls)\n",
    "\n",
    "print(\"shock_nonscore value counts\")\n",
    "print(df[\"shock_nonscore\"].value_counts(dropna=False).sort_index())\n",
    "\n",
    "print(\"vol_nonscore_s2d_prior min max\")\n",
    "print(float(df[\"vol_nonscore_s2d_prior\"].min()), float(df[\"vol_nonscore_s2d_prior\"].max()))\n",
    "\n",
    "print(\"cum_shocks_nonscore_prior min max\")\n",
    "print(int(df[\"cum_shocks_nonscore_prior\"].min()), int(df[\"cum_shocks_nonscore_prior\"].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce854611-f080-480f-914e-a6f1dfc30583",
   "metadata": {},
   "source": [
    "We define consistent AIC and BIC calculation helpers to avoid common pitfalls, such as using deviance-based BIC or failing to account for the fact that robust clustering affects inference without altering the likelihood criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa5db68-638e-4f3c-9367-7934b39ed5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpers ready\n"
     ]
    }
   ],
   "source": [
    "df = con.execute(\"SELECT * FROM step18_model_frame\").df()\n",
    "\n",
    "TEAM_COL = \"team\" if \"team\" in df.columns else \"team_key\"\n",
    "SEASON_COL = \"season\"\n",
    "WEEK_COL = \"week\"\n",
    "\n",
    "OUTCOME_DEF = \"Inj_Def_Next_w\"\n",
    "OUTCOME_OFF = \"Inj_Off_Next_w\"\n",
    "\n",
    "for out in [OUTCOME_DEF, OUTCOME_OFF]:\n",
    "    if out not in df.columns:\n",
    "        raise RuntimeError(f\"Missing outcome {out}, rerun notebook 9 through 11 then rebuild step16 and step18\")\n",
    "\n",
    "def aic_bic(llf: float, nobs: int, k_params: int) -> tuple[float, float]:\n",
    "    if not np.isfinite(llf) or (nobs <= 0) or (k_params <= 0):\n",
    "        return np.nan, np.nan\n",
    "    aic_val = -2.0 * llf + 2.0 * k_params\n",
    "    bic_val = -2.0 * llf + np.log(float(nobs)) * float(k_params)\n",
    "    return float(aic_val), float(bic_val)\n",
    "\n",
    "def extract_alpha(res) -> float:\n",
    "    if res is None:\n",
    "        return np.nan\n",
    "    try:\n",
    "        if hasattr(res, \"params\") and (\"alpha\" in res.params.index):\n",
    "            return float(res.params.loc[\"alpha\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        fam = getattr(getattr(res, \"model\", None), \"family\", None)\n",
    "        if fam is not None and hasattr(fam, \"alpha\"):\n",
    "            return float(fam.alpha)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.nan\n",
    "\n",
    "def fit_poisson(formula: str, data: pd.DataFrame):\n",
    "    m = smf.glm(formula=formula, data=data, family=sm.families.Poisson())\n",
    "    r = m.fit(maxiter=200, disp=0)\n",
    "    return r\n",
    "\n",
    "def fit_nb_discrete(formula: str, data: pd.DataFrame):\n",
    "    m = smf.negativebinomial(formula=formula, data=data)\n",
    "    r = m.fit(disp=False, maxiter=200)\n",
    "    return r\n",
    "\n",
    "def robust_cluster(res, groups: pd.Series):\n",
    "    try:\n",
    "        return res.get_robustcov_results(cov_type=\"cluster\", groups=groups)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fit_one_spec(spec_id: str, side: str, outcome: str, formula: str, family: str, data: pd.DataFrame, key_terms: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if family not in [\"poisson\", \"negative_binomial\"]:\n",
    "        raise RuntimeError(\"family must be poisson or negative_binomial\")\n",
    "\n",
    "    base_res = None\n",
    "    err = None\n",
    "    try:\n",
    "        if family == \"poisson\":\n",
    "            base_res = fit_poisson(formula, data)\n",
    "        else:\n",
    "            base_res = fit_nb_discrete(formula, data)\n",
    "    except Exception as e:\n",
    "        err = str(e)\n",
    "\n",
    "    if base_res is None:\n",
    "        meta = pd.DataFrame([{\n",
    "            \"spec_id\": spec_id,\n",
    "            \"side\": side,\n",
    "            \"outcome\": outcome,\n",
    "            \"family\": family,\n",
    "            \"formula\": formula,\n",
    "            \"nobs\": np.nan,\n",
    "            \"k_params\": np.nan,\n",
    "            \"llf\": np.nan,\n",
    "            \"aic\": np.nan,\n",
    "            \"bic\": np.nan,\n",
    "            \"alpha\": np.nan,\n",
    "            \"fit_error\": err,\n",
    "        }])\n",
    "        coefs = pd.DataFrame([], columns=[\n",
    "            \"spec_id\", \"side\", \"outcome\", \"family\", \"term\", \"beta\", \"se_cluster\", \"pvalue\", \"is_key_term\"\n",
    "        ])\n",
    "        return meta, coefs\n",
    "\n",
    "    nobs = int(getattr(base_res, \"nobs\", np.nan))\n",
    "    params = base_res.params\n",
    "    k_params = int(len(params))\n",
    "    llf = float(getattr(base_res, \"llf\", np.nan))\n",
    "    aic_val, bic_val = aic_bic(llf, nobs, k_params)\n",
    "    alpha = extract_alpha(base_res)\n",
    "\n",
    "    groups = data[TEAM_COL]\n",
    "    rob = robust_cluster(base_res, groups)\n",
    "\n",
    "    if rob is None:\n",
    "        se = getattr(base_res, \"bse\", pd.Series(index=params.index, data=np.nan)).astype(float)\n",
    "        pv = getattr(base_res, \"pvalues\", pd.Series(index=params.index, data=np.nan)).astype(float)\n",
    "    else:\n",
    "        se = rob.bse.astype(float)\n",
    "        pv = rob.pvalues.astype(float)\n",
    "\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"spec_id\": spec_id,\n",
    "        \"side\": side,\n",
    "        \"outcome\": outcome,\n",
    "        \"family\": family,\n",
    "        \"term\": params.index.astype(str),\n",
    "        \"beta\": params.values.astype(float),\n",
    "        \"se_cluster\": se.reindex(params.index).values.astype(float),\n",
    "        \"pvalue\": pv.reindex(params.index).values.astype(float),\n",
    "    })\n",
    "\n",
    "    key_set = set(key_terms)\n",
    "    coef_df[\"is_key_term\"] = coef_df[\"term\"].apply(lambda x: 1 if x in key_set else 0)\n",
    "\n",
    "    meta = pd.DataFrame([{\n",
    "        \"spec_id\": spec_id,\n",
    "        \"side\": side,\n",
    "        \"outcome\": outcome,\n",
    "        \"family\": family,\n",
    "        \"formula\": formula,\n",
    "        \"nobs\": nobs,\n",
    "        \"k_params\": k_params,\n",
    "        \"llf\": llf,\n",
    "        \"aic\": aic_val,\n",
    "        \"bic\": bic_val,\n",
    "        \"alpha\": alpha,\n",
    "        \"fit_error\": None,\n",
    "    }])\n",
    "\n",
    "    return meta, coef_df\n",
    "\n",
    "print(\"helpers ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754061de-a0c0-48fe-b6dd-139ecb3137cd",
   "metadata": {},
   "source": [
    "We fit a focused grid of model variants, then we write AIC and BIC tables and a coefficients table into DuckDB and into outputs csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc36ce5-4c33-45f9-ba1d-f4c791c930c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top specs by BIC for defense\n",
      "                        spec_id   family  nobs           aic           bic  \\\n",
      "0        nonscore_roll4_no_lags  poisson  5950  20805.188499  22551.577735   \n",
      "1          nonscore_s2d_no_lags  poisson  5950  20806.041592  22552.430828   \n",
      "2  scorelinked_s2d_diag_no_lags  poisson  5950  20806.194923  22552.584159   \n",
      "3          all_s2d_diag_no_lags  poisson  5950  20808.143250  22554.532486   \n",
      "4      nonscore_s2d_lags_no_vol  poisson  5950  20807.485216  22567.256745   \n",
      "5      nonscore_roll4_with_lags  poisson  5950  20808.400090  22574.862766   \n",
      "6        nonscore_s2d_with_lags  poisson  5950  20808.983821  22575.446496   \n",
      "\n",
      "  fit_error  \n",
      "0      None  \n",
      "1      None  \n",
      "2      None  \n",
      "3      None  \n",
      "4      None  \n",
      "5      None  \n",
      "6      None  \n",
      "top specs by BIC for offense\n",
      "                         spec_id   family  nobs           aic           bic  \\\n",
      "7         nonscore_roll4_no_lags  poisson  5950  20178.233429  21924.622665   \n",
      "8   scorelinked_s2d_diag_no_lags  poisson  5950  20178.625652  21925.014888   \n",
      "9           all_s2d_diag_no_lags  poisson  5950  20179.728926  21926.118162   \n",
      "10          nonscore_s2d_no_lags  poisson  5950  20183.164035  21929.553271   \n",
      "11      nonscore_s2d_lags_no_vol  poisson  5950  20188.125778  21947.897307   \n",
      "12      nonscore_roll4_with_lags  poisson  5950  20182.826369  21949.289045   \n",
      "13        nonscore_s2d_with_lags  poisson  5950  20187.268872  21953.731547   \n",
      "\n",
      "   fit_error  \n",
      "7       None  \n",
      "8       None  \n",
      "9       None  \n",
      "10      None  \n",
      "11      None  \n",
      "12      None  \n",
      "13      None  \n",
      "wrote duckdb table step18_model_selection_aic_bic\n",
      "wrote duckdb table step18_model_selection_coefficients\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step18_model_selection_aic_bic.csv\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step18_model_selection_coefficients.csv\n"
     ]
    }
   ],
   "source": [
    "df = con.execute(\"SELECT * FROM step18_model_frame\").df()\n",
    "TEAM_COL = \"team\" if \"team\" in df.columns else \"team_key\"\n",
    "\n",
    "FE_TEAM = f\"C({TEAM_COL})\"\n",
    "FE_TIME = \"C(season_week)\"\n",
    "\n",
    "control_common = [\n",
    "    \"short_week_flag_w\",\n",
    "    \"days_rest_w\",\n",
    "    \"bye_last_week_flag_w\",\n",
    "    \"home_flag_w\",\n",
    "    \"blowout_flag_w\",\n",
    "    \"points_for\",\n",
    "    \"points_against\",\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    \"Inj_Off_Last_w\",\n",
    "    \"Inj_Def_Last_w\",\n",
    "    \"Cumulative_Workload_Index_w\",\n",
    "]\n",
    "\n",
    "control_common = [c for c in control_common if c in df.columns]\n",
    "\n",
    "if \"points_for\" not in df.columns or \"points_against\" not in df.columns:\n",
    "    raise RuntimeError(\"Missing points_for or points_against, rerun notebook 10 and rebuild step11 onward\")\n",
    "\n",
    "base_lags = [\n",
    "    \"ST_Shock_NonScore_w_minus_1\",\n",
    "    \"ST_Shock_NonScore_w_minus_2\",\n",
    "    \"ST_Shock_NonScore_w_minus_3\",\n",
    "]\n",
    "base_lags = [c for c in base_lags if c in df.columns]\n",
    "\n",
    "specs = []\n",
    "\n",
    "specs.append({\n",
    "    \"spec_id\": \"nonscore_s2d_with_lags\",\n",
    "    \"family\": None,\n",
    "    \"side\": \"both\",\n",
    "    \"exposure_terms\": [\n",
    "        \"shock_nonscore\",\n",
    "        \"shock_x_blowout\",\n",
    "        \"vol_nonscore_s2d_prior\",\n",
    "        \"cum_shocks_nonscore_prior\",\n",
    "    ] + base_lags,\n",
    "})\n",
    "\n",
    "specs.append({\n",
    "    \"spec_id\": \"nonscore_s2d_no_lags\",\n",
    "    \"family\": None,\n",
    "    \"side\": \"both\",\n",
    "    \"exposure_terms\": [\n",
    "        \"shock_nonscore\",\n",
    "        \"shock_x_blowout\",\n",
    "        \"vol_nonscore_s2d_prior\",\n",
    "        \"cum_shocks_nonscore_prior\",\n",
    "    ],\n",
    "})\n",
    "\n",
    "specs.append({\n",
    "    \"spec_id\": \"nonscore_roll4_with_lags\",\n",
    "    \"family\": None,\n",
    "    \"side\": \"both\",\n",
    "    \"exposure_terms\": [\n",
    "        \"shock_nonscore\",\n",
    "        \"shock_x_blowout\",\n",
    "        \"vol_nonscore_roll4_prior\",\n",
    "        \"cum_shocks_nonscore_prior\",\n",
    "    ] + base_lags,\n",
    "})\n",
    "\n",
    "specs.append({\n",
    "    \"spec_id\": \"nonscore_roll4_no_lags\",\n",
    "    \"family\": None,\n",
    "    \"side\": \"both\",\n",
    "    \"exposure_terms\": [\n",
    "        \"shock_nonscore\",\n",
    "        \"shock_x_blowout\",\n",
    "        \"vol_nonscore_roll4_prior\",\n",
    "        \"cum_shocks_nonscore_prior\",\n",
    "    ],\n",
    "})\n",
    "\n",
    "specs.append({\n",
    "    \"spec_id\": \"nonscore_s2d_lags_no_vol\",\n",
    "    \"family\": None,\n",
    "    \"side\": \"both\",\n",
    "    \"exposure_terms\": [\n",
    "        \"shock_nonscore\",\n",
    "        \"shock_x_blowout\",\n",
    "        \"cum_shocks_nonscore_prior\",\n",
    "    ] + base_lags,\n",
    "})\n",
    "\n",
    "if \"shock_scorelinked\" in df.columns:\n",
    "    diag_lags = []\n",
    "    specs.append({\n",
    "        \"spec_id\": \"scorelinked_s2d_diag_no_lags\",\n",
    "        \"family\": None,\n",
    "        \"side\": \"both\",\n",
    "        \"exposure_terms\": [\n",
    "            \"shock_scorelinked\",\n",
    "            \"shock_x_blowout_scorelinked\",\n",
    "            \"vol_scorelinked_s2d_prior\",\n",
    "            \"cum_shocks_scorelinked_prior\",\n",
    "        ] + diag_lags,\n",
    "    })\n",
    "\n",
    "if \"shock_all\" in df.columns:\n",
    "    diag_lags = []\n",
    "    specs.append({\n",
    "        \"spec_id\": \"all_s2d_diag_no_lags\",\n",
    "        \"family\": None,\n",
    "        \"side\": \"both\",\n",
    "        \"exposure_terms\": [\n",
    "            \"shock_all\",\n",
    "            \"shock_x_blowout_all\",\n",
    "            \"vol_all_s2d_prior\",\n",
    "            \"cum_shocks_all_prior\",\n",
    "        ] + diag_lags,\n",
    "    })\n",
    "\n",
    "def choose_family_from_step16(outcome: str) -> str:\n",
    "    stats_cols = set(con.execute(\"SHOW TABLES\").df()[\"name\"].astype(str).tolist())\n",
    "\n",
    "    if \"step16_overdispersion_diagnostics\" in stats_cols:\n",
    "        d = con.execute(\"SELECT * FROM step16_overdispersion_diagnostics\").df()\n",
    "        cols = list(d.columns)\n",
    "        low = {c.lower(): c for c in cols}\n",
    "\n",
    "        outcome_col_candidates = [\"outcome\", \"y\", \"depvar\", \"dependent\", \"response\", \"dv\"]\n",
    "        fam_col_candidates = [\"chosen_family\", \"family\", \"selected_family\", \"best_family\", \"model_family\"]\n",
    "\n",
    "        out_col = next((low[c] for c in outcome_col_candidates if c in low), None)\n",
    "        fam_col = next((low[c] for c in fam_col_candidates if c in low), None)\n",
    "\n",
    "        if out_col is None:\n",
    "            for c in cols:\n",
    "                try:\n",
    "                    if (d[c].astype(str) == str(outcome)).any():\n",
    "                        out_col = c\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "        if fam_col is None:\n",
    "            for c in cols:\n",
    "                try:\n",
    "                    vals = d[c].astype(str).str.lower().unique().tolist()\n",
    "                    joined = \" \".join(vals)\n",
    "                    if (\"poisson\" in joined) or (\"negative\" in joined) or (\"nb\" in joined):\n",
    "                        fam_col = c\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "        if (out_col is not None) and (fam_col is not None):\n",
    "            row = d[d[out_col].astype(str) == str(outcome)]\n",
    "            if len(row) == 1:\n",
    "                fam_raw = str(row[fam_col].iloc[0]).lower()\n",
    "                if (\"negative\" in fam_raw) or (fam_raw in [\"nb\", \"neg_bin\", \"negativebinomial\", \"negative_binomial\"]):\n",
    "                    return \"negative_binomial\"\n",
    "                if \"poisson\" in fam_raw:\n",
    "                    return \"poisson\"\n",
    "\n",
    "    y = df[outcome].astype(float)\n",
    "    m = float(y.mean())\n",
    "    v = float(y.var(ddof=1))\n",
    "    if np.isfinite(m) and m > 0 and np.isfinite(v) and (v / m) >= 1.5:\n",
    "        return \"negative_binomial\"\n",
    "    return \"poisson\"\n",
    "\n",
    "fam_def = choose_family_from_step16(OUTCOME_DEF)\n",
    "fam_off = choose_family_from_step16(OUTCOME_OFF)\n",
    "\n",
    "def build_formula(outcome: str, exposure_terms: list[str]) -> str:\n",
    "    rhs = exposure_terms + control_common + [FE_TEAM, FE_TIME]\n",
    "    rhs = [t for t in rhs if t in df.columns or t.startswith(\"C(\")]\n",
    "    return outcome + \" ~ \" + \" + \".join(rhs)\n",
    "\n",
    "meta_rows = []\n",
    "coef_rows = []\n",
    "\n",
    "for sp in specs:\n",
    "    spec_id = sp[\"spec_id\"]\n",
    "    exposure_terms = sp[\"exposure_terms\"]\n",
    "\n",
    "    f_def = build_formula(OUTCOME_DEF, exposure_terms)\n",
    "    f_off = build_formula(OUTCOME_OFF, exposure_terms)\n",
    "\n",
    "    key_terms_def = exposure_terms\n",
    "    key_terms_off = exposure_terms\n",
    "\n",
    "    m_def, c_def = fit_one_spec(spec_id, \"def\", OUTCOME_DEF, f_def, fam_def, df, key_terms_def)\n",
    "    m_off, c_off = fit_one_spec(spec_id, \"off\", OUTCOME_OFF, f_off, fam_off, df, key_terms_off)\n",
    "\n",
    "    meta_rows.append(m_def)\n",
    "    meta_rows.append(m_off)\n",
    "    coef_rows.append(c_def)\n",
    "    coef_rows.append(c_off)\n",
    "\n",
    "meta_df = pd.concat(meta_rows, ignore_index=True)\n",
    "coef_df = pd.concat(coef_rows, ignore_index=True)\n",
    "\n",
    "meta_df = meta_df.sort_values([\"outcome\", \"side\", \"bic\"], na_position=\"last\").reset_index(drop=True)\n",
    "\n",
    "print(\"top specs by BIC for defense\")\n",
    "print(meta_df[(meta_df[\"side\"] == \"def\")].head(10)[[\"spec_id\", \"family\", \"nobs\", \"aic\", \"bic\", \"fit_error\"]])\n",
    "\n",
    "print(\"top specs by BIC for offense\")\n",
    "print(meta_df[(meta_df[\"side\"] == \"off\")].head(10)[[\"spec_id\", \"family\", \"nobs\", \"aic\", \"bic\", \"fit_error\"]])\n",
    "\n",
    "con.register(\"step18_meta_tmp\", meta_df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step18_model_selection_aic_bic AS SELECT * FROM step18_meta_tmp\")\n",
    "con.unregister(\"step18_meta_tmp\")\n",
    "\n",
    "con.register(\"step18_coef_tmp\", coef_df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step18_model_selection_coefficients AS SELECT * FROM step18_coef_tmp\")\n",
    "con.unregister(\"step18_coef_tmp\")\n",
    "\n",
    "out_dir = Path(\"../outputs\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "meta_csv = out_dir / \"step18_model_selection_aic_bic.csv\"\n",
    "coef_csv = out_dir / \"step18_model_selection_coefficients.csv\"\n",
    "\n",
    "meta_df.to_csv(meta_csv, index=False)\n",
    "coef_df.to_csv(coef_csv, index=False)\n",
    "\n",
    "print(\"wrote duckdb table step18_model_selection_aic_bic\")\n",
    "print(\"wrote duckdb table step18_model_selection_coefficients\")\n",
    "print(\"wrote csv\", meta_csv.resolve())\n",
    "print(\"wrote csv\", coef_csv.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff6f66-643c-420e-b310-50e96780d2e7",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the preferred spec selection excludes diagnostics and consistently picks the lowest BIC NonScore model for each side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3723b44d-13df-4198-b05b-85685b430bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  side         outcome   family                 spec_id  \\\n",
      "0  def  Inj_Def_Next_w  poisson  nonscore_roll4_no_lags   \n",
      "1  off  Inj_Off_Next_w  poisson  nonscore_roll4_no_lags   \n",
      "\n",
      "                                             formula           aic  \\\n",
      "0  Inj_Def_Next_w ~ shock_nonscore + shock_x_blow...  20805.188499   \n",
      "1  Inj_Off_Next_w ~ shock_nonscore + shock_x_blow...  20178.233429   \n",
      "\n",
      "            bic  \n",
      "0  22551.577735  \n",
      "1  21924.622665  \n",
      "wrote duckdb table step18_preferred_model_specs\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step18_preferred_model_specs.csv\n"
     ]
    }
   ],
   "source": [
    "meta_df = con.execute(\"SELECT * FROM step18_model_selection_aic_bic\").df()\n",
    "\n",
    "col_map = {c.lower(): c for c in meta_df.columns}\n",
    "OUTCOME_COL = col_map.get(\"outcome\", None)\n",
    "if OUTCOME_COL is None:\n",
    "    OUTCOME_COL = col_map.get(\"y\", None)\n",
    "\n",
    "if OUTCOME_COL is None:\n",
    "    OUTCOME_COL = \"outcome\"\n",
    "    meta_df[OUTCOME_COL] = meta_df[\"formula\"].astype(str).str.split(\"~\").str[0].str.strip()\n",
    "\n",
    "def pick_preferred(side: str) -> pd.Series:\n",
    "    m = meta_df[(meta_df[\"side\"] == side) & (meta_df[\"fit_error\"].isna())].copy()\n",
    "    m[\"is_diag\"] = m[\"spec_id\"].astype(str).str.contains(\"scorelinked|all\", case=False, regex=True)\n",
    "    m = m[m[\"is_diag\"] == False].copy()\n",
    "    m = m.sort_values([\"bic\", \"aic\", \"spec_id\"], na_position=\"last\").reset_index(drop=True)\n",
    "    if len(m) == 0:\n",
    "        raise RuntimeError(f\"No successful NonScore specs for side {side}\")\n",
    "    return m.iloc[0]\n",
    "\n",
    "pref_def = pick_preferred(\"def\")\n",
    "pref_off = pick_preferred(\"off\")\n",
    "\n",
    "preferred = pd.DataFrame([{\n",
    "    \"side\": \"def\",\n",
    "    \"outcome\": str(pref_def[OUTCOME_COL]),\n",
    "    \"family\": str(pref_def[\"family\"]),\n",
    "    \"spec_id\": str(pref_def[\"spec_id\"]),\n",
    "    \"formula\": str(pref_def[\"formula\"]),\n",
    "    \"aic\": float(pref_def[\"aic\"]),\n",
    "    \"bic\": float(pref_def[\"bic\"]),\n",
    "}, {\n",
    "    \"side\": \"off\",\n",
    "    \"outcome\": str(pref_off[OUTCOME_COL]),\n",
    "    \"family\": str(pref_off[\"family\"]),\n",
    "    \"spec_id\": str(pref_off[\"spec_id\"]),\n",
    "    \"formula\": str(pref_off[\"formula\"]),\n",
    "    \"aic\": float(pref_off[\"aic\"]),\n",
    "    \"bic\": float(pref_off[\"bic\"]),\n",
    "}])\n",
    "\n",
    "print(preferred)\n",
    "\n",
    "if (preferred[\"spec_id\"] != \"nonscore_roll4_no_lags\").any():\n",
    "    print(\"note preferred spec is not nonscore_roll4_no_lags for at least one side, verify step18_model_selection_aic_bic ordering\")\n",
    "\n",
    "con.register(\"step18_pref_tmp\", preferred)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step18_preferred_model_specs AS SELECT * FROM step18_pref_tmp\")\n",
    "con.unregister(\"step18_pref_tmp\")\n",
    "\n",
    "out_dir = Path(\"../outputs\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pref_csv = out_dir / \"step18_preferred_model_specs.csv\"\n",
    "preferred.to_csv(pref_csv, index=False)\n",
    "\n",
    "print(\"wrote duckdb table step18_preferred_model_specs\")\n",
    "print(\"wrote csv\", pref_csv.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
