{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a19dee-1441-4cbd-8c20-75b4ba6cd2db",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edb5cda-e19a-488b-911c-7f2070960879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected db /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/db/nflpa.duckdb\n",
      "base table step16_modeling_frame_nolookahead\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, HessianInversionWarning\n",
    "\n",
    "try:\n",
    "    import statsmodels.genmod.generalized_linear_model as glm\n",
    "    glm.SET_USE_BIC_LLF(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"The bic value is computed using the deviance formula.*\",\n",
    ")\n",
    "\n",
    "CWD = Path().resolve()\n",
    "\n",
    "REPO_ROOT = None\n",
    "DB_FILE = None\n",
    "\n",
    "for p in [CWD] + list(CWD.parents):\n",
    "    cand = p / \"db\" / \"nflpa.duckdb\"\n",
    "    if cand.exists():\n",
    "        REPO_ROOT = p\n",
    "        DB_FILE = cand\n",
    "        break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    for p in [CWD] + list(CWD.parents):\n",
    "        cand = p / \"nflpa.duckdb\"\n",
    "        if cand.exists():\n",
    "            REPO_ROOT = p\n",
    "            DB_FILE = cand\n",
    "            break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    raise RuntimeError(\"Could not find nflpa.duckdb, expected db or notebook parent folders to contain it\")\n",
    "\n",
    "con = duckdb.connect(str(DB_FILE), read_only=False)\n",
    "\n",
    "BASE_TABLE = \"step16_modeling_frame_nolookahead\"\n",
    "\n",
    "exists_df = con.execute(f\"\"\"\n",
    "SELECT COUNT(*) AS n\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name = '{BASE_TABLE}'\n",
    "  AND table_type IN ('BASE TABLE', 'VIEW')\n",
    "\"\"\").df()\n",
    "\n",
    "if int(exists_df[\"n\"].iloc[0]) == 0:\n",
    "    raise RuntimeError(f\"Missing {BASE_TABLE}, run notebook 16 first\")\n",
    "\n",
    "print(\"connected db\", str(DB_FILE))\n",
    "print(\"base table\", BASE_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb9d01-6b3e-4cc2-8dad-3b3bfb5dc617",
   "metadata": {},
   "source": [
    "We build a modeling table that adds rolling volatility and prior season to date volatility and prior cumulative shock, and construct 'ScoreLinked' and 'All' diagnostics without changing the main 'NonScore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21882fb2-3558-4226-902b-c9dbbc3c7478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote duckdb table step18_model_frame\n",
      "rows 5950\n"
     ]
    }
   ],
   "source": [
    "df = con.execute(f\"SELECT * FROM {BASE_TABLE}\").df()\n",
    "\n",
    "desc = con.execute(f\"DESCRIBE {BASE_TABLE}\").df()\n",
    "cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "def pick_col(candidates: list[str], available: set[str], label: str) -> str:\n",
    "    for c in candidates:\n",
    "        if c in available:\n",
    "            return c\n",
    "    raise RuntimeError(f\"Missing {label}, add its exact name into candidates, available columns include {sorted(list(available))[:40]}\")\n",
    "\n",
    "TEAM_COL = pick_col([\"team\", \"team_key\"], cols, \"team id column\")\n",
    "SEASON_COL = pick_col([\"season\"], cols, \"season column\")\n",
    "WEEK_COL = pick_col([\"week\"], cols, \"week column\")\n",
    "\n",
    "if \"season_week\" not in df.columns:\n",
    "    df[\"season_week\"] = (df[SEASON_COL].astype(int) * 100 + df[WEEK_COL].astype(int)).astype(int)\n",
    "\n",
    "if \"load_nonscore\" not in df.columns:\n",
    "    load_candidates = [\"ST_Load_NonScore_w\", \"ST_Load_NonScore\", \"ST_Load_NonScore_w\"]\n",
    "    load_col = pick_col(load_candidates, cols, \"NonScore load column for volatility construction\")\n",
    "    df[\"load_nonscore\"] = df[load_col].astype(float)\n",
    "\n",
    "if \"shock_nonscore\" not in df.columns:\n",
    "    shock_candidates = [\"ST_Shock_NonScore_w\", \"shock_nonscore\"]\n",
    "    shock_col = pick_col(shock_candidates, cols, \"NonScore shock column\")\n",
    "    df[\"shock_nonscore\"] = df[shock_col].fillna(0).astype(int)\n",
    "\n",
    "if \"blowout_flag_w\" not in df.columns:\n",
    "    raise RuntimeError(\"Missing blowout_flag_w in the step16 frame, rerun notebook 10 and 11 then rebuild step16\")\n",
    "\n",
    "df = df.sort_values([TEAM_COL, SEASON_COL, WEEK_COL]).reset_index(drop=True)\n",
    "g = df.groupby([TEAM_COL, SEASON_COL], sort=False)\n",
    "\n",
    "df[\"cum_shocks_nonscore_prior\"] = g[\"shock_nonscore\"].cumsum().shift(1).fillna(0).astype(int)\n",
    "\n",
    "df[\"vol_nonscore_s2d_prior\"] = (\n",
    "    g[\"load_nonscore\"]\n",
    "    .apply(lambda s: s.expanding().std(ddof=1).shift(1))\n",
    "    .reset_index(level=[0, 1], drop=True)\n",
    "    .fillna(0.0)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"vol_nonscore_roll4_prior\"] = (\n",
    "    g[\"load_nonscore\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(4, min_periods=2).std(ddof=1))\n",
    "    .reset_index(level=[0, 1], drop=True)\n",
    "    .fillna(df[\"vol_nonscore_s2d_prior\"])\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "for k in [1, 2, 3]:\n",
    "    col = f\"ST_Shock_NonScore_w_minus_{k}\"\n",
    "    if col not in df.columns:\n",
    "        df[col] = g[\"shock_nonscore\"].shift(k).fillna(0).astype(int)\n",
    "\n",
    "if \"shock_x_blowout\" not in df.columns:\n",
    "    df[\"shock_x_blowout\"] = (df[\"shock_nonscore\"] * df[\"blowout_flag_w\"].fillna(0).astype(int)).astype(int)\n",
    "\n",
    "MODEL_VIEW = \"team_week_panel_nextweek_model\"\n",
    "mv_exists = con.execute(f\"\"\"\n",
    "SELECT COUNT(*) AS n\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name = '{MODEL_VIEW}'\n",
    "  AND table_type IN ('BASE TABLE', 'VIEW')\n",
    "\"\"\").df()\n",
    "if int(mv_exists[\"n\"].iloc[0]) == 0:\n",
    "    raise RuntimeError(f\"Missing {MODEL_VIEW}, run notebook 11 to recreate it\")\n",
    "\n",
    "mv_desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "mv_cols = set(mv_desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "scorelinked_col = None\n",
    "all_col = None\n",
    "if \"ST_Load_ScoreLinked_w\" in cols:\n",
    "    scorelinked_col = \"ST_Load_ScoreLinked_w\"\n",
    "if \"ST_Load_All_w\" in cols:\n",
    "    all_col = \"ST_Load_All_w\"\n",
    "\n",
    "need_join = (scorelinked_col is None) or (all_col is None)\n",
    "if need_join:\n",
    "    if \"ST_Load_ScoreLinked_w\" in mv_cols:\n",
    "        scorelinked_col = \"ST_Load_ScoreLinked_w\"\n",
    "    if \"ST_Load_All_w\" in mv_cols:\n",
    "        all_col = \"ST_Load_All_w\"\n",
    "\n",
    "if scorelinked_col is not None or all_col is not None:\n",
    "    join_cols = [SEASON_COL, WEEK_COL, TEAM_COL]\n",
    "    sel = [f\"a.*\"]\n",
    "    if scorelinked_col is not None and scorelinked_col not in cols:\n",
    "        sel.append(f\"b.{scorelinked_col} AS {scorelinked_col}\")\n",
    "    if all_col is not None and all_col not in cols:\n",
    "        sel.append(f\"b.{all_col} AS {all_col}\")\n",
    "\n",
    "    if len(sel) > 1:\n",
    "        df = con.execute(f\"\"\"\n",
    "        SELECT {\", \".join(sel)}\n",
    "        FROM df a\n",
    "        LEFT JOIN {MODEL_VIEW} b\n",
    "        ON a.{SEASON_COL} = b.{SEASON_COL}\n",
    "        AND a.{WEEK_COL} = b.{WEEK_COL}\n",
    "        AND a.{TEAM_COL} = b.{TEAM_COL}\n",
    "        \"\"\").df()\n",
    "\n",
    "def add_diag_prefix(load_col: str, prefix: str):\n",
    "    df[f\"load_{prefix}\"] = df[load_col].astype(float)\n",
    "\n",
    "    mean_prior = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.expanding().mean().shift(1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "    sd_prior = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.expanding().std(ddof=1).shift(1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "\n",
    "    z_prior = (df[f\"load_{prefix}\"] - mean_prior) / sd_prior\n",
    "    df[f\"shock_{prefix}\"] = (z_prior >= 1).fillna(False).astype(int)\n",
    "    df[f\"shock_x_blowout_{prefix}\"] = (df[f\"shock_{prefix}\"] * df[\"blowout_flag_w\"].fillna(0).astype(int)).astype(int)\n",
    "\n",
    "    df[f\"vol_{prefix}_s2d_prior\"] = sd_prior.fillna(0.0).astype(float)\n",
    "    df[f\"vol_{prefix}_roll4_prior\"] = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.shift(1).rolling(4, min_periods=2).std(ddof=1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "        .fillna(df[f\"vol_{prefix}_s2d_prior\"])\n",
    "        .astype(float)\n",
    "    )\n",
    "    df[f\"cum_shocks_{prefix}_prior\"] = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"shock_{prefix}\"]\n",
    "        .cumsum()\n",
    "        .shift(1)\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "if scorelinked_col is not None and scorelinked_col in df.columns:\n",
    "    add_diag_prefix(scorelinked_col, \"scorelinked\")\n",
    "\n",
    "if all_col is not None and all_col in df.columns:\n",
    "    add_diag_prefix(all_col, \"all\")\n",
    "\n",
    "con.register(\"step18_model_frame_tmp\", df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step18_model_frame AS SELECT * FROM step18_model_frame_tmp\")\n",
    "con.unregister(\"step18_model_frame_tmp\")\n",
    "\n",
    "print(\"wrote duckdb table step18_model_frame\")\n",
    "print(\"rows\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b27d1-4905-45a6-80e5-0ac4b98cd80d",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that every candidate spec will use a consistent non missing modeling sample and the key exposure variables have variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3401807-bb5a-4ad2-ac87-3ecdc838e30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null counts in required columns\n",
      "shock_nonscore                 0\n",
      "shock_x_blowout                0\n",
      "cum_shocks_nonscore_prior      0\n",
      "vol_nonscore_s2d_prior         0\n",
      "vol_nonscore_roll4_prior       0\n",
      "ST_Shock_NonScore_w_minus_1    0\n",
      "ST_Shock_NonScore_w_minus_2    0\n",
      "ST_Shock_NonScore_w_minus_3    0\n",
      "blowout_flag_w                 0\n",
      "dtype: int64\n",
      "shock_nonscore value counts\n",
      "shock_nonscore\n",
      "0    4943\n",
      "1    1007\n",
      "Name: count, dtype: int64\n",
      "vol_nonscore_s2d_prior min max\n",
      "0.0 9.192388155425117\n",
      "cum_shocks_nonscore_prior min max\n",
      "0 7\n"
     ]
    }
   ],
   "source": [
    "df = con.execute(\"SELECT * FROM step18_model_frame\").df()\n",
    "\n",
    "required = [\n",
    "    \"shock_nonscore\",\n",
    "    \"shock_x_blowout\",\n",
    "    \"cum_shocks_nonscore_prior\",\n",
    "    \"vol_nonscore_s2d_prior\",\n",
    "    \"vol_nonscore_roll4_prior\",\n",
    "    \"ST_Shock_NonScore_w_minus_1\",\n",
    "    \"ST_Shock_NonScore_w_minus_2\",\n",
    "    \"ST_Shock_NonScore_w_minus_3\",\n",
    "    \"blowout_flag_w\",\n",
    "]\n",
    "\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing required step18 columns, {missing}\")\n",
    "\n",
    "nulls = df[required].isna().sum().sort_values(ascending=False)\n",
    "print(\"null counts in required columns\")\n",
    "print(nulls)\n",
    "\n",
    "print(\"shock_nonscore value counts\")\n",
    "print(df[\"shock_nonscore\"].value_counts(dropna=False).sort_index())\n",
    "\n",
    "print(\"vol_nonscore_s2d_prior min max\")\n",
    "print(float(df[\"vol_nonscore_s2d_prior\"].min()), float(df[\"vol_nonscore_s2d_prior\"].max()))\n",
    "\n",
    "print(\"cum_shocks_nonscore_prior min max\")\n",
    "print(int(df[\"cum_shocks_nonscore_prior\"].min()), int(df[\"cum_shocks_nonscore_prior\"].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce854611-f080-480f-914e-a6f1dfc30583",
   "metadata": {},
   "source": [
    "We define consistent AIC and BIC calculation helpers to avoid common pitfalls, such as using deviance-based BIC or failing to account for the fact that robust clustering affects inference without altering the likelihood criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa5db68-638e-4f3c-9367-7934b39ed5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpers ready\n"
     ]
    }
   ],
   "source": [
    "df = con.execute(\"SELECT * FROM step18_model_frame\").df()\n",
    "\n",
    "TEAM_COL = \"team\" if \"team\" in df.columns else \"team_key\"\n",
    "SEASON_COL = \"season\"\n",
    "WEEK_COL = \"week\"\n",
    "\n",
    "OUTCOME_DEF = \"Inj_Def_Next_w\"\n",
    "OUTCOME_OFF = \"Inj_Off_Next_w\"\n",
    "\n",
    "for out in [OUTCOME_DEF, OUTCOME_OFF]:\n",
    "    if out not in df.columns:\n",
    "        raise RuntimeError(f\"Missing outcome {out}, rerun notebook 9 through 11 then rebuild step16 and step18\")\n",
    "\n",
    "def aic_bic(llf: float, nobs: int, k_params: int) -> tuple[float, float]:\n",
    "    if not np.isfinite(llf) or (nobs <= 0) or (k_params <= 0):\n",
    "        return np.nan, np.nan\n",
    "    aic_val = -2.0 * llf + 2.0 * k_params\n",
    "    bic_val = -2.0 * llf + np.log(float(nobs)) * float(k_params)\n",
    "    return float(aic_val), float(bic_val)\n",
    "\n",
    "def extract_alpha(res) -> float:\n",
    "    if res is None:\n",
    "        return np.nan\n",
    "    try:\n",
    "        if hasattr(res, \"params\") and (\"alpha\" in res.params.index):\n",
    "            return float(res.params.loc[\"alpha\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        fam = getattr(getattr(res, \"model\", None), \"family\", None)\n",
    "        if fam is not None and hasattr(fam, \"alpha\"):\n",
    "            return float(fam.alpha)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.nan\n",
    "\n",
    "def fit_poisson(formula: str, data: pd.DataFrame):\n",
    "    m = smf.glm(formula=formula, data=data, family=sm.families.Poisson())\n",
    "    r = m.fit(maxiter=200, disp=0)\n",
    "    return r\n",
    "\n",
    "def fit_nb_discrete(formula: str, data: pd.DataFrame):\n",
    "    m = smf.negativebinomial(formula=formula, data=data)\n",
    "    r = m.fit(disp=False, maxiter=200)\n",
    "    return r\n",
    "\n",
    "def robust_cluster(res, groups: pd.Series):\n",
    "    try:\n",
    "        return res.get_robustcov_results(cov_type=\"cluster\", groups=groups)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fit_one_spec(spec_id: str, side: str, outcome: str, formula: str, family: str, data: pd.DataFrame, key_terms: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if family not in [\"poisson\", \"negative_binomial\"]:\n",
    "        raise RuntimeError(\"family must be poisson or negative_binomial\")\n",
    "\n",
    "    base_res = None\n",
    "    err = None\n",
    "    try:\n",
    "        if family == \"poisson\":\n",
    "            base_res = fit_poisson(formula, data)\n",
    "        else:\n",
    "            base_res = fit_nb_discrete(formula, data)\n",
    "    except Exception as e:\n",
    "        err = str(e)\n",
    "\n",
    "    if base_res is None:\n",
    "        meta = pd.DataFrame([{\n",
    "            \"spec_id\": spec_id,\n",
    "            \"side\": side,\n",
    "            \"outcome\": outcome,\n",
    "            \"family\": family,\n",
    "            \"formula\": formula,\n",
    "            \"nobs\": np.nan,\n",
    "            \"k_params\": np.nan,\n",
    "            \"llf\": np.nan,\n",
    "            \"aic\": np.nan,\n",
    "            \"bic\": np.nan,\n",
    "            \"alpha\": np.nan,\n",
    "            \"fit_error\": err,\n",
    "        }])\n",
    "        coefs = pd.DataFrame([], columns=[\n",
    "            \"spec_id\", \"side\", \"outcome\", \"family\", \"term\", \"beta\", \"se_cluster\", \"pvalue\", \"is_key_term\"\n",
    "        ])\n",
    "        return meta, coefs\n",
    "\n",
    "    nobs = int(getattr(base_res, \"nobs\", np.nan))\n",
    "    params = base_res.params\n",
    "    k_params = int(len(params))\n",
    "    llf = float(getattr(base_res, \"llf\", np.nan))\n",
    "    aic_val, bic_val = aic_bic(llf, nobs, k_params)\n",
    "    alpha = extract_alpha(base_res)\n",
    "\n",
    "    groups = data[TEAM_COL]\n",
    "    rob = robust_cluster(base_res, groups)\n",
    "\n",
    "    if rob is None:\n",
    "        se = getattr(base_res, \"bse\", pd.Series(index=params.index, data=np.nan)).astype(float)\n",
    "        pv = getattr(base_res, \"pvalues\", pd.Series(index=params.index, data=np.nan)).astype(float)\n",
    "    else:\n",
    "        se = rob.bse.astype(float)\n",
    "        pv = rob.pvalues.astype(float)\n",
    "\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"spec_id\": spec_id,\n",
    "        \"side\": side,\n",
    "        \"outcome\": outcome,\n",
    "        \"family\": family,\n",
    "        \"term\": params.index.astype(str),\n",
    "        \"beta\": params.values.astype(float),\n",
    "        \"se_cluster\": se.reindex(params.index).values.astype(float),\n",
    "        \"pvalue\": pv.reindex(params.index).values.astype(float),\n",
    "    })\n",
    "\n",
    "    key_set = set(key_terms)\n",
    "    coef_df[\"is_key_term\"] = coef_df[\"term\"].apply(lambda x: 1 if x in key_set else 0)\n",
    "\n",
    "    meta = pd.DataFrame([{\n",
    "        \"spec_id\": spec_id,\n",
    "        \"side\": side,\n",
    "        \"outcome\": outcome,\n",
    "        \"family\": family,\n",
    "        \"formula\": formula,\n",
    "        \"nobs\": nobs,\n",
    "        \"k_params\": k_params,\n",
    "        \"llf\": llf,\n",
    "        \"aic\": aic_val,\n",
    "        \"bic\": bic_val,\n",
    "        \"alpha\": alpha,\n",
    "        \"fit_error\": None,\n",
    "    }])\n",
    "\n",
    "    return meta, coef_df\n",
    "\n",
    "print(\"helpers ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
