{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a19dee-1441-4cbd-8c20-75b4ba6cd2db",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edb5cda-e19a-488b-911c-7f2070960879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected db /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/db/nflpa.duckdb\n",
      "base table step16_modeling_frame_nolookahead\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, HessianInversionWarning\n",
    "\n",
    "try:\n",
    "    import statsmodels.genmod.generalized_linear_model as glm\n",
    "    glm.SET_USE_BIC_LLF(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"The bic value is computed using the deviance formula.*\",\n",
    ")\n",
    "\n",
    "CWD = Path().resolve()\n",
    "\n",
    "REPO_ROOT = None\n",
    "DB_FILE = None\n",
    "\n",
    "for p in [CWD] + list(CWD.parents):\n",
    "    cand = p / \"db\" / \"nflpa.duckdb\"\n",
    "    if cand.exists():\n",
    "        REPO_ROOT = p\n",
    "        DB_FILE = cand\n",
    "        break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    for p in [CWD] + list(CWD.parents):\n",
    "        cand = p / \"nflpa.duckdb\"\n",
    "        if cand.exists():\n",
    "            REPO_ROOT = p\n",
    "            DB_FILE = cand\n",
    "            break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    raise RuntimeError(\"Could not find nflpa.duckdb, expected db or notebook parent folders to contain it\")\n",
    "\n",
    "con = duckdb.connect(str(DB_FILE), read_only=False)\n",
    "\n",
    "BASE_TABLE = \"step16_modeling_frame_nolookahead\"\n",
    "\n",
    "exists_df = con.execute(f\"\"\"\n",
    "SELECT COUNT(*) AS n\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name = '{BASE_TABLE}'\n",
    "  AND table_type IN ('BASE TABLE', 'VIEW')\n",
    "\"\"\").df()\n",
    "\n",
    "if int(exists_df[\"n\"].iloc[0]) == 0:\n",
    "    raise RuntimeError(f\"Missing {BASE_TABLE}, run notebook 16 first\")\n",
    "\n",
    "print(\"connected db\", str(DB_FILE))\n",
    "print(\"base table\", BASE_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb9d01-6b3e-4cc2-8dad-3b3bfb5dc617",
   "metadata": {},
   "source": [
    "We build a modeling table that adds rolling volatility and prior season to date volatility and prior cumulative shock, and construct 'ScoreLinked' and 'All' diagnostics without changing the main 'NonScore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21882fb2-3558-4226-902b-c9dbbc3c7478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote duckdb table step18_model_frame\n",
      "rows 5950\n"
     ]
    }
   ],
   "source": [
    "df = con.execute(f\"SELECT * FROM {BASE_TABLE}\").df()\n",
    "\n",
    "desc = con.execute(f\"DESCRIBE {BASE_TABLE}\").df()\n",
    "cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "def pick_col(candidates: list[str], available: set[str], label: str) -> str:\n",
    "    for c in candidates:\n",
    "        if c in available:\n",
    "            return c\n",
    "    raise RuntimeError(f\"Missing {label}, add its exact name into candidates, available columns include {sorted(list(available))[:40]}\")\n",
    "\n",
    "TEAM_COL = pick_col([\"team\", \"team_key\"], cols, \"team id column\")\n",
    "SEASON_COL = pick_col([\"season\"], cols, \"season column\")\n",
    "WEEK_COL = pick_col([\"week\"], cols, \"week column\")\n",
    "\n",
    "if \"season_week\" not in df.columns:\n",
    "    df[\"season_week\"] = (df[SEASON_COL].astype(int) * 100 + df[WEEK_COL].astype(int)).astype(int)\n",
    "\n",
    "if \"load_nonscore\" not in df.columns:\n",
    "    load_candidates = [\"ST_Load_NonScore_w\", \"ST_Load_NonScore\", \"ST_Load_NonScore_w\"]\n",
    "    load_col = pick_col(load_candidates, cols, \"NonScore load column for volatility construction\")\n",
    "    df[\"load_nonscore\"] = df[load_col].astype(float)\n",
    "\n",
    "if \"shock_nonscore\" not in df.columns:\n",
    "    shock_candidates = [\"ST_Shock_NonScore_w\", \"shock_nonscore\"]\n",
    "    shock_col = pick_col(shock_candidates, cols, \"NonScore shock column\")\n",
    "    df[\"shock_nonscore\"] = df[shock_col].fillna(0).astype(int)\n",
    "\n",
    "if \"blowout_flag_w\" not in df.columns:\n",
    "    raise RuntimeError(\"Missing blowout_flag_w in the step16 frame, rerun notebook 10 and 11 then rebuild step16\")\n",
    "\n",
    "df = df.sort_values([TEAM_COL, SEASON_COL, WEEK_COL]).reset_index(drop=True)\n",
    "g = df.groupby([TEAM_COL, SEASON_COL], sort=False)\n",
    "\n",
    "df[\"cum_shocks_nonscore_prior\"] = g[\"shock_nonscore\"].cumsum().shift(1).fillna(0).astype(int)\n",
    "\n",
    "df[\"vol_nonscore_s2d_prior\"] = (\n",
    "    g[\"load_nonscore\"]\n",
    "    .apply(lambda s: s.expanding().std(ddof=1).shift(1))\n",
    "    .reset_index(level=[0, 1], drop=True)\n",
    "    .fillna(0.0)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"vol_nonscore_roll4_prior\"] = (\n",
    "    g[\"load_nonscore\"]\n",
    "    .apply(lambda s: s.shift(1).rolling(4, min_periods=2).std(ddof=1))\n",
    "    .reset_index(level=[0, 1], drop=True)\n",
    "    .fillna(df[\"vol_nonscore_s2d_prior\"])\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "for k in [1, 2, 3]:\n",
    "    col = f\"ST_Shock_NonScore_w_minus_{k}\"\n",
    "    if col not in df.columns:\n",
    "        df[col] = g[\"shock_nonscore\"].shift(k).fillna(0).astype(int)\n",
    "\n",
    "if \"shock_x_blowout\" not in df.columns:\n",
    "    df[\"shock_x_blowout\"] = (df[\"shock_nonscore\"] * df[\"blowout_flag_w\"].fillna(0).astype(int)).astype(int)\n",
    "\n",
    "MODEL_VIEW = \"team_week_panel_nextweek_model\"\n",
    "mv_exists = con.execute(f\"\"\"\n",
    "SELECT COUNT(*) AS n\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name = '{MODEL_VIEW}'\n",
    "  AND table_type IN ('BASE TABLE', 'VIEW')\n",
    "\"\"\").df()\n",
    "if int(mv_exists[\"n\"].iloc[0]) == 0:\n",
    "    raise RuntimeError(f\"Missing {MODEL_VIEW}, run notebook 11 to recreate it\")\n",
    "\n",
    "mv_desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "mv_cols = set(mv_desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "scorelinked_col = None\n",
    "all_col = None\n",
    "if \"ST_Load_ScoreLinked_w\" in cols:\n",
    "    scorelinked_col = \"ST_Load_ScoreLinked_w\"\n",
    "if \"ST_Load_All_w\" in cols:\n",
    "    all_col = \"ST_Load_All_w\"\n",
    "\n",
    "need_join = (scorelinked_col is None) or (all_col is None)\n",
    "if need_join:\n",
    "    if \"ST_Load_ScoreLinked_w\" in mv_cols:\n",
    "        scorelinked_col = \"ST_Load_ScoreLinked_w\"\n",
    "    if \"ST_Load_All_w\" in mv_cols:\n",
    "        all_col = \"ST_Load_All_w\"\n",
    "\n",
    "if scorelinked_col is not None or all_col is not None:\n",
    "    join_cols = [SEASON_COL, WEEK_COL, TEAM_COL]\n",
    "    sel = [f\"a.*\"]\n",
    "    if scorelinked_col is not None and scorelinked_col not in cols:\n",
    "        sel.append(f\"b.{scorelinked_col} AS {scorelinked_col}\")\n",
    "    if all_col is not None and all_col not in cols:\n",
    "        sel.append(f\"b.{all_col} AS {all_col}\")\n",
    "\n",
    "    if len(sel) > 1:\n",
    "        df = con.execute(f\"\"\"\n",
    "        SELECT {\", \".join(sel)}\n",
    "        FROM df a\n",
    "        LEFT JOIN {MODEL_VIEW} b\n",
    "        ON a.{SEASON_COL} = b.{SEASON_COL}\n",
    "        AND a.{WEEK_COL} = b.{WEEK_COL}\n",
    "        AND a.{TEAM_COL} = b.{TEAM_COL}\n",
    "        \"\"\").df()\n",
    "\n",
    "def add_diag_prefix(load_col: str, prefix: str):\n",
    "    df[f\"load_{prefix}\"] = df[load_col].astype(float)\n",
    "\n",
    "    mean_prior = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.expanding().mean().shift(1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "    sd_prior = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.expanding().std(ddof=1).shift(1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "\n",
    "    z_prior = (df[f\"load_{prefix}\"] - mean_prior) / sd_prior\n",
    "    df[f\"shock_{prefix}\"] = (z_prior >= 1).fillna(False).astype(int)\n",
    "    df[f\"shock_x_blowout_{prefix}\"] = (df[f\"shock_{prefix}\"] * df[\"blowout_flag_w\"].fillna(0).astype(int)).astype(int)\n",
    "\n",
    "    df[f\"vol_{prefix}_s2d_prior\"] = sd_prior.fillna(0.0).astype(float)\n",
    "    df[f\"vol_{prefix}_roll4_prior\"] = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"load_{prefix}\"]\n",
    "        .apply(lambda s: s.shift(1).rolling(4, min_periods=2).std(ddof=1))\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "        .fillna(df[f\"vol_{prefix}_s2d_prior\"])\n",
    "        .astype(float)\n",
    "    )\n",
    "    df[f\"cum_shocks_{prefix}_prior\"] = (\n",
    "        df.groupby([TEAM_COL, SEASON_COL], sort=False)[f\"shock_{prefix}\"]\n",
    "        .cumsum()\n",
    "        .shift(1)\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "if scorelinked_col is not None and scorelinked_col in df.columns:\n",
    "    add_diag_prefix(scorelinked_col, \"scorelinked\")\n",
    "\n",
    "if all_col is not None and all_col in df.columns:\n",
    "    add_diag_prefix(all_col, \"all\")\n",
    "\n",
    "con.register(\"step18_model_frame_tmp\", df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step18_model_frame AS SELECT * FROM step18_model_frame_tmp\")\n",
    "con.unregister(\"step18_model_frame_tmp\")\n",
    "\n",
    "print(\"wrote duckdb table step18_model_frame\")\n",
    "print(\"rows\", len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
