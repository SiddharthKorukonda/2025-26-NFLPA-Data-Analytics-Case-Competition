{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eebc722f-3c8c-4d7a-be7a-b6d0d5f2570b",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses. We also load the preferred specs and the modeling frame, then confirm seasons are present and ordered so the split is chronological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a661b78-eed6-4a28-8f39-2c10e6aba0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in step18_model_frame 5950\n",
      "preferred specs\n",
      "  side         outcome   family                 spec_id  \\\n",
      "0  def  Inj_Def_Next_w  poisson  nonscore_roll4_no_lags   \n",
      "1  off  Inj_Off_Next_w  poisson  nonscore_roll4_no_lags   \n",
      "\n",
      "                                             formula           aic  \\\n",
      "0  Inj_Def_Next_w ~ shock_nonscore + shock_x_blow...  20805.188499   \n",
      "1  Inj_Off_Next_w ~ shock_nonscore + shock_x_blow...  20178.233429   \n",
      "\n",
      "            bic  \n",
      "0  22551.577735  \n",
      "1  21924.622665  \n",
      "seasons [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021] to [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "CWD = Path().resolve()\n",
    "DB_FILE = None\n",
    "for p in [CWD] + list(CWD.parents):\n",
    "    cand = p / \"db\" / \"nflpa.duckdb\"\n",
    "    if cand.exists():\n",
    "        DB_FILE = cand\n",
    "        break\n",
    "if DB_FILE is None:\n",
    "    for p in [CWD] + list(CWD.parents):\n",
    "        cand = p / \"nflpa.duckdb\"\n",
    "        if cand.exists():\n",
    "            DB_FILE = cand\n",
    "            break\n",
    "if DB_FILE is None:\n",
    "    raise RuntimeError(\"Could not find nflpa.duckdb\")\n",
    "\n",
    "con = duckdb.connect(str(DB_FILE), read_only=False)\n",
    "\n",
    "need = [\"step18_model_frame\", \"step18_preferred_model_specs\"]\n",
    "existing = set(con.execute(\"SHOW TABLES\").df()[\"name\"].astype(str).tolist())\n",
    "missing = [t for t in need if t not in existing]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing tables for step19, {missing}, run notebook 18 first\")\n",
    "\n",
    "df = con.execute(\"SELECT * FROM step18_model_frame\").df()\n",
    "pref = con.execute(\"SELECT * FROM step18_preferred_model_specs\").df()\n",
    "\n",
    "print(\"rows in step18_model_frame\", len(df))\n",
    "print(\"preferred specs\")\n",
    "print(pref)\n",
    "\n",
    "if \"season\" not in df.columns or \"week\" not in df.columns:\n",
    "    raise RuntimeError(\"Missing season or week in step18_model_frame\")\n",
    "\n",
    "seasons = sorted(df[\"season\"].dropna().astype(int).unique().tolist())\n",
    "print(\"seasons\", seasons[:10], \"to\", seasons[-10:])\n",
    "if len(seasons) < 3:\n",
    "    raise RuntimeError(\"Need at least 3 seasons for chronological cross validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d581265-196f-46c6-b335-3a953e2af6df",
   "metadata": {},
   "source": [
    "We define season based forward splits that train on earlier seasons and test on later seasons and avoid the common pitfall where season week fixed effects block prediction in unseen seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce0243e-729b-4ca1-9391-928b08c28353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv formula defense\n",
      "Inj_Def_Next_w ~ shock_nonscore + shock_x_blowout + vol_nonscore_roll4_prior + cum_shocks_nonscore_prior + short_week_flag_w + bye_last_week_flag_w + home_flag_w + blowout_flag_w + points_for + points_against + offensive_snaps_w + defensive ...\n",
      "cv formula offense\n",
      "Inj_Off_Next_w ~ shock_nonscore + shock_x_blowout + vol_nonscore_roll4_prior + cum_shocks_nonscore_prior + short_week_flag_w + bye_last_week_flag_w + home_flag_w + blowout_flag_w + points_for + points_against + offensive_snaps_w + defensive ...\n",
      "folds\n",
      "1 train up to 2022 test [2023]\n",
      "2 train up to 2023 test [2024]\n"
     ]
    }
   ],
   "source": [
    "TEAM_COL = \"team\" if \"team\" in df.columns else \"team_key\"\n",
    "\n",
    "if \"season_trend\" not in df.columns:\n",
    "    df[\"season_trend\"] = df[\"season\"].astype(int) - int(df[\"season\"].astype(int).min())\n",
    "\n",
    "if df[\"season_trend\"].isna().any():\n",
    "    raise RuntimeError(\"season_trend has missing values, check season column types\")\n",
    "\n",
    "def make_cv_formula(formula: str) -> str:\n",
    "    f = str(formula)\n",
    "\n",
    "    if \"C(season_week)\" in f:\n",
    "        f = f.replace(\"C(season_week)\", \"C(week) + season_trend\")\n",
    "\n",
    "    f = f.replace(\"C(season) + C(week)\", \"C(week) + season_trend\")\n",
    "    f = f.replace(\"C(week) + C(season)\", \"C(week) + season_trend\")\n",
    "\n",
    "    f = f.replace(\"+  C(week) + season_trend\", \"+ C(week) + season_trend\")\n",
    "    f = f.replace(\"+ C(week)  + season_trend\", \"+ C(week) + season_trend\")\n",
    "\n",
    "    return f\n",
    "\n",
    "pref_def = pref[pref[\"side\"] == \"def\"].iloc[0].to_dict()\n",
    "pref_off = pref[pref[\"side\"] == \"off\"].iloc[0].to_dict()\n",
    "\n",
    "cv_formula_def = make_cv_formula(pref_def[\"formula\"])\n",
    "cv_formula_off = make_cv_formula(pref_off[\"formula\"])\n",
    "\n",
    "print(\"cv formula defense\")\n",
    "print(cv_formula_def[:240], \"...\")\n",
    "\n",
    "print(\"cv formula offense\")\n",
    "print(cv_formula_off[:240], \"...\")\n",
    "\n",
    "N_TEST_SEASONS = 2\n",
    "test_seasons = seasons[-N_TEST_SEASONS:]\n",
    "folds = []\n",
    "for s in test_seasons:\n",
    "    train = [x for x in seasons if x < s]\n",
    "    test = [s]\n",
    "    folds.append({\"train_seasons\": train, \"test_seasons\": test})\n",
    "\n",
    "print(\"folds\")\n",
    "for i, f in enumerate(folds, start=1):\n",
    "    print(i, \"train up to\", max(f[\"train_seasons\"]), \"test\", f[\"test_seasons\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dde59f-2eb9-4f93-ab94-c4d3c657f405",
   "metadata": {},
   "source": [
    "We refit the main Models A and B on each training set and produce out of sample predictions on the test seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a59501-4052-4302-8a65-edea27b6a43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 train rows 4990 test rows 480\n",
      "fold 2 train rows 5470 test rows 480\n",
      "fold metrics\n",
      "   fold_id side         outcome   family  train_seasons_max  test_season  \\\n",
      "0        1  def  Inj_Def_Next_w  poisson               2022         2023   \n",
      "1        1  off  Inj_Off_Next_w  poisson               2022         2023   \n",
      "2        2  def  Inj_Def_Next_w  poisson               2023         2024   \n",
      "3        2  off  Inj_Off_Next_w  poisson               2023         2024   \n",
      "\n",
      "   n_train  n_test      loglik  loglik_per_obs       mae      rmse  fit_ok  \n",
      "0     4990     480 -889.030679       -1.852147  1.291938  1.616624       1  \n",
      "1     4990     480 -869.802797       -1.812089  1.266719  1.572176       1  \n",
      "2     5470     480 -902.416572       -1.880035  1.340095  1.673221       1  \n",
      "3     5470     480 -875.806401       -1.824597  1.263455  1.581088       1  \n",
      "coef rows 16\n"
     ]
    }
   ],
   "source": [
    "OUTCOME_DEF = str(pref_def[\"outcome\"])\n",
    "OUTCOME_OFF = str(pref_off[\"outcome\"])\n",
    "\n",
    "fam_def = str(pref_def[\"family\"])\n",
    "fam_off = str(pref_off[\"family\"])\n",
    "\n",
    "def fit_poisson(formula: str, data: pd.DataFrame):\n",
    "    m = smf.glm(formula=formula, data=data, family=sm.families.Poisson())\n",
    "    r = m.fit(maxiter=200, disp=0)\n",
    "    return r\n",
    "\n",
    "def fit_nb_discrete(formula: str, data: pd.DataFrame):\n",
    "    m = smf.negativebinomial(formula=formula, data=data)\n",
    "    r = m.fit(disp=False, maxiter=200)\n",
    "    return r\n",
    "\n",
    "def get_alpha_nb(res) -> float:\n",
    "    try:\n",
    "        if \"alpha\" in res.params.index:\n",
    "            return float(res.params.loc[\"alpha\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.nan\n",
    "\n",
    "def predict_mean(res, data: pd.DataFrame) -> np.ndarray:\n",
    "    mu = res.predict(data)\n",
    "    mu = np.asarray(mu, dtype=float)\n",
    "    mu = np.clip(mu, 1e-10, 1e12)\n",
    "    return mu\n",
    "\n",
    "def loglik_poisson(y: np.ndarray, mu: np.ndarray) -> float:\n",
    "    return float(stats.poisson.logpmf(y, mu).sum())\n",
    "\n",
    "def loglik_nb2(y: np.ndarray, mu: np.ndarray, alpha: float) -> float:\n",
    "    if not np.isfinite(alpha) or alpha <= 0:\n",
    "        return np.nan\n",
    "    n = 1.0 / alpha\n",
    "    p = n / (n + mu)\n",
    "    return float(stats.nbinom.logpmf(y, n, p).sum())\n",
    "\n",
    "def eval_metrics(y: np.ndarray, mu: np.ndarray) -> dict:\n",
    "    err = y - mu\n",
    "    mae = float(np.mean(np.abs(err)))\n",
    "    rmse = float(np.sqrt(np.mean(err ** 2)))\n",
    "    return {\"mae\": mae, \"rmse\": rmse}\n",
    "\n",
    "fold_metrics = []\n",
    "fold_coefs = []\n",
    "\n",
    "key_terms_hint = [\n",
    "    \"shock_nonscore\",\n",
    "    \"shock_x_blowout\",\n",
    "    \"vol_nonscore_s2d_prior\",\n",
    "    \"vol_nonscore_roll4_prior\",\n",
    "    \"cum_shocks_nonscore_prior\",\n",
    "    \"ST_Shock_NonScore_w_minus_1\",\n",
    "    \"ST_Shock_NonScore_w_minus_2\",\n",
    "    \"ST_Shock_NonScore_w_minus_3\",\n",
    "]\n",
    "\n",
    "for fold_id, f in enumerate(folds, start=1):\n",
    "    train_df = df[df[\"season\"].astype(int).isin(f[\"train_seasons\"])].copy()\n",
    "    test_df = df[df[\"season\"].astype(int).isin(f[\"test_seasons\"])].copy()\n",
    "\n",
    "    if len(train_df) == 0 or len(test_df) == 0:\n",
    "        raise RuntimeError(\"Empty train or test fold, check season filtering\")\n",
    "\n",
    "    print(\"fold\", fold_id, \"train rows\", len(train_df), \"test rows\", len(test_df))\n",
    "\n",
    "    res_def = None\n",
    "    res_off = None\n",
    "\n",
    "    try:\n",
    "        if fam_def == \"poisson\":\n",
    "            res_def = fit_poisson(cv_formula_def, train_df)\n",
    "        else:\n",
    "            res_def = fit_nb_discrete(cv_formula_def, train_df)\n",
    "    except Exception as e:\n",
    "        print(\"defense fit failed fold\", fold_id, str(e))\n",
    "\n",
    "    try:\n",
    "        if fam_off == \"poisson\":\n",
    "            res_off = fit_poisson(cv_formula_off, train_df)\n",
    "        else:\n",
    "            res_off = fit_nb_discrete(cv_formula_off, train_df)\n",
    "    except Exception as e:\n",
    "        print(\"offense fit failed fold\", fold_id, str(e))\n",
    "\n",
    "    def record(side: str, outcome: str, res, fam: str, formula: str):\n",
    "        if res is None:\n",
    "            fold_metrics.append({\n",
    "                \"fold_id\": fold_id,\n",
    "                \"side\": side,\n",
    "                \"outcome\": outcome,\n",
    "                \"family\": fam,\n",
    "                \"train_seasons_max\": int(max(f[\"train_seasons\"])),\n",
    "                \"test_season\": int(f[\"test_seasons\"][0]),\n",
    "                \"n_train\": int(len(train_df)),\n",
    "                \"n_test\": int(len(test_df)),\n",
    "                \"loglik\": np.nan,\n",
    "                \"loglik_per_obs\": np.nan,\n",
    "                \"mae\": np.nan,\n",
    "                \"rmse\": np.nan,\n",
    "                \"fit_ok\": 0,\n",
    "            })\n",
    "            return\n",
    "\n",
    "        y = test_df[outcome].astype(int).to_numpy()\n",
    "        mu = predict_mean(res, test_df)\n",
    "\n",
    "        if fam == \"poisson\":\n",
    "            ll = loglik_poisson(y, mu)\n",
    "        else:\n",
    "            alpha = get_alpha_nb(res)\n",
    "            ll = loglik_nb2(y, mu, alpha)\n",
    "\n",
    "        mets = eval_metrics(y.astype(float), mu)\n",
    "\n",
    "        fold_metrics.append({\n",
    "            \"fold_id\": fold_id,\n",
    "            \"side\": side,\n",
    "            \"outcome\": outcome,\n",
    "            \"family\": fam,\n",
    "            \"train_seasons_max\": int(max(f[\"train_seasons\"])),\n",
    "            \"test_season\": int(f[\"test_seasons\"][0]),\n",
    "            \"n_train\": int(len(train_df)),\n",
    "            \"n_test\": int(len(test_df)),\n",
    "            \"loglik\": float(ll) if np.isfinite(ll) else np.nan,\n",
    "            \"loglik_per_obs\": float(ll) / float(len(y)) if np.isfinite(ll) else np.nan,\n",
    "            \"mae\": mets[\"mae\"],\n",
    "            \"rmse\": mets[\"rmse\"],\n",
    "            \"fit_ok\": 1,\n",
    "        })\n",
    "\n",
    "        params = res.params.copy()\n",
    "        for term in key_terms_hint:\n",
    "            if term in params.index:\n",
    "                fold_coefs.append({\n",
    "                    \"fold_id\": fold_id,\n",
    "                    \"side\": side,\n",
    "                    \"outcome\": outcome,\n",
    "                    \"term\": term,\n",
    "                    \"beta\": float(params.loc[term]),\n",
    "                    \"train_seasons_max\": int(max(f[\"train_seasons\"])),\n",
    "                    \"test_season\": int(f[\"test_seasons\"][0]),\n",
    "                })\n",
    "\n",
    "    record(\"def\", OUTCOME_DEF, res_def, fam_def, cv_formula_def)\n",
    "    record(\"off\", OUTCOME_OFF, res_off, fam_off, cv_formula_off)\n",
    "\n",
    "metrics_df = pd.DataFrame(fold_metrics)\n",
    "coefs_df = pd.DataFrame(fold_coefs)\n",
    "\n",
    "print(\"fold metrics\")\n",
    "print(metrics_df)\n",
    "print(\"coef rows\", len(coefs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2a0f5-6b1c-4d78-abee-37be36fd1b2f",
   "metadata": {},
   "source": [
    "We compute stability checks on the key 'NonScore' exposure terms across time and then summarize sign consistency and magnitude drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e2af73-6e7f-4bee-894e-11177c090107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loglik per obs by side\n",
      "  side  loglik_per_obs\n",
      "0  def       -1.866091\n",
      "1  off       -1.818343\n",
      "coefficient stability summary\n",
      "  side                       term  n_folds  mean_beta   sd_beta  min_beta  \\\n",
      "0  def  cum_shocks_nonscore_prior        2   0.010980  0.002695  0.009074   \n",
      "1  def             shock_nonscore        2   0.019110  0.012595  0.010204   \n",
      "2  def            shock_x_blowout        2   0.027231  0.004986  0.023706   \n",
      "3  def   vol_nonscore_roll4_prior        2  -0.013457  0.000761 -0.013995   \n",
      "4  off  cum_shocks_nonscore_prior        2  -0.009058  0.000099 -0.009128   \n",
      "5  off             shock_nonscore        2   0.019672  0.013710  0.009978   \n",
      "6  off            shock_x_blowout        2   0.098328  0.007478  0.093040   \n",
      "7  off   vol_nonscore_roll4_prior        2   0.018144  0.003301  0.015810   \n",
      "\n",
      "   max_beta  sign_consistency  \n",
      "0  0.012886               1.0  \n",
      "1  0.028015               1.0  \n",
      "2  0.030757               1.0  \n",
      "3 -0.012919               1.0  \n",
      "4 -0.008988               1.0  \n",
      "5  0.029366               1.0  \n",
      "6  0.103615               1.0  \n",
      "7  0.020479               1.0  \n"
     ]
    }
   ],
   "source": [
    "metrics_df = metrics_df.copy()\n",
    "coefs_df = coefs_df.copy()\n",
    "\n",
    "print(\"mean loglik per obs by side\")\n",
    "print(\n",
    "    metrics_df.groupby(\"side\", dropna=False)[\"loglik_per_obs\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "if len(coefs_df) == 0:\n",
    "    raise RuntimeError(\"No coefficient rows captured, this usually means key terms are missing from the fitted formulas\")\n",
    "\n",
    "stability = (\n",
    "    coefs_df\n",
    "    .groupby([\"side\", \"term\"], dropna=False)\n",
    "    .agg(\n",
    "        n_folds=(\"beta\", \"count\"),\n",
    "        mean_beta=(\"beta\", \"mean\"),\n",
    "        sd_beta=(\"beta\", \"std\"),\n",
    "        min_beta=(\"beta\", \"min\"),\n",
    "        max_beta=(\"beta\", \"max\"),\n",
    "        sign_consistency=(\"beta\", lambda x: float((np.sign(x) == np.sign(x.iloc[0])).mean()) if len(x) > 0 else np.nan),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"coefficient stability summary\")\n",
    "print(stability.sort_values([\"side\", \"term\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3a085-bcc9-4d10-b01a-de03f7755d44",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the exposure signs match the full sample direction and that predictive performance does not collapse in later seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9c0251-4756-4ddf-bb5d-2ff8e84933e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preferred full sample specs\n",
      "  side                 spec_id   family           aic           bic\n",
      "0  def  nonscore_roll4_no_lags  poisson  20805.188499  22551.577735\n",
      "1  off  nonscore_roll4_no_lags  poisson  20178.233429  21924.622665\n",
      "bad folds count 0\n",
      "loglik per obs range by side\n",
      "  side       min       max      mean\n",
      "0  def -1.880035 -1.852147 -1.866091\n",
      "1  off -1.824597 -1.812089 -1.818343\n",
      "shock term estimates by fold\n",
      "   fold_id side         outcome             term      beta  train_seasons_max  \\\n",
      "0        1  def  Inj_Def_Next_w   shock_nonscore  0.010204               2022   \n",
      "1        1  def  Inj_Def_Next_w  shock_x_blowout  0.030757               2022   \n",
      "2        2  def  Inj_Def_Next_w   shock_nonscore  0.028015               2023   \n",
      "3        2  def  Inj_Def_Next_w  shock_x_blowout  0.023706               2023   \n",
      "4        1  off  Inj_Off_Next_w   shock_nonscore  0.029366               2022   \n",
      "5        1  off  Inj_Off_Next_w  shock_x_blowout  0.093040               2022   \n",
      "6        2  off  Inj_Off_Next_w   shock_nonscore  0.009978               2023   \n",
      "7        2  off  Inj_Off_Next_w  shock_x_blowout  0.103615               2023   \n",
      "\n",
      "   test_season  \n",
      "0         2023  \n",
      "1         2023  \n",
      "2         2024  \n",
      "3         2024  \n",
      "4         2023  \n",
      "5         2023  \n",
      "6         2024  \n",
      "7         2024  \n"
     ]
    }
   ],
   "source": [
    "pref_full = con.execute(\"SELECT * FROM step18_preferred_model_specs\").df()\n",
    "print(\"preferred full sample specs\")\n",
    "print(pref_full[[\"side\", \"spec_id\", \"family\", \"aic\", \"bic\"]])\n",
    "\n",
    "bad_folds = metrics_df[(metrics_df[\"fit_ok\"] == 0) | (metrics_df[\"loglik_per_obs\"].isna())]\n",
    "print(\"bad folds count\", len(bad_folds))\n",
    "if len(bad_folds) > 0:\n",
    "    print(bad_folds)\n",
    "\n",
    "print(\"loglik per obs range by side\")\n",
    "print(metrics_df.groupby(\"side\")[\"loglik_per_obs\"].agg([\"min\", \"max\", \"mean\"]).reset_index())\n",
    "\n",
    "shock_terms = coefs_df[coefs_df[\"term\"].isin([\"shock_nonscore\", \"shock_x_blowout\"])].copy()\n",
    "print(\"shock term estimates by fold\")\n",
    "print(shock_terms.sort_values([\"side\", \"fold_id\", \"term\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d77275-c6e4-445b-b714-7b88066e17aa",
   "metadata": {},
   "source": [
    "We export cross validation metrics and coefficient stability tables to DuckDB and to outputs csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19346b0-d1af-4e22-ba29-e8415de3d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote duckdb table step19_time_cv_metrics\n",
      "wrote duckdb table step19_time_cv_coefficients\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step19_time_cv_metrics.csv\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step19_time_cv_coefficients.csv\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step19_time_cv_stability_summary.csv\n"
     ]
    }
   ],
   "source": [
    "con.register(\"step19_metrics_tmp\", metrics_df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step19_time_cv_metrics AS SELECT * FROM step19_metrics_tmp\")\n",
    "con.unregister(\"step19_metrics_tmp\")\n",
    "\n",
    "con.register(\"step19_coefs_tmp\", coefs_df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step19_time_cv_coefficients AS SELECT * FROM step19_coefs_tmp\")\n",
    "con.unregister(\"step19_coefs_tmp\")\n",
    "\n",
    "out_dir = Path(\"../outputs\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "m_csv = out_dir / \"step19_time_cv_metrics.csv\"\n",
    "c_csv = out_dir / \"step19_time_cv_coefficients.csv\"\n",
    "s_csv = out_dir / \"step19_time_cv_stability_summary.csv\"\n",
    "\n",
    "metrics_df.to_csv(m_csv, index=False)\n",
    "coefs_df.to_csv(c_csv, index=False)\n",
    "stability.to_csv(s_csv, index=False)\n",
    "\n",
    "print(\"wrote duckdb table step19_time_cv_metrics\")\n",
    "print(\"wrote duckdb table step19_time_cv_coefficients\")\n",
    "print(\"wrote csv\", m_csv.resolve())\n",
    "print(\"wrote csv\", c_csv.resolve())\n",
    "print(\"wrote csv\", s_csv.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
