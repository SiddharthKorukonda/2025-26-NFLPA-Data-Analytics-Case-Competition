{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2324abe-75ba-48c3-b62f-2977bd4406e6",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a384e-072d-4d8a-afb8-6663463e37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cwd = Path.cwd()\n",
    "\n",
    "root = None\n",
    "for p in [cwd] + list(cwd.parents):\n",
    "    if (p / \"db\").exists():\n",
    "        root = p\n",
    "        break\n",
    "\n",
    "if root is None:\n",
    "    raise FileNotFoundError(\"Could not find a db folder above the current working directory\")\n",
    "\n",
    "DB_PATH = root / \"db\" / \"nflpa.duckdb\"\n",
    "print(\"Using DB_PATH\", DB_PATH)\n",
    "\n",
    "con = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "con.execute(\"PRAGMA threads=4\")\n",
    "con.execute(\"PRAGMA memory_limit='4GB'\")\n",
    "\n",
    "print(con.execute(\"SELECT COUNT(*) AS rows FROM team_week_panel\").df())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a850a79-cd91-4464-987d-0a7cc9ca6769",
   "metadata": {},
   "source": [
    "We confirm that the 'team_week_panel' table, which houses our rows keyed by season, week, and team ID, is physically present in the workspace, sets the team and abbreviation columns to match the configuration used for gathering raw data and building the panel, and also loads the necessary utility functions for the PCA preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119fb5d-e377-4c3b-be9f-dd0d2e0a709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = set(con.execute(\"SHOW TABLES\").df()[\"name\"].tolist())\n",
    "\n",
    "if \"team_week_panel\" not in tables:\n",
    "    raise RuntimeError(\"team_week_panel missing, run notebooks 01 through 07 first\")\n",
    "\n",
    "panel_cols = con.execute(\"PRAGMA table_info('team_week_panel')\").df()\n",
    "panel_cols_list = panel_cols[\"name\"].tolist()\n",
    "panel_cols_set = set(panel_cols_list)\n",
    "\n",
    "TEAM_COL = \"team_id\" if \"team_id\" in panel_cols_set else \"team\"\n",
    "TEAM_ABBR_COL = \"team\" if \"team\" in panel_cols_set else TEAM_COL\n",
    "\n",
    "print(\"Using TEAM_COL\", TEAM_COL)\n",
    "print(\"Using TEAM_ABBR_COL\", TEAM_ABBR_COL)\n",
    "\n",
    "def _existing_cols(table_name):\n",
    "    return set(con.execute(f\"PRAGMA table_info('{table_name}')\").df()[\"name\"].tolist())\n",
    "\n",
    "def _star_excluding(table_name, alias, cols_to_maybe_exclude):\n",
    "    existing = _existing_cols(table_name)\n",
    "    keep = [c for c in cols_to_maybe_exclude if c in existing]\n",
    "    if keep:\n",
    "        return f\"{alias}.* EXCLUDE ({', '.join(keep)})\"\n",
    "    return f\"{alias}.*\"\n",
    "\n",
    "print(\"team\" in panel_cols_set, \"team_id\" in panel_cols_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0120b6-a1da-4863-a00f-934cc2e90fc2",
   "metadata": {},
   "source": [
    "We define the exact set of cumulative and per-game workload columns that will feed into the PCA, and also performs a strict validation check against the 'team_week_panel' to ensure all previously persisted data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c39f2-8d9b-429f-939e-bf0dec97dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_inputs = [\n",
    "    \"cum_off_snaps_w\",\n",
    "    \"cum_def_snaps_w\",\n",
    "    \"cum_ST_Load_w\",\n",
    "    \"cum_short_weeks_w\",\n",
    "    \"cum_long_travel_w\",\n",
    "    \"cum_timezone_changes_w\",\n",
    "    \"cum_west_to_east_w\",\n",
    "    \"cum_total_snaps_w\",\n",
    "    \"cum_rest_deficit_days_w\",\n",
    "    \"cum_away_games_w\",\n",
    "    \"cum_byes_w\",\n",
    "]\n",
    "\n",
    "cols_now = _existing_cols(\"team_week_panel\")\n",
    "\n",
    "missing_required = [c for c in required_inputs if c not in cols_now]\n",
    "print(\"Missing required inputs\", missing_required)\n",
    "\n",
    "if missing_required:\n",
    "    raise RuntimeError(\n",
    "        \"Step 8 cannot run because required cumulative columns are missing, missing are \"\n",
    "        + \", \".join(missing_required)\n",
    "    )\n",
    "\n",
    "pca_inputs = required_inputs\n",
    "\n",
    "print(\"Final PCA input columns used\", pca_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee426c8-5962-4133-93ee-0960768632c9",
   "metadata": {},
   "source": [
    "We pull the PCA inputs into pandas, verifies that each team-week has a unique index to prevent data leakage, handles any missing values through imputation or zero-filling, and then standardizes each variable across the entire dataset to prepare for the Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f394704-201d-4160-bc09-8145d399065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.execute(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "      season,\n",
    "      week,\n",
    "      {TEAM_ABBR_COL} AS team_key,\n",
    "      {\", \".join(pca_inputs)}\n",
    "    FROM team_week_panel\n",
    "    \"\"\"\n",
    ").df()\n",
    "\n",
    "if df.duplicated(subset=[\"season\", \"week\", \"team_key\"]).any():\n",
    "    n_dup = int(df.duplicated(subset=[\"season\", \"week\", \"team_key\"]).sum())\n",
    "    raise RuntimeError(f\"Duplicate keys found in extracted panel, duplicates {n_dup}\")\n",
    "\n",
    "for c in pca_inputs:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "missing_rates = df[pca_inputs].isna().mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"Missing rate per input\")\n",
    "print(missing_rates)\n",
    "\n",
    "df[pca_inputs] = df[pca_inputs].fillna(0.0)\n",
    "\n",
    "means = df[pca_inputs].mean(axis=0)\n",
    "sds = df[pca_inputs].std(axis=0, ddof=0)\n",
    "\n",
    "zero_sd = [c for c in pca_inputs if float(sds[c]) == 0.0 or np.isclose(float(sds[c]), 0.0)]\n",
    "use_inputs = [c for c in pca_inputs if c not in zero_sd]\n",
    "\n",
    "print(\"Zero standard deviation inputs dropped\", zero_sd)\n",
    "print(\"Inputs used after drop\", use_inputs)\n",
    "\n",
    "if len(use_inputs) < 3:\n",
    "    raise RuntimeError(\"Too few usable inputs for PCA after dropping zero variance columns\")\n",
    "\n",
    "Z = (df[use_inputs] - means[use_inputs]) / sds[use_inputs]\n",
    "Z = Z.replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "\n",
    "print(\"Z shape\", Z.shape)\n",
    "print(Z.mean().sort_values())\n",
    "print(Z.std(ddof=0).sort_values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
