{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea49f9fa-c76e-437c-bdd1-346ef7fe1b91",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c4bae1-db0f-4171-a1af-574d6e26c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "candidates = []\n",
    "search_roots = [\n",
    "    Path(\".\"),\n",
    "    Path(\"..\"),\n",
    "    Path(\"./data\"),\n",
    "    Path(\"../data\"),\n",
    "    Path(\"../../data\"),\n",
    "]\n",
    "\n",
    "for root in search_roots:\n",
    "    if root.exists():\n",
    "        candidates.extend(list(root.glob(\"nflpa.duckdb\")))\n",
    "        candidates.extend(list(root.glob(\"**/nflpa.duckdb\")))\n",
    "\n",
    "seen = set()\n",
    "duckdb_files = []\n",
    "for f in candidates:\n",
    "    fp = str(f.resolve())\n",
    "    if fp not in seen:\n",
    "        seen.add(fp)\n",
    "        duckdb_files.append(f.resolve())\n",
    "\n",
    "print(\"nflpa.duckdb candidates found\", len(duckdb_files))\n",
    "for i, f in enumerate(duckdb_files[:25]):\n",
    "    print(i, f)\n",
    "\n",
    "if not duckdb_files:\n",
    "    raise RuntimeError(\"No nflpa.duckdb found near this notebook, run notebook 00 or check where you saved the database\")\n",
    "\n",
    "DB_PATH = duckdb_files[0]\n",
    "print(\"using DB_PATH\", DB_PATH)\n",
    "\n",
    "con = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_tables\n",
    "FROM (SHOW TABLES)\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb51c571-b21f-4148-a2af-cbacc87e5729",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the specialized database view has been successfully materialized and that it contains the complete set of features required for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a2404-0518-4a81-be22-c1395ec5f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEASON_COL = \"season\"\n",
    "WEEK_COL = \"week\"\n",
    "TEAM_COL = \"team\"\n",
    "\n",
    "PANEL_TABLE = \"team_week_panel\"\n",
    "MODEL_VIEW = \"team_week_panel_nextweek_model\"\n",
    "\n",
    "con.execute(\"DROP TABLE IF EXISTS panel_next_week_flags\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE TABLE panel_next_week_flags AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    {SEASON_COL} AS season,\n",
    "    {WEEK_COL} AS week,\n",
    "    CAST({TEAM_COL} AS VARCHAR) AS team_key\n",
    "  FROM {PANEL_TABLE}\n",
    "),\n",
    "nxt AS (\n",
    "  SELECT\n",
    "    {SEASON_COL} AS season,\n",
    "    {WEEK_COL} AS week,\n",
    "    CAST({TEAM_COL} AS VARCHAR) AS team_key\n",
    "  FROM {PANEL_TABLE}\n",
    ")\n",
    "SELECT\n",
    "  b.season,\n",
    "  b.week,\n",
    "  b.team_key,\n",
    "  CASE WHEN n.week IS NULL THEN 0 ELSE 1 END AS has_next_week\n",
    "FROM base b\n",
    "LEFT JOIN nxt n\n",
    "  ON n.season = b.season\n",
    " AND n.team_key = b.team_key\n",
    " AND n.week = b.week + 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"DROP VIEW IF EXISTS {MODEL_VIEW}\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW {MODEL_VIEW} AS\n",
    "SELECT\n",
    "  p.*,\n",
    "  f.has_next_week\n",
    "FROM {PANEL_TABLE} p\n",
    "JOIN panel_next_week_flags f\n",
    "  ON f.season = p.{SEASON_COL}\n",
    " AND f.week = p.{WEEK_COL}\n",
    " AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "WHERE f.has_next_week = 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows_model,\n",
    "  COUNT(DISTINCT {SEASON_COL} || '-' || {WEEK_COL} || '-' || CAST({TEAM_COL} AS VARCHAR)) AS distinct_keys_model\n",
    "FROM {MODEL_VIEW}\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ab6d9-6c2f-48b5-915a-eba7b4a20d4b",
   "metadata": {},
   "source": [
    "We compute overall mean and variance for next week offensive and defensive injury outcomes and also adds basic distribution stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887188f9-6868-4774-9126-489b1c116994",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_summary = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  AVG(CAST(Inj_Off_Next_w AS DOUBLE)) AS mean_inj_off_next,\n",
    "  VAR_POP(CAST(Inj_Off_Next_w AS DOUBLE)) AS var_inj_off_next,\n",
    "  MIN(CAST(Inj_Off_Next_w AS DOUBLE)) AS min_inj_off_next,\n",
    "  approx_quantile(CAST(Inj_Off_Next_w AS DOUBLE), 0.25) AS p25_inj_off_next,\n",
    "  approx_quantile(CAST(Inj_Off_Next_w AS DOUBLE), 0.50) AS p50_inj_off_next,\n",
    "  approx_quantile(CAST(Inj_Off_Next_w AS DOUBLE), 0.75) AS p75_inj_off_next,\n",
    "  MAX(CAST(Inj_Off_Next_w AS DOUBLE)) AS max_inj_off_next,\n",
    "\n",
    "  AVG(CAST(Inj_Def_Next_w AS DOUBLE)) AS mean_inj_def_next,\n",
    "  VAR_POP(CAST(Inj_Def_Next_w AS DOUBLE)) AS var_inj_def_next,\n",
    "  MIN(CAST(Inj_Def_Next_w AS DOUBLE)) AS min_inj_def_next,\n",
    "  approx_quantile(CAST(Inj_Def_Next_w AS DOUBLE), 0.25) AS p25_inj_def_next,\n",
    "  approx_quantile(CAST(Inj_Def_Next_w AS DOUBLE), 0.50) AS p50_inj_def_next,\n",
    "  approx_quantile(CAST(Inj_Def_Next_w AS DOUBLE), 0.75) AS p75_inj_def_next,\n",
    "  MAX(CAST(Inj_Def_Next_w AS DOUBLE)) AS max_inj_def_next\n",
    "FROM {MODEL_VIEW}\n",
    "\"\"\").df()\n",
    "\n",
    "inj_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef57e2f-c44b-418e-89e6-d30ba180e925",
   "metadata": {},
   "source": [
    "We compute distribution summaries for special teams load measures for All, ScoreLinked, and NonScore, and create a long table to keep the stats consistent across buckets and makes comparisons easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d78aca-c6d7-406c-9a25-669a278f8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS step12_st_load_summary\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE TABLE step12_st_load_summary AS\n",
    "WITH long AS (\n",
    "  SELECT '{'ST_Load_All_w'}' AS metric, CAST(ST_Load_All_w AS DOUBLE) AS x FROM {MODEL_VIEW}\n",
    "  UNION ALL\n",
    "  SELECT '{'ST_Load_ScoreLinked_w'}' AS metric, CAST(ST_Load_ScoreLinked_w AS DOUBLE) AS x FROM {MODEL_VIEW}\n",
    "  UNION ALL\n",
    "  SELECT '{'ST_Load_NonScore_w'}' AS metric, CAST(ST_Load_NonScore_w AS DOUBLE) AS x FROM {MODEL_VIEW}\n",
    ")\n",
    "SELECT\n",
    "  metric,\n",
    "  COUNT(*) AS n_rows,\n",
    "  AVG(x) AS mean_x,\n",
    "  VAR_POP(x) AS var_x,\n",
    "  MIN(x) AS min_x,\n",
    "  approx_quantile(x, 0.25) AS p25_x,\n",
    "  approx_quantile(x, 0.50) AS p50_x,\n",
    "  approx_quantile(x, 0.75) AS p75_x,\n",
    "  MAX(x) AS max_x\n",
    "FROM long\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"SELECT * FROM step12_st_load_summary ORDER BY metric\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140919a-2d25-43c0-bbbb-34d0057ce126",
   "metadata": {},
   "source": [
    "We compute distribution summaries for special teams volatility measures for All, ScoreLinked, and NonScore, using the same table format as loads in order to help spot whether volatility is sparse or concentrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446bc37-f6be-4f28-9a41-bac7ec4362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS step12_st_vol_summary\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE TABLE step12_st_vol_summary AS\n",
    "WITH long AS (\n",
    "  SELECT '{'ST_Vol_All_w'}' AS metric, CAST(ST_Vol_All_w AS DOUBLE) AS x FROM {MODEL_VIEW}\n",
    "  UNION ALL\n",
    "  SELECT '{'ST_Vol_ScoreLinked_w'}' AS metric, CAST(ST_Vol_ScoreLinked_w AS DOUBLE) AS x FROM {MODEL_VIEW}\n",
    "  UNION ALL\n",
    "  SELECT '{'ST_Vol_NonScore_w'}' AS metric, CAST(ST_Vol_NonScore_w AS DOUBLE) AS x FROM {MODEL_VIEW}\n",
    ")\n",
    "SELECT\n",
    "  metric,\n",
    "  COUNT(*) AS n_rows,\n",
    "  AVG(x) AS mean_x,\n",
    "  VAR_POP(x) AS var_x,\n",
    "  MIN(x) AS min_x,\n",
    "  approx_quantile(x, 0.25) AS p25_x,\n",
    "  approx_quantile(x, 0.50) AS p50_x,\n",
    "  approx_quantile(x, 0.75) AS p75_x,\n",
    "  MAX(x) AS max_x\n",
    "FROM long\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"SELECT * FROM step12_st_vol_summary ORDER BY metric\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650450a7-771b-42a5-b667-e18d04b259b0",
   "metadata": {},
   "source": [
    "We compute the proportion of weeks flagged as shock weeks for each shock definition and include the raw counts for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deacaed-7c5b-4bba-b5f3-2755bab75762",
   "metadata": {},
   "outputs": [],
   "source": [
    "shock_props = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(CAST(ST_Shock_All_w AS BIGINT)) AS n_shock_all,\n",
    "  AVG(CAST(ST_Shock_All_w AS DOUBLE)) AS p_shock_all,\n",
    "  SUM(CAST(ST_Shock_ScoreLinked_w AS BIGINT)) AS n_shock_scorelinked,\n",
    "  AVG(CAST(ST_Shock_ScoreLinked_w AS DOUBLE)) AS p_shock_scorelinked,\n",
    "  SUM(CAST(ST_Shock_NonScore_w AS BIGINT)) AS n_shock_nonscore,\n",
    "  AVG(CAST(ST_Shock_NonScore_w AS DOUBLE)) AS p_shock_nonscore\n",
    "FROM {MODEL_VIEW}\n",
    "\"\"\").df()\n",
    "\n",
    "shock_props"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
