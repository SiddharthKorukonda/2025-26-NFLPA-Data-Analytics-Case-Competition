{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d842573f-1064-4678-b8f8-18ef317dbd29",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd3ce4d-791f-46b1-b270-f2248c960672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected db /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/db/nflpa.duckdb\n",
      "model view team_week_panel_nextweek_model\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, HessianInversionWarning\n",
    "\n",
    "try:\n",
    "    import statsmodels.genmod.generalized_linear_model as glm\n",
    "    glm.SET_USE_BIC_LLF(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"The bic value is computed using the deviance formula.*\",\n",
    ")\n",
    "\n",
    "CWD = Path().resolve()\n",
    "\n",
    "REPO_ROOT = None\n",
    "DB_FILE = None\n",
    "\n",
    "for p in [CWD] + list(CWD.parents):\n",
    "    cand = p / \"db\" / \"nflpa.duckdb\"\n",
    "    if cand.exists():\n",
    "        REPO_ROOT = p\n",
    "        DB_FILE = cand\n",
    "        break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    for p in [CWD] + list(CWD.parents):\n",
    "        cand = p / \"nflpa.duckdb\"\n",
    "        if cand.exists():\n",
    "            REPO_ROOT = p\n",
    "            DB_FILE = cand\n",
    "            break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    raise RuntimeError(\"Could not find nflpa.duckdb, expected db/nflpa.duckdb or nflpa.duckdb near this notebook\")\n",
    "\n",
    "con = duckdb.connect(str(DB_FILE), read_only=False)\n",
    "\n",
    "MODEL_VIEW = \"team_week_panel_nextweek_model\"\n",
    "\n",
    "exists_df = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name = '{MODEL_VIEW}'\n",
    "  AND table_type IN ('BASE TABLE', 'VIEW')\n",
    "\"\"\").df()\n",
    "\n",
    "if int(exists_df[\"n\"].iloc[0]) == 0:\n",
    "    raise RuntimeError(f\"Missing {MODEL_VIEW}, run notebook 11 to create the model view\")\n",
    "\n",
    "print(\"connected db\", str(DB_FILE))\n",
    "print(\"model view\", MODEL_VIEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217dcaa-d6eb-4800-a595-e095e5b586a2",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the modeling view only contains next week eligible rows, has non null offensive and defensive outcomes, and has unique team week keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0959b75-5ed8-471a-ac25-7787d9a4993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dup_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dup_rows\n",
       "0         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows_model,\n",
    "  SUM(CASE WHEN has_next_week != 1 THEN 1 ELSE 0 END) AS bad_has_next_week,\n",
    "  SUM(CASE WHEN Inj_Def_Next_w IS NULL THEN 1 ELSE 0 END) AS null_outcome_def,\n",
    "  SUM(CASE WHEN Inj_Off_Next_w IS NULL THEN 1 ELSE 0 END) AS null_outcome_off\n",
    "FROM {MODEL_VIEW}\n",
    "\"\"\").df()\n",
    "\n",
    "desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "if \"team\" in cols:\n",
    "    TEAM_COL = \"team\"\n",
    "elif \"team_key\" in cols:\n",
    "    TEAM_COL = \"team_key\"\n",
    "else:\n",
    "    raise RuntimeError(f\"No team id column found in {MODEL_VIEW}, expected team or team_key\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS dup_rows\n",
    "FROM (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    {TEAM_COL} AS team_any,\n",
    "    COUNT(*) AS n\n",
    "  FROM {MODEL_VIEW}\n",
    "  GROUP BY 1,2,3\n",
    "  HAVING COUNT(*) > 1\n",
    ")\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f7bf1-36ee-479f-8ddc-9efd6db1b869",
   "metadata": {},
   "source": [
    "We build a single, clean modeling frame table with robust column detection, consistent names, and consistent missing value handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5f7291-8696-4b28-8243-7e974c0f5a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before dropna 5950\n",
      "rows after dropna 5950\n",
      "wrote duckdb table step16_modeling_frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>team</th>\n",
       "      <th>Inj_Def_Next_w</th>\n",
       "      <th>Inj_Off_Next_w</th>\n",
       "      <th>Inj_Def_Last_w</th>\n",
       "      <th>Inj_Off_Last_w</th>\n",
       "      <th>blowout_flag_w</th>\n",
       "      <th>short_week_flag_w</th>\n",
       "      <th>bye_last_week_flag_w</th>\n",
       "      <th>...</th>\n",
       "      <th>ST_Shock_NonScore_w_minus_2</th>\n",
       "      <th>ST_Shock_NonScore_w_minus_3</th>\n",
       "      <th>points_for</th>\n",
       "      <th>points_against</th>\n",
       "      <th>score_diff_w</th>\n",
       "      <th>off_yards_per_play_w</th>\n",
       "      <th>Cumulative_Workload_Index_w</th>\n",
       "      <th>season_week</th>\n",
       "      <th>shock_nonscore</th>\n",
       "      <th>shock_x_blowout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>6.836364</td>\n",
       "      <td>-3.940011</td>\n",
       "      <td>201201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>4.412698</td>\n",
       "      <td>-3.638251</td>\n",
       "      <td>201202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>5.565217</td>\n",
       "      <td>-2.938346</td>\n",
       "      <td>201203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  week team  Inj_Def_Next_w  Inj_Off_Next_w  Inj_Def_Last_w  \\\n",
       "0    2012     1  ATL             2.0             2.0             0.0   \n",
       "1    2012     2  ATL             3.0             2.0             2.0   \n",
       "2    2012     3  ATL             2.0             2.0             3.0   \n",
       "\n",
       "   Inj_Off_Last_w  blowout_flag_w  short_week_flag_w  bye_last_week_flag_w  \\\n",
       "0             0.0               1                  0                     0   \n",
       "1             2.0               0                  0                     0   \n",
       "2             2.0               1                  0                     0   \n",
       "\n",
       "   ...  ST_Shock_NonScore_w_minus_2  ST_Shock_NonScore_w_minus_3  points_for  \\\n",
       "0  ...                            0                            0          40   \n",
       "1  ...                            0                            0          27   \n",
       "2  ...                            0                            0          27   \n",
       "\n",
       "   points_against  score_diff_w  off_yards_per_play_w  \\\n",
       "0              24            16              6.836364   \n",
       "1              21             6              4.412698   \n",
       "2               3            24              5.565217   \n",
       "\n",
       "   Cumulative_Workload_Index_w  season_week  shock_nonscore  shock_x_blowout  \n",
       "0                    -3.940011       201201               0                0  \n",
       "1                    -3.638251       201202               0                0  \n",
       "2                    -2.938346       201203               0                0  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pick_first_present(candidates: list[str], present: set[str]) -> str | None:\n",
    "    for c in candidates:\n",
    "        if c in present:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "present_cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "SEASON_COL = pick_first_present([\"season\"], present_cols)\n",
    "WEEK_COL = pick_first_present([\"week\"], present_cols)\n",
    "TEAM_RAW_COL = pick_first_present([\"team\", \"team_key\"], present_cols)\n",
    "\n",
    "if SEASON_COL is None or WEEK_COL is None:\n",
    "    raise RuntimeError(\"Missing season or week columns in model view\")\n",
    "if TEAM_RAW_COL is None:\n",
    "    raise RuntimeError(\"Missing team column, expected team or team_key in model view\")\n",
    "\n",
    "OUTCOME_DEF = \"Inj_Def_Next_w\"\n",
    "OUTCOME_OFF = \"Inj_Off_Next_w\"\n",
    "if OUTCOME_DEF not in present_cols or OUTCOME_OFF not in present_cols:\n",
    "    raise RuntimeError(\"Missing Inj_Def_Next_w or Inj_Off_Next_w in model view\")\n",
    "\n",
    "LAG_CANDIDATES = [\n",
    "    \"ST_Shock_NonScore_w_minus_1\",\n",
    "    \"ST_Shock_NonScore_w_minus_2\",\n",
    "    \"ST_Shock_NonScore_w_minus_3\",\n",
    "]\n",
    "LAG_COLS = [c for c in LAG_CANDIDATES if c in present_cols]\n",
    "\n",
    "SHOCK_COL_MAIN = pick_first_present(\n",
    "    [\"ST_Shock_NonScore_w\", \"st_shock_nonscore_w\", \"shock_nonscore\"],\n",
    "    present_cols\n",
    ")\n",
    "\n",
    "POINTS_FOR_COL = pick_first_present([\"points_for_w\", \"points_for\"], present_cols)\n",
    "POINTS_AGAINST_COL = pick_first_present([\"points_against_w\", \"points_against\"], present_cols)\n",
    "SCORE_DIFF_COL = pick_first_present([\"score_diff_w\", \"score_diff\"], present_cols)\n",
    "OFF_YPP_COL = pick_first_present([\"off_yards_per_play_w\", \"Off_yards_per_play_w\"], present_cols)\n",
    "CWI_COL = pick_first_present([\"Cumulative_Workload_Index_w\", \"cumulative_workload_index_w\"], present_cols)\n",
    "\n",
    "required_core = [\n",
    "    SHOCK_COL_MAIN,\n",
    "    POINTS_FOR_COL,\n",
    "    POINTS_AGAINST_COL,\n",
    "    SCORE_DIFF_COL,\n",
    "    OFF_YPP_COL,\n",
    "    CWI_COL,\n",
    "]\n",
    "if any(c is None for c in required_core):\n",
    "    raise RuntimeError(\"Missing one or more required columns for steps 16 and 17, check your step 10 and step 11 outputs\")\n",
    "\n",
    "select_cols = [\n",
    "    SEASON_COL,\n",
    "    WEEK_COL,\n",
    "    TEAM_RAW_COL,\n",
    "    OUTCOME_DEF,\n",
    "    OUTCOME_OFF,\n",
    "    \"Inj_Def_Last_w\",\n",
    "    \"Inj_Off_Last_w\",\n",
    "    \"blowout_flag_w\",\n",
    "    \"short_week_flag_w\",\n",
    "    \"bye_last_week_flag_w\",\n",
    "    \"home_flag_w\",\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    SHOCK_COL_MAIN,\n",
    "    \"ST_Vol_NonScore_w\",\n",
    "    \"Cum_Shocks_NonScore_w\",\n",
    "] + LAG_COLS + [\n",
    "    POINTS_FOR_COL,\n",
    "    POINTS_AGAINST_COL,\n",
    "    SCORE_DIFF_COL,\n",
    "    OFF_YPP_COL,\n",
    "    CWI_COL,\n",
    "]\n",
    "\n",
    "df = con.execute(f\"SELECT {', '.join(select_cols)} FROM {MODEL_VIEW}\").df()\n",
    "\n",
    "rename_map = {}\n",
    "\n",
    "if TEAM_RAW_COL != \"team\":\n",
    "    rename_map[TEAM_RAW_COL] = \"team\"\n",
    "if POINTS_FOR_COL != \"points_for\":\n",
    "    rename_map[POINTS_FOR_COL] = \"points_for\"\n",
    "if POINTS_AGAINST_COL != \"points_against\":\n",
    "    rename_map[POINTS_AGAINST_COL] = \"points_against\"\n",
    "if SCORE_DIFF_COL != \"score_diff_w\":\n",
    "    rename_map[SCORE_DIFF_COL] = \"score_diff_w\"\n",
    "if OFF_YPP_COL != \"off_yards_per_play_w\":\n",
    "    rename_map[OFF_YPP_COL] = \"off_yards_per_play_w\"\n",
    "if CWI_COL != \"Cumulative_Workload_Index_w\":\n",
    "    rename_map[CWI_COL] = \"Cumulative_Workload_Index_w\"\n",
    "if SHOCK_COL_MAIN != \"ST_Shock_NonScore_w\":\n",
    "    rename_map[SHOCK_COL_MAIN] = \"ST_Shock_NonScore_w\"\n",
    "\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "df[\"team\"] = df[\"team\"].astype(str)\n",
    "df[SEASON_COL] = df[SEASON_COL].astype(int)\n",
    "df[WEEK_COL] = df[WEEK_COL].astype(int)\n",
    "\n",
    "df[\"season_week\"] = (df[SEASON_COL] * 100 + df[WEEK_COL]).astype(int)\n",
    "\n",
    "df[\"blowout_flag_w\"] = df[\"blowout_flag_w\"].fillna(0).astype(int)\n",
    "df[\"short_week_flag_w\"] = df[\"short_week_flag_w\"].fillna(0).astype(int)\n",
    "df[\"bye_last_week_flag_w\"] = df[\"bye_last_week_flag_w\"].fillna(0).astype(int)\n",
    "df[\"home_flag_w\"] = df[\"home_flag_w\"].fillna(0).astype(int)\n",
    "\n",
    "df[\"Inj_Def_Last_w\"] = df[\"Inj_Def_Last_w\"].fillna(0).astype(float)\n",
    "df[\"Inj_Off_Last_w\"] = df[\"Inj_Off_Last_w\"].fillna(0).astype(float)\n",
    "\n",
    "df[\"ST_Shock_NonScore_w\"] = df[\"ST_Shock_NonScore_w\"].fillna(0).astype(int)\n",
    "df[\"shock_nonscore\"] = df[\"ST_Shock_NonScore_w\"].astype(int)\n",
    "df[\"shock_x_blowout\"] = (df[\"shock_nonscore\"] * df[\"blowout_flag_w\"]).astype(int)\n",
    "\n",
    "for c in LAG_COLS:\n",
    "    df[c] = df[c].fillna(0).astype(int)\n",
    "\n",
    "must_not_be_null = [\n",
    "    OUTCOME_DEF,\n",
    "    OUTCOME_OFF,\n",
    "    \"ST_Vol_NonScore_w\",\n",
    "    \"Cum_Shocks_NonScore_w\",\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    \"points_for\",\n",
    "    \"points_against\",\n",
    "    \"score_diff_w\",\n",
    "    \"off_yards_per_play_w\",\n",
    "    \"Cumulative_Workload_Index_w\",\n",
    "]\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=must_not_be_null).reset_index(drop=True)\n",
    "after = len(df)\n",
    "\n",
    "print(\"rows before dropna\", before)\n",
    "print(\"rows after dropna\", after)\n",
    "\n",
    "con.register(\"step16_modeling_frame_tmp\", df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step16_modeling_frame AS SELECT * FROM step16_modeling_frame_tmp\")\n",
    "con.unregister(\"step16_modeling_frame_tmp\")\n",
    "\n",
    "print(\"wrote duckdb table step16_modeling_frame\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e4cda-64bb-4682-b58e-8f33c6da53f2",
   "metadata": {},
   "source": [
    "We compute the first pass mean and variance checks for both outcomes so that we can see unconditional overdispersion before running model based tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b43d83-ccc8-412e-a3f2-01e871d19114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defense outcome Inj_Def_Next_w\n",
      "mean 2.083865546218487\n",
      "var 2.380761656150105\n",
      "var_over_mean 1.1424737361152615\n",
      "share_zero 0.15529411764705883\n",
      "max 10.0\n",
      "\n",
      "offense outcome Inj_Off_Next_w\n",
      "mean 1.9201680672268908\n",
      "var 2.1612169830110557\n",
      "var_over_mean 1.125535321568121\n",
      "share_zero 0.17714285714285713\n",
      "max 9.0\n"
     ]
    }
   ],
   "source": [
    "def outcome_dispersion_stats(y: pd.Series) -> dict:\n",
    "    y = y.astype(float)\n",
    "    mean = float(y.mean())\n",
    "    var = float(y.var(ddof=1))\n",
    "    share_zero = float((y == 0).mean())\n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"var\": var,\n",
    "        \"var_over_mean\": (var / mean) if mean > 0 else np.nan,\n",
    "        \"share_zero\": share_zero,\n",
    "        \"max\": float(y.max()),\n",
    "    }\n",
    "\n",
    "stats_def = outcome_dispersion_stats(df[OUTCOME_DEF])\n",
    "stats_off = outcome_dispersion_stats(df[OUTCOME_OFF])\n",
    "\n",
    "print(\"defense outcome\", OUTCOME_DEF)\n",
    "for k in [\"mean\", \"var\", \"var_over_mean\", \"share_zero\", \"max\"]:\n",
    "    print(k, stats_def[k])\n",
    "\n",
    "print()\n",
    "print(\"offense outcome\", OUTCOME_OFF)\n",
    "for k in [\"mean\", \"var\", \"var_over_mean\", \"share_zero\", \"max\"]:\n",
    "    print(k, stats_off[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47656532-8416-48b6-9c3c-2feeeb6222be",
   "metadata": {},
   "source": [
    "We fit Poisson and Negative Binomial versions of Models A and B using the same predictor blocks and fixed effects structure and store the preferred script spec that matches the existing selection rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c247ca-778a-441b-87bd-70e45c2e42a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit ok Inj_Def_Next_w points_for_diff\n",
      "fit ok Inj_Def_Next_w points_against_diff\n",
      "fit ok Inj_Def_Next_w points_for_against\n",
      "fit ok Inj_Off_Next_w points_for_diff\n",
      "fit ok Inj_Off_Next_w points_against_diff\n",
      "fit ok Inj_Off_Next_w points_for_against\n",
      "\n",
      "selected Model A spec points_for_diff\n",
      "Inj_Def_Next_w ~ shock_nonscore + shock_x_blowout + ST_Vol_NonScore_w + Cum_Shocks_NonScore_w + ST_Shock_NonScore_w_minus_1 + ST_Shock_NonScore_w_minus_2 + ST_Shock_NonScore_w_minus_3 + offensive_snaps_w + defensive_snaps_w + blowout_flag_w + short_week_flag_w + bye_last_week_flag_w + home_flag_w + off_yards_per_play_w + Inj_Def_Last_w + Cumulative_Workload_Index_w + points_for + score_diff_w + C(team) + C(season_week)\n",
      "\n",
      "selected Model B spec points_for_diff\n",
      "Inj_Off_Next_w ~ shock_nonscore + shock_x_blowout + ST_Vol_NonScore_w + Cum_Shocks_NonScore_w + ST_Shock_NonScore_w_minus_1 + ST_Shock_NonScore_w_minus_2 + ST_Shock_NonScore_w_minus_3 + offensive_snaps_w + defensive_snaps_w + blowout_flag_w + short_week_flag_w + bye_last_week_flag_w + home_flag_w + off_yards_per_play_w + Inj_Off_Last_w + Cumulative_Workload_Index_w + points_for + score_diff_w + C(team) + C(season_week)\n",
      "\n",
      "defense nb alpha hat 0.0069069372321752046\n",
      "\n",
      "offense nb alpha hat 1e-08\n"
     ]
    }
   ],
   "source": [
    "FE_TEAM = \"C(team)\"\n",
    "FE_TIME = \"C(season_week)\"\n",
    "cluster_groups = df[\"team\"]\n",
    "\n",
    "OUTCOME_DEF_USED = OUTCOME_DEF\n",
    "OUTCOME_OFF_USED = OUTCOME_OFF\n",
    "\n",
    "exposure_terms = [\n",
    "    \"shock_nonscore\",\n",
    "    \"shock_x_blowout\",\n",
    "    \"ST_Vol_NonScore_w\",\n",
    "    \"Cum_Shocks_NonScore_w\",\n",
    "] + LAG_COLS\n",
    "\n",
    "control_terms_base_def = [\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    \"blowout_flag_w\",\n",
    "    \"short_week_flag_w\",\n",
    "    \"bye_last_week_flag_w\",\n",
    "    \"home_flag_w\",\n",
    "    \"off_yards_per_play_w\",\n",
    "    \"Inj_Def_Last_w\",\n",
    "    \"Cumulative_Workload_Index_w\",\n",
    "]\n",
    "\n",
    "control_terms_base_off = [\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    \"blowout_flag_w\",\n",
    "    \"short_week_flag_w\",\n",
    "    \"bye_last_week_flag_w\",\n",
    "    \"home_flag_w\",\n",
    "    \"off_yards_per_play_w\",\n",
    "    \"Inj_Off_Last_w\",\n",
    "    \"Cumulative_Workload_Index_w\",\n",
    "]\n",
    "\n",
    "script_specs = [\n",
    "    (\"points_for_diff\", [\"points_for\", \"score_diff_w\"]),\n",
    "    (\"points_against_diff\", [\"points_against\", \"score_diff_w\"]),\n",
    "    (\"points_for_against\", [\"points_for\", \"points_against\"]),\n",
    "]\n",
    "\n",
    "preferred_order = [\"points_for_diff\", \"points_against_diff\", \"points_for_against\"]\n",
    "\n",
    "def build_formula(outcome: str, base_controls: list[str], script_terms: list[str]) -> str:\n",
    "    rhs = exposure_terms + base_controls + script_terms + [FE_TEAM, FE_TIME]\n",
    "    return outcome + \" ~ \" + \" + \".join(rhs)\n",
    "\n",
    "def fit_count_model_poisson_glm(formula: str, data: pd.DataFrame, groups: pd.Series, maxiter: int = 200):\n",
    "    m = smf.glm(formula=formula, data=data, family=sm.families.Poisson())\n",
    "    r = m.fit(maxiter=maxiter, cov_type=\"cluster\", cov_kwds={\"groups\": groups})\n",
    "    return r\n",
    "\n",
    "def estimate_nb2_alpha_moments(y: np.ndarray, mu: np.ndarray) -> float:\n",
    "    y = y.astype(float)\n",
    "    mu = mu.astype(float)\n",
    "    den = float(np.sum(mu ** 2))\n",
    "    if den <= 0:\n",
    "        return 1e-8\n",
    "    num = float(np.sum((y - mu) ** 2 - mu))\n",
    "    alpha = num / den\n",
    "    if not np.isfinite(alpha):\n",
    "        alpha = 1e-8\n",
    "    alpha = float(max(alpha, 1e-8))\n",
    "    alpha = float(min(alpha, 50.0))\n",
    "    return alpha\n",
    "\n",
    "def fit_count_model_negative_binomial_glm_nb2(formula: str, data: pd.DataFrame, groups: pd.Series, alpha: float, maxiter: int = 200):\n",
    "    fam = sm.families.NegativeBinomial(alpha=alpha)\n",
    "    m = smf.glm(formula=formula, data=data, family=fam)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=HessianInversionWarning)\n",
    "        r = m.fit(maxiter=maxiter, cov_type=\"cluster\", cov_kwds={\"groups\": groups})\n",
    "\n",
    "    return r\n",
    "\n",
    "def fit_model_grid(outcome: str, base_controls: list[str]) -> tuple[str, str, object, object]:\n",
    "    fits = []\n",
    "    for tag, script_terms in script_specs:\n",
    "        f = build_formula(outcome, base_controls, script_terms)\n",
    "\n",
    "        pois = None\n",
    "        nb = None\n",
    "\n",
    "        try:\n",
    "            pois = fit_count_model_poisson_glm(f, df, cluster_groups)\n",
    "        except Exception as e:\n",
    "            print(\"poisson failed\", outcome, tag, str(e))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            y = df[outcome].to_numpy()\n",
    "            mu = np.asarray(pois.mu)\n",
    "            alpha_hat = estimate_nb2_alpha_moments(y, mu)\n",
    "\n",
    "            nb = fit_count_model_negative_binomial_glm_nb2(\n",
    "                f,\n",
    "                df,\n",
    "                cluster_groups,\n",
    "                alpha=alpha_hat,\n",
    "                maxiter=200,\n",
    "            )\n",
    "\n",
    "            nb._alpha_hat_mom = alpha_hat\n",
    "        except Exception as e:\n",
    "            print(\"negative binomial glm failed\", outcome, tag, str(e))\n",
    "\n",
    "        fits.append((tag, f, pois, nb))\n",
    "        print(\"fit ok\", outcome, tag)\n",
    "\n",
    "    if len(fits) == 0:\n",
    "        raise RuntimeError(f\"No specifications fit successfully for {outcome}\")\n",
    "\n",
    "    fits_sorted = sorted(\n",
    "        fits,\n",
    "        key=lambda x: preferred_order.index(x[0]) if x[0] in preferred_order else 999\n",
    "    )\n",
    "    return fits_sorted[0]\n",
    "\n",
    "spec_tag_def, formula_def_used, pois_def, nb_def = fit_model_grid(OUTCOME_DEF_USED, control_terms_base_def)\n",
    "spec_tag_off, formula_off_used, pois_off, nb_off = fit_model_grid(OUTCOME_OFF_USED, control_terms_base_off)\n",
    "\n",
    "print()\n",
    "print(\"selected Model A spec\", spec_tag_def)\n",
    "print(formula_def_used)\n",
    "print()\n",
    "print(\"selected Model B spec\", spec_tag_off)\n",
    "print(formula_off_used)\n",
    "\n",
    "if nb_def is not None:\n",
    "    print()\n",
    "    print(\"defense nb alpha hat\", float(getattr(nb_def, \"_alpha_hat_mom\", np.nan)))\n",
    "\n",
    "if nb_off is not None:\n",
    "    print()\n",
    "    print(\"offense nb alpha hat\", float(getattr(nb_off, \"_alpha_hat_mom\", np.nan)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd4a20-12a9-47f7-aedd-8ca061e75b39",
   "metadata": {},
   "source": [
    "We run model based overdispersion diagnostics for each Poisson fit using Pearson dispersion and an approximate z test so the decision is not based only on unconditional variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a6c5041-2151-4fa8-a306-4ac59cff32fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson overdispersion diagnostics, defense\n",
      "pearson_dispersion 1.0699401873476033\n",
      "pearson_z 3.729196098233154\n",
      "pearson_pvalue 0.00019209162261613066\n",
      "deviance_dispersion 1.205507707915455\n",
      "aic 20850.174345191903\n",
      "bic 22616.637020806378\n",
      "llf -10161.087172595951\n",
      "nobs 5950\n",
      "\n",
      "poisson overdispersion diagnostics, offense\n",
      "pearson_dispersion 1.045766743017786\n",
      "pearson_z 2.440273124270023\n",
      "pearson_pvalue 0.014676161275462452\n",
      "deviance_dispersion 1.1981689973697445\n",
      "aic 20219.032919018013\n",
      "bic 21985.495594632488\n",
      "llf -9845.516459509006\n",
      "nobs 5950\n"
     ]
    }
   ],
   "source": [
    "def poisson_overdispersion_diagnostics(res) -> dict:\n",
    "    chi2 = float(res.pearson_chi2)\n",
    "    df_resid = float(res.df_resid)\n",
    "    ratio = chi2 / df_resid if df_resid > 0 else np.nan\n",
    "\n",
    "    z = (chi2 - df_resid) / np.sqrt(2.0 * df_resid) if df_resid > 0 else np.nan\n",
    "    p = float(2.0 * (1.0 - stats.norm.cdf(abs(z)))) if np.isfinite(z) else np.nan\n",
    "\n",
    "    dev = float(res.deviance)\n",
    "    dev_ratio = dev / df_resid if df_resid > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"pearson_chi2\": chi2,\n",
    "        \"df_resid\": df_resid,\n",
    "        \"pearson_dispersion\": ratio,\n",
    "        \"pearson_z\": float(z) if np.isfinite(z) else np.nan,\n",
    "        \"pearson_pvalue\": p,\n",
    "        \"deviance\": dev,\n",
    "        \"deviance_dispersion\": dev_ratio,\n",
    "        \"aic\": float(getattr(res, \"aic\", np.nan)),\n",
    "        \"bic\": float(getattr(res, \"bic\", np.nan)),\n",
    "        \"llf\": float(getattr(res, \"llf\", np.nan)),\n",
    "        \"nobs\": int(getattr(res, \"nobs\", np.nan)),\n",
    "    }\n",
    "\n",
    "diag_def = poisson_overdispersion_diagnostics(pois_def)\n",
    "diag_off = poisson_overdispersion_diagnostics(pois_off)\n",
    "\n",
    "print(\"poisson overdispersion diagnostics, defense\")\n",
    "for k in [\"pearson_dispersion\", \"pearson_z\", \"pearson_pvalue\", \"deviance_dispersion\", \"aic\", \"bic\", \"llf\", \"nobs\"]:\n",
    "    print(k, diag_def[k])\n",
    "\n",
    "print()\n",
    "print(\"poisson overdispersion diagnostics, offense\")\n",
    "for k in [\"pearson_dispersion\", \"pearson_z\", \"pearson_pvalue\", \"deviance_dispersion\", \"aic\", \"bic\", \"llf\", \"nobs\"]:\n",
    "    print(k, diag_off[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001db89a-1738-4228-99fb-5274ed9768b0",
   "metadata": {},
   "source": [
    "We formalize the family choice rule and export a diagnostics table plus the selected family results for Models A and B to DuckDB and csv so that the later steps always reference a single preferred count model per side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2bb54c9-0120-4975-84f8-c1076fd22932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family choice defense poisson\n",
      "reason defense no strong overdispersion signal, or NB failed\n",
      "\n",
      "family choice offense poisson\n",
      "reason offense no strong overdispersion signal, or NB failed\n",
      "wrote duckdb table step16_overdispersion_diagnostics\n",
      "wrote duckdb table step16_selected_count_results\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step16_overdispersion_diagnostics.csv\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step16_selected_count_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>spec_tag</th>\n",
       "      <th>formula_used</th>\n",
       "      <th>outcome_mean</th>\n",
       "      <th>outcome_var</th>\n",
       "      <th>outcome_var_over_mean</th>\n",
       "      <th>poisson_pearson_dispersion</th>\n",
       "      <th>poisson_pearson_pvalue</th>\n",
       "      <th>poisson_deviance_dispersion</th>\n",
       "      <th>poisson_aic</th>\n",
       "      <th>poisson_bic</th>\n",
       "      <th>nb_aic</th>\n",
       "      <th>nb_bic</th>\n",
       "      <th>nb_alpha</th>\n",
       "      <th>family_choice</th>\n",
       "      <th>choice_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>defense</td>\n",
       "      <td>points_for_diff</td>\n",
       "      <td>Inj_Def_Next_w ~ shock_nonscore + shock_x_blow...</td>\n",
       "      <td>2.083866</td>\n",
       "      <td>2.380762</td>\n",
       "      <td>1.142474</td>\n",
       "      <td>1.069940</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>1.205508</td>\n",
       "      <td>20850.174345</td>\n",
       "      <td>22616.637021</td>\n",
       "      <td>20849.514123</td>\n",
       "      <td>22615.976799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poisson</td>\n",
       "      <td>no strong overdispersion signal, or NB failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offense</td>\n",
       "      <td>points_for_diff</td>\n",
       "      <td>Inj_Off_Next_w ~ shock_nonscore + shock_x_blow...</td>\n",
       "      <td>1.920168</td>\n",
       "      <td>2.161217</td>\n",
       "      <td>1.125535</td>\n",
       "      <td>1.045767</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>1.198169</td>\n",
       "      <td>20219.032919</td>\n",
       "      <td>21985.495595</td>\n",
       "      <td>20219.033728</td>\n",
       "      <td>21985.496404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poisson</td>\n",
       "      <td>no strong overdispersion signal, or NB failed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      side         spec_tag  \\\n",
       "0  defense  points_for_diff   \n",
       "1  offense  points_for_diff   \n",
       "\n",
       "                                        formula_used  outcome_mean  \\\n",
       "0  Inj_Def_Next_w ~ shock_nonscore + shock_x_blow...      2.083866   \n",
       "1  Inj_Off_Next_w ~ shock_nonscore + shock_x_blow...      1.920168   \n",
       "\n",
       "   outcome_var  outcome_var_over_mean  poisson_pearson_dispersion  \\\n",
       "0     2.380762               1.142474                    1.069940   \n",
       "1     2.161217               1.125535                    1.045767   \n",
       "\n",
       "   poisson_pearson_pvalue  poisson_deviance_dispersion   poisson_aic  \\\n",
       "0                0.000192                     1.205508  20850.174345   \n",
       "1                0.014676                     1.198169  20219.032919   \n",
       "\n",
       "    poisson_bic        nb_aic        nb_bic  nb_alpha family_choice  \\\n",
       "0  22616.637021  20849.514123  22615.976799       NaN       poisson   \n",
       "1  21985.495595  20219.033728  21985.496404       NaN       poisson   \n",
       "\n",
       "                                   choice_reason  \n",
       "0  no strong overdispersion signal, or NB failed  \n",
       "1  no strong overdispersion signal, or NB failed  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_nb_alpha(res) -> float:\n",
    "    if res is None:\n",
    "        return np.nan\n",
    "    try:\n",
    "        if \"alpha\" in res.params.index:\n",
    "            return float(res.params[\"alpha\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.nan\n",
    "\n",
    "alpha_def = extract_nb_alpha(nb_def)\n",
    "alpha_off = extract_nb_alpha(nb_off)\n",
    "\n",
    "nb_meta_def = {\n",
    "    \"aic\": float(getattr(nb_def, \"aic\", np.nan)) if nb_def is not None else np.nan,\n",
    "    \"bic\": float(getattr(nb_def, \"bic\", np.nan)) if nb_def is not None else np.nan,\n",
    "    \"llf\": float(getattr(nb_def, \"llf\", np.nan)) if nb_def is not None else np.nan,\n",
    "    \"nobs\": int(getattr(nb_def, \"nobs\", np.nan)) if nb_def is not None else np.nan,\n",
    "    \"alpha\": alpha_def,\n",
    "}\n",
    "nb_meta_off = {\n",
    "    \"aic\": float(getattr(nb_off, \"aic\", np.nan)) if nb_off is not None else np.nan,\n",
    "    \"bic\": float(getattr(nb_off, \"bic\", np.nan)) if nb_off is not None else np.nan,\n",
    "    \"llf\": float(getattr(nb_off, \"llf\", np.nan)) if nb_off is not None else np.nan,\n",
    "    \"nobs\": int(getattr(nb_off, \"nobs\", np.nan)) if nb_off is not None else np.nan,\n",
    "    \"alpha\": alpha_off,\n",
    "}\n",
    "\n",
    "def choose_family(uncond_stats: dict, pois_diag: dict, nb_res) -> tuple[str, str]:\n",
    "    var_over_mean = float(uncond_stats.get(\"var_over_mean\", np.nan))\n",
    "    pearson_disp = float(pois_diag.get(\"pearson_dispersion\", np.nan))\n",
    "    pval = float(pois_diag.get(\"pearson_pvalue\", np.nan))\n",
    "\n",
    "    overdisp_uncond = np.isfinite(var_over_mean) and (var_over_mean >= 1.5)\n",
    "    overdisp_model = np.isfinite(pearson_disp) and np.isfinite(pval) and (pearson_disp >= 1.2) and (pval < 0.05)\n",
    "\n",
    "    if (overdisp_uncond or overdisp_model) and (nb_res is not None):\n",
    "        return \"negative_binomial\", \"overdispersion flagged by unconditional or model based test\"\n",
    "    return \"poisson\", \"no strong overdispersion signal, or NB failed\"\n",
    "\n",
    "choice_def, reason_def = choose_family(stats_def, diag_def, nb_def)\n",
    "choice_off, reason_off = choose_family(stats_off, diag_off, nb_off)\n",
    "\n",
    "print(\"family choice defense\", choice_def)\n",
    "print(\"reason defense\", reason_def)\n",
    "print()\n",
    "print(\"family choice offense\", choice_off)\n",
    "print(\"reason offense\", reason_off)\n",
    "\n",
    "def tidy_count_res(res, model_name: str, outcome_name: str, spec_tag: str, key_terms: list[str]) -> pd.DataFrame:\n",
    "    params = res.params.copy()\n",
    "    bse = res.bse.copy()\n",
    "    pvals = res.pvalues.copy()\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"model\": model_name,\n",
    "        \"spec_tag\": spec_tag,\n",
    "        \"outcome\": outcome_name,\n",
    "        \"term\": params.index.astype(str),\n",
    "        \"beta\": params.values.astype(float),\n",
    "        \"se_cluster\": bse.values.astype(float),\n",
    "        \"pvalue\": pvals.values.astype(float),\n",
    "    })\n",
    "\n",
    "    out[\"nobs\"] = int(getattr(res, \"nobs\", np.nan))\n",
    "    out[\"aic\"] = float(getattr(res, \"aic\", np.nan))\n",
    "    out[\"bic\"] = float(getattr(res, \"bic\", np.nan))\n",
    "    out[\"llf\"] = float(getattr(res, \"llf\", np.nan))\n",
    "\n",
    "    out[\"irr\"] = np.exp(out[\"beta\"].astype(float))\n",
    "    out[\"irr_ci_lo\"] = np.exp(out[\"beta\"].astype(float) - 1.96 * out[\"se_cluster\"].astype(float))\n",
    "    out[\"irr_ci_hi\"] = np.exp(out[\"beta\"].astype(float) + 1.96 * out[\"se_cluster\"].astype(float))\n",
    "\n",
    "    key_keep = set(key_terms)\n",
    "    out[\"is_key_term\"] = out[\"term\"].apply(lambda x: 1 if x in key_keep else 0)\n",
    "    return out\n",
    "\n",
    "key_terms = exposure_terms\n",
    "\n",
    "selected_def_res = nb_def if choice_def == \"negative_binomial\" else pois_def\n",
    "selected_off_res = nb_off if choice_off == \"negative_binomial\" else pois_off\n",
    "\n",
    "selected_def_name = f\"{choice_def}_modelA_selected\"\n",
    "selected_off_name = f\"{choice_off}_modelB_selected\"\n",
    "\n",
    "selected_def_df = tidy_count_res(selected_def_res, selected_def_name, OUTCOME_DEF_USED, spec_tag_def, key_terms)\n",
    "selected_off_df = tidy_count_res(selected_off_res, selected_off_name, OUTCOME_OFF_USED, spec_tag_off, key_terms)\n",
    "\n",
    "final_selected = pd.concat([selected_def_df, selected_off_df], ignore_index=True)\n",
    "\n",
    "diag_rows = []\n",
    "diag_rows.append({\n",
    "    \"side\": \"defense\",\n",
    "    \"spec_tag\": spec_tag_def,\n",
    "    \"formula_used\": formula_def_used,\n",
    "    \"outcome_mean\": stats_def[\"mean\"],\n",
    "    \"outcome_var\": stats_def[\"var\"],\n",
    "    \"outcome_var_over_mean\": stats_def[\"var_over_mean\"],\n",
    "    \"poisson_pearson_dispersion\": diag_def[\"pearson_dispersion\"],\n",
    "    \"poisson_pearson_pvalue\": diag_def[\"pearson_pvalue\"],\n",
    "    \"poisson_deviance_dispersion\": diag_def[\"deviance_dispersion\"],\n",
    "    \"poisson_aic\": diag_def[\"aic\"],\n",
    "    \"poisson_bic\": diag_def[\"bic\"],\n",
    "    \"nb_aic\": nb_meta_def[\"aic\"],\n",
    "    \"nb_bic\": nb_meta_def[\"bic\"],\n",
    "    \"nb_alpha\": nb_meta_def[\"alpha\"],\n",
    "    \"family_choice\": choice_def,\n",
    "    \"choice_reason\": reason_def,\n",
    "})\n",
    "diag_rows.append({\n",
    "    \"side\": \"offense\",\n",
    "    \"spec_tag\": spec_tag_off,\n",
    "    \"formula_used\": formula_off_used,\n",
    "    \"outcome_mean\": stats_off[\"mean\"],\n",
    "    \"outcome_var\": stats_off[\"var\"],\n",
    "    \"outcome_var_over_mean\": stats_off[\"var_over_mean\"],\n",
    "    \"poisson_pearson_dispersion\": diag_off[\"pearson_dispersion\"],\n",
    "    \"poisson_pearson_pvalue\": diag_off[\"pearson_pvalue\"],\n",
    "    \"poisson_deviance_dispersion\": diag_off[\"deviance_dispersion\"],\n",
    "    \"poisson_aic\": diag_off[\"aic\"],\n",
    "    \"poisson_bic\": diag_off[\"bic\"],\n",
    "    \"nb_aic\": nb_meta_off[\"aic\"],\n",
    "    \"nb_bic\": nb_meta_off[\"bic\"],\n",
    "    \"nb_alpha\": nb_meta_off[\"alpha\"],\n",
    "    \"family_choice\": choice_off,\n",
    "    \"choice_reason\": reason_off,\n",
    "})\n",
    "\n",
    "diag_df = pd.DataFrame(diag_rows)\n",
    "\n",
    "con.register(\"step16_overdisp_tmp\", diag_df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step16_overdispersion_diagnostics AS SELECT * FROM step16_overdisp_tmp\")\n",
    "con.unregister(\"step16_overdisp_tmp\")\n",
    "\n",
    "con.register(\"step16_selected_tmp\", final_selected)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step16_selected_count_results AS SELECT * FROM step16_selected_tmp\")\n",
    "con.unregister(\"step16_selected_tmp\")\n",
    "\n",
    "out_dir = Path(\"../outputs\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "diag_csv = out_dir / \"step16_overdispersion_diagnostics.csv\"\n",
    "sel_csv = out_dir / \"step16_selected_count_results.csv\"\n",
    "\n",
    "diag_df.to_csv(diag_csv, index=False)\n",
    "final_selected.to_csv(sel_csv, index=False)\n",
    "\n",
    "print(\"wrote duckdb table step16_overdispersion_diagnostics\")\n",
    "print(\"wrote duckdb table step16_selected_count_results\")\n",
    "print(\"wrote csv\", diag_csv.resolve())\n",
    "print(\"wrote csv\", sel_csv.resolve())\n",
    "\n",
    "diag_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
