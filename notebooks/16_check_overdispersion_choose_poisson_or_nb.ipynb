{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d842573f-1064-4678-b8f8-18ef317dbd29",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd3ce4d-791f-46b1-b270-f2248c960672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected db /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/db/nflpa.duckdb\n",
      "model view team_week_panel_nextweek_model\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, HessianInversionWarning\n",
    "\n",
    "try:\n",
    "    import statsmodels.genmod.generalized_linear_model as glm\n",
    "    glm.SET_USE_BIC_LLF(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"The bic value is computed using the deviance formula.*\",\n",
    ")\n",
    "\n",
    "CWD = Path().resolve()\n",
    "\n",
    "REPO_ROOT = None\n",
    "DB_FILE = None\n",
    "\n",
    "for p in [CWD] + list(CWD.parents):\n",
    "    cand = p / \"db\" / \"nflpa.duckdb\"\n",
    "    if cand.exists():\n",
    "        REPO_ROOT = p\n",
    "        DB_FILE = cand\n",
    "        break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    for p in [CWD] + list(CWD.parents):\n",
    "        cand = p / \"nflpa.duckdb\"\n",
    "        if cand.exists():\n",
    "            REPO_ROOT = p\n",
    "            DB_FILE = cand\n",
    "            break\n",
    "\n",
    "if DB_FILE is None:\n",
    "    raise RuntimeError(\"Could not find nflpa.duckdb, expected db/nflpa.duckdb or nflpa.duckdb near this notebook\")\n",
    "\n",
    "con = duckdb.connect(str(DB_FILE), read_only=False)\n",
    "\n",
    "MODEL_VIEW = \"team_week_panel_nextweek_model\"\n",
    "\n",
    "exists_df = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name = '{MODEL_VIEW}'\n",
    "  AND table_type IN ('BASE TABLE', 'VIEW')\n",
    "\"\"\").df()\n",
    "\n",
    "if int(exists_df[\"n\"].iloc[0]) == 0:\n",
    "    raise RuntimeError(f\"Missing {MODEL_VIEW}, run notebook 11 to create the model view\")\n",
    "\n",
    "print(\"connected db\", str(DB_FILE))\n",
    "print(\"model view\", MODEL_VIEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217dcaa-d6eb-4800-a595-e095e5b586a2",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the modeling view only contains next week eligible rows, has non null offensive and defensive outcomes, and has unique team week keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0959b75-5ed8-471a-ac25-7787d9a4993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dup_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dup_rows\n",
       "0         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows_model,\n",
    "  SUM(CASE WHEN has_next_week != 1 THEN 1 ELSE 0 END) AS bad_has_next_week,\n",
    "  SUM(CASE WHEN Inj_Def_Next_w IS NULL THEN 1 ELSE 0 END) AS null_outcome_def,\n",
    "  SUM(CASE WHEN Inj_Off_Next_w IS NULL THEN 1 ELSE 0 END) AS null_outcome_off\n",
    "FROM {MODEL_VIEW}\n",
    "\"\"\").df()\n",
    "\n",
    "desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "if \"team\" in cols:\n",
    "    TEAM_COL = \"team\"\n",
    "elif \"team_key\" in cols:\n",
    "    TEAM_COL = \"team_key\"\n",
    "else:\n",
    "    raise RuntimeError(f\"No team id column found in {MODEL_VIEW}, expected team or team_key\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS dup_rows\n",
    "FROM (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    {TEAM_COL} AS team_any,\n",
    "    COUNT(*) AS n\n",
    "  FROM {MODEL_VIEW}\n",
    "  GROUP BY 1,2,3\n",
    "  HAVING COUNT(*) > 1\n",
    ")\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f7bf1-36ee-479f-8ddc-9efd6db1b869",
   "metadata": {},
   "source": [
    "We build a single, clean modeling frame table with robust column detection, consistent names, and consistent missing value handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5f7291-8696-4b28-8243-7e974c0f5a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before dropna 5950\n",
      "rows after dropna 5950\n",
      "wrote duckdb table step16_modeling_frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>team</th>\n",
       "      <th>Inj_Def_Next_w</th>\n",
       "      <th>Inj_Off_Next_w</th>\n",
       "      <th>Inj_Def_Last_w</th>\n",
       "      <th>Inj_Off_Last_w</th>\n",
       "      <th>blowout_flag_w</th>\n",
       "      <th>short_week_flag_w</th>\n",
       "      <th>bye_last_week_flag_w</th>\n",
       "      <th>...</th>\n",
       "      <th>ST_Shock_NonScore_w_minus_2</th>\n",
       "      <th>ST_Shock_NonScore_w_minus_3</th>\n",
       "      <th>points_for</th>\n",
       "      <th>points_against</th>\n",
       "      <th>score_diff_w</th>\n",
       "      <th>off_yards_per_play_w</th>\n",
       "      <th>Cumulative_Workload_Index_w</th>\n",
       "      <th>season_week</th>\n",
       "      <th>shock_nonscore</th>\n",
       "      <th>shock_x_blowout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>6.836364</td>\n",
       "      <td>-3.940011</td>\n",
       "      <td>201201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>4.412698</td>\n",
       "      <td>-3.638251</td>\n",
       "      <td>201202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>5.565217</td>\n",
       "      <td>-2.938346</td>\n",
       "      <td>201203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  week team  Inj_Def_Next_w  Inj_Off_Next_w  Inj_Def_Last_w  \\\n",
       "0    2012     1  ATL             2.0             2.0             0.0   \n",
       "1    2012     2  ATL             3.0             2.0             2.0   \n",
       "2    2012     3  ATL             2.0             2.0             3.0   \n",
       "\n",
       "   Inj_Off_Last_w  blowout_flag_w  short_week_flag_w  bye_last_week_flag_w  \\\n",
       "0             0.0               1                  0                     0   \n",
       "1             2.0               0                  0                     0   \n",
       "2             2.0               1                  0                     0   \n",
       "\n",
       "   ...  ST_Shock_NonScore_w_minus_2  ST_Shock_NonScore_w_minus_3  points_for  \\\n",
       "0  ...                            0                            0          40   \n",
       "1  ...                            0                            0          27   \n",
       "2  ...                            0                            0          27   \n",
       "\n",
       "   points_against  score_diff_w  off_yards_per_play_w  \\\n",
       "0              24            16              6.836364   \n",
       "1              21             6              4.412698   \n",
       "2               3            24              5.565217   \n",
       "\n",
       "   Cumulative_Workload_Index_w  season_week  shock_nonscore  shock_x_blowout  \n",
       "0                    -3.940011       201201               0                0  \n",
       "1                    -3.638251       201202               0                0  \n",
       "2                    -2.938346       201203               0                0  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pick_first_present(candidates: list[str], present: set[str]) -> str | None:\n",
    "    for c in candidates:\n",
    "        if c in present:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "present_cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "SEASON_COL = pick_first_present([\"season\"], present_cols)\n",
    "WEEK_COL = pick_first_present([\"week\"], present_cols)\n",
    "TEAM_RAW_COL = pick_first_present([\"team\", \"team_key\"], present_cols)\n",
    "\n",
    "if SEASON_COL is None or WEEK_COL is None:\n",
    "    raise RuntimeError(\"Missing season or week columns in model view\")\n",
    "if TEAM_RAW_COL is None:\n",
    "    raise RuntimeError(\"Missing team column, expected team or team_key in model view\")\n",
    "\n",
    "OUTCOME_DEF = \"Inj_Def_Next_w\"\n",
    "OUTCOME_OFF = \"Inj_Off_Next_w\"\n",
    "if OUTCOME_DEF not in present_cols or OUTCOME_OFF not in present_cols:\n",
    "    raise RuntimeError(\"Missing Inj_Def_Next_w or Inj_Off_Next_w in model view\")\n",
    "\n",
    "LAG_CANDIDATES = [\n",
    "    \"ST_Shock_NonScore_w_minus_1\",\n",
    "    \"ST_Shock_NonScore_w_minus_2\",\n",
    "    \"ST_Shock_NonScore_w_minus_3\",\n",
    "]\n",
    "LAG_COLS = [c for c in LAG_CANDIDATES if c in present_cols]\n",
    "\n",
    "SHOCK_COL_MAIN = pick_first_present(\n",
    "    [\"ST_Shock_NonScore_w\", \"st_shock_nonscore_w\", \"shock_nonscore\"],\n",
    "    present_cols\n",
    ")\n",
    "\n",
    "POINTS_FOR_COL = pick_first_present([\"points_for_w\", \"points_for\"], present_cols)\n",
    "POINTS_AGAINST_COL = pick_first_present([\"points_against_w\", \"points_against\"], present_cols)\n",
    "SCORE_DIFF_COL = pick_first_present([\"score_diff_w\", \"score_diff\"], present_cols)\n",
    "OFF_YPP_COL = pick_first_present([\"off_yards_per_play_w\", \"Off_yards_per_play_w\"], present_cols)\n",
    "CWI_COL = pick_first_present([\"Cumulative_Workload_Index_w\", \"cumulative_workload_index_w\"], present_cols)\n",
    "\n",
    "required_core = [\n",
    "    SHOCK_COL_MAIN,\n",
    "    POINTS_FOR_COL,\n",
    "    POINTS_AGAINST_COL,\n",
    "    SCORE_DIFF_COL,\n",
    "    OFF_YPP_COL,\n",
    "    CWI_COL,\n",
    "]\n",
    "if any(c is None for c in required_core):\n",
    "    raise RuntimeError(\"Missing one or more required columns for steps 16 and 17, check your step 10 and step 11 outputs\")\n",
    "\n",
    "select_cols = [\n",
    "    SEASON_COL,\n",
    "    WEEK_COL,\n",
    "    TEAM_RAW_COL,\n",
    "    OUTCOME_DEF,\n",
    "    OUTCOME_OFF,\n",
    "    \"Inj_Def_Last_w\",\n",
    "    \"Inj_Off_Last_w\",\n",
    "    \"blowout_flag_w\",\n",
    "    \"short_week_flag_w\",\n",
    "    \"bye_last_week_flag_w\",\n",
    "    \"home_flag_w\",\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    SHOCK_COL_MAIN,\n",
    "    \"ST_Vol_NonScore_w\",\n",
    "    \"Cum_Shocks_NonScore_w\",\n",
    "] + LAG_COLS + [\n",
    "    POINTS_FOR_COL,\n",
    "    POINTS_AGAINST_COL,\n",
    "    SCORE_DIFF_COL,\n",
    "    OFF_YPP_COL,\n",
    "    CWI_COL,\n",
    "]\n",
    "\n",
    "df = con.execute(f\"SELECT {', '.join(select_cols)} FROM {MODEL_VIEW}\").df()\n",
    "\n",
    "rename_map = {}\n",
    "\n",
    "if TEAM_RAW_COL != \"team\":\n",
    "    rename_map[TEAM_RAW_COL] = \"team\"\n",
    "if POINTS_FOR_COL != \"points_for\":\n",
    "    rename_map[POINTS_FOR_COL] = \"points_for\"\n",
    "if POINTS_AGAINST_COL != \"points_against\":\n",
    "    rename_map[POINTS_AGAINST_COL] = \"points_against\"\n",
    "if SCORE_DIFF_COL != \"score_diff_w\":\n",
    "    rename_map[SCORE_DIFF_COL] = \"score_diff_w\"\n",
    "if OFF_YPP_COL != \"off_yards_per_play_w\":\n",
    "    rename_map[OFF_YPP_COL] = \"off_yards_per_play_w\"\n",
    "if CWI_COL != \"Cumulative_Workload_Index_w\":\n",
    "    rename_map[CWI_COL] = \"Cumulative_Workload_Index_w\"\n",
    "if SHOCK_COL_MAIN != \"ST_Shock_NonScore_w\":\n",
    "    rename_map[SHOCK_COL_MAIN] = \"ST_Shock_NonScore_w\"\n",
    "\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "df[\"team\"] = df[\"team\"].astype(str)\n",
    "df[SEASON_COL] = df[SEASON_COL].astype(int)\n",
    "df[WEEK_COL] = df[WEEK_COL].astype(int)\n",
    "\n",
    "df[\"season_week\"] = (df[SEASON_COL] * 100 + df[WEEK_COL]).astype(int)\n",
    "\n",
    "df[\"blowout_flag_w\"] = df[\"blowout_flag_w\"].fillna(0).astype(int)\n",
    "df[\"short_week_flag_w\"] = df[\"short_week_flag_w\"].fillna(0).astype(int)\n",
    "df[\"bye_last_week_flag_w\"] = df[\"bye_last_week_flag_w\"].fillna(0).astype(int)\n",
    "df[\"home_flag_w\"] = df[\"home_flag_w\"].fillna(0).astype(int)\n",
    "\n",
    "df[\"Inj_Def_Last_w\"] = df[\"Inj_Def_Last_w\"].fillna(0).astype(float)\n",
    "df[\"Inj_Off_Last_w\"] = df[\"Inj_Off_Last_w\"].fillna(0).astype(float)\n",
    "\n",
    "df[\"ST_Shock_NonScore_w\"] = df[\"ST_Shock_NonScore_w\"].fillna(0).astype(int)\n",
    "df[\"shock_nonscore\"] = df[\"ST_Shock_NonScore_w\"].astype(int)\n",
    "df[\"shock_x_blowout\"] = (df[\"shock_nonscore\"] * df[\"blowout_flag_w\"]).astype(int)\n",
    "\n",
    "for c in LAG_COLS:\n",
    "    df[c] = df[c].fillna(0).astype(int)\n",
    "\n",
    "must_not_be_null = [\n",
    "    OUTCOME_DEF,\n",
    "    OUTCOME_OFF,\n",
    "    \"ST_Vol_NonScore_w\",\n",
    "    \"Cum_Shocks_NonScore_w\",\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    \"points_for\",\n",
    "    \"points_against\",\n",
    "    \"score_diff_w\",\n",
    "    \"off_yards_per_play_w\",\n",
    "    \"Cumulative_Workload_Index_w\",\n",
    "]\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=must_not_be_null).reset_index(drop=True)\n",
    "after = len(df)\n",
    "\n",
    "print(\"rows before dropna\", before)\n",
    "print(\"rows after dropna\", after)\n",
    "\n",
    "con.register(\"step16_modeling_frame_tmp\", df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step16_modeling_frame AS SELECT * FROM step16_modeling_frame_tmp\")\n",
    "con.unregister(\"step16_modeling_frame_tmp\")\n",
    "\n",
    "print(\"wrote duckdb table step16_modeling_frame\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e90fa1-95d3-4d9b-8f4f-ee2f9d9fecbf",
   "metadata": {},
   "source": [
    "We patch 'step16_modeling_frame' by rebuilding a prior weeks only 'NonScore' shock from the load column, and then regenerate the lag shock columns so that the model uses a lookahead free exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12e4822-7043-4345-bb4a-c3c3e72a6d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote duckdb table step16_modeling_frame_nolookahead\n"
     ]
    }
   ],
   "source": [
    "desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "load_candidates = [\n",
    "    \"ST_Load_NonScore_w\",\n",
    "    \"ST_Load_NonScore\",\n",
    "    \"ST_NonScore_Load_w\",\n",
    "    \"st_load_nonscore_w\",\n",
    "]\n",
    "LOAD_COL = None\n",
    "for c in load_candidates:\n",
    "    if c in cols:\n",
    "        LOAD_COL = c\n",
    "        break\n",
    "\n",
    "if LOAD_COL is None:\n",
    "    raise RuntimeError(\"NonScore load column not found, add the exact name from DESCRIBE into load_candidates\")\n",
    "\n",
    "if \"load_nonscore\" not in df.columns:\n",
    "    load_df = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "      season,\n",
    "      week,\n",
    "      team,\n",
    "      {LOAD_COL} AS load_nonscore\n",
    "    FROM {MODEL_VIEW}\n",
    "    WHERE has_next_week = 1\n",
    "    \"\"\").df()\n",
    "\n",
    "    df = df.merge(load_df, on=[\"season\", \"week\", \"team\"], how=\"left\")\n",
    "\n",
    "if df[\"load_nonscore\"].isna().any():\n",
    "    raise RuntimeError(\"load_nonscore has nulls after merge, check join keys or the load column\")\n",
    "\n",
    "df = df.sort_values([\"season\", \"team\", \"week\"]).reset_index(drop=True)\n",
    "\n",
    "g = df.groupby([\"season\", \"team\"], sort=False)\n",
    "\n",
    "mean_prior = g[\"load_nonscore\"].apply(lambda s: s.expanding().mean().shift(1)).reset_index(level=[0,1], drop=True)\n",
    "sd_prior = g[\"load_nonscore\"].apply(lambda s: s.expanding().std(ddof=1).shift(1)).reset_index(level=[0,1], drop=True)\n",
    "\n",
    "z_prior = (df[\"load_nonscore\"] - mean_prior) / sd_prior\n",
    "shock_prior = (z_prior >= 1).astype(float)\n",
    "shock_prior = shock_prior.fillna(0).astype(int)\n",
    "\n",
    "df[\"ST_Shock_NonScore_w\"] = shock_prior\n",
    "df[\"shock_nonscore\"] = df[\"ST_Shock_NonScore_w\"].astype(int)\n",
    "df[\"shock_x_blowout\"] = (df[\"shock_nonscore\"] * df[\"blowout_flag_w\"]).astype(int)\n",
    "\n",
    "lag_map = {\n",
    "    \"ST_Shock_NonScore_w_minus_1\": 1,\n",
    "    \"ST_Shock_NonScore_w_minus_2\": 2,\n",
    "    \"ST_Shock_NonScore_w_minus_3\": 3,\n",
    "}\n",
    "for col, k in lag_map.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = g[\"ST_Shock_NonScore_w\"].shift(k).fillna(0).astype(int)\n",
    "\n",
    "con.register(\"step16_modeling_frame_nolookahead_tmp\", df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step16_modeling_frame_nolookahead AS SELECT * FROM step16_modeling_frame_nolookahead_tmp\")\n",
    "con.unregister(\"step16_modeling_frame_nolookahead_tmp\")\n",
    "\n",
    "print(\"wrote duckdb table step16_modeling_frame_nolookahead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe8364-0c01-4759-9cea-98c02d0bf01b",
   "metadata": {},
   "source": [
    "We overwrite the patched table by recomputing the prior weeks only shock entirely inside DuckDB using the exact sd equals zero rule and then regenerate the lag shocks and shock interaction fields from that exact shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcf418d-8379-49d9-8f42-183a89d8cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebuilt step16_modeling_frame_nolookahead using duckdb prior only shock rule\n"
     ]
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE step16_modeling_frame_nolookahead AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    AVG(load_nonscore) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS mean_prior,\n",
    "    STDDEV_SAMP(load_nonscore) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS sd_prior\n",
    "  FROM step16_modeling_frame_nolookahead\n",
    "),\n",
    "calc AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN sd_prior IS NULL OR sd_prior = 0 THEN NULL\n",
    "      ELSE (load_nonscore - mean_prior) / sd_prior\n",
    "    END AS z_prior\n",
    "  FROM base\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN z_prior IS NULL THEN 0\n",
    "      WHEN z_prior >= 1 THEN 1\n",
    "      ELSE 0\n",
    "    END AS shock_prior_only\n",
    "  FROM calc\n",
    ")\n",
    "SELECT\n",
    "  * REPLACE (\n",
    "    shock_prior_only AS ST_Shock_NonScore_w,\n",
    "    COALESCE(LAG(shock_prior_only, 1) OVER (PARTITION BY season, team ORDER BY week), 0) AS ST_Shock_NonScore_w_minus_1,\n",
    "    COALESCE(LAG(shock_prior_only, 2) OVER (PARTITION BY season, team ORDER BY week), 0) AS ST_Shock_NonScore_w_minus_2,\n",
    "    COALESCE(LAG(shock_prior_only, 3) OVER (PARTITION BY season, team ORDER BY week), 0) AS ST_Shock_NonScore_w_minus_3,\n",
    "    shock_prior_only AS shock_nonscore,\n",
    "    (shock_prior_only * blowout_flag_w) AS shock_x_blowout\n",
    "  )\n",
    "FROM final\n",
    "\"\"\")\n",
    "\n",
    "print(\"rebuilt step16_modeling_frame_nolookahead using duckdb prior only shock rule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ffa2b-34bb-45bc-a971-9011db6d46e7",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm the mismatch count is now zero under the same DuckDB prior weeks only rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbcb08ee-44fa-4d67-af92-4f36fb26b842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_mismatch</th>\n",
       "      <th>mismatch_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_mismatch  mismatch_rate\n",
       "0         0.0            0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch = con.execute(\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    load_nonscore,\n",
    "    ST_Shock_NonScore_w AS shock_patched,\n",
    "    AVG(load_nonscore) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS mean_prior,\n",
    "    STDDEV_SAMP(load_nonscore) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS sd_prior\n",
    "  FROM step16_modeling_frame_nolookahead\n",
    "),\n",
    "calc AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN sd_prior IS NULL OR sd_prior = 0 THEN NULL\n",
    "      ELSE (load_nonscore - mean_prior) / sd_prior\n",
    "    END AS z_prior\n",
    "  FROM base\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN z_prior IS NULL THEN 0\n",
    "      WHEN z_prior >= 1 THEN 1\n",
    "      ELSE 0\n",
    "    END AS shock_prior_only\n",
    "  FROM calc\n",
    ")\n",
    "SELECT\n",
    "  SUM(CASE WHEN shock_patched != shock_prior_only THEN 1 ELSE 0 END) AS n_mismatch,\n",
    "  CAST(SUM(CASE WHEN shock_patched != shock_prior_only THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*) AS mismatch_rate\n",
    "FROM final\n",
    "\"\"\").df()\n",
    "\n",
    "mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e4cda-64bb-4682-b58e-8f33c6da53f2",
   "metadata": {},
   "source": [
    "We compute the first pass mean and variance checks for both outcomes so that we can see unconditional overdispersion before running model based tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b43d83-ccc8-412e-a3f2-01e871d19114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defense outcome Inj_Def_Next_w\n",
      "mean 2.083865546218487\n",
      "var 2.380761656150105\n",
      "var_over_mean 1.1424737361152615\n",
      "share_zero 0.15529411764705883\n",
      "max 10.0\n",
      "\n",
      "offense outcome Inj_Off_Next_w\n",
      "mean 1.9201680672268908\n",
      "var 2.1612169830110557\n",
      "var_over_mean 1.125535321568121\n",
      "share_zero 0.17714285714285713\n",
      "max 9.0\n"
     ]
    }
   ],
   "source": [
    "def outcome_dispersion_stats(y: pd.Series) -> dict:\n",
    "    y = y.astype(float)\n",
    "    mean = float(y.mean())\n",
    "    var = float(y.var(ddof=1))\n",
    "    share_zero = float((y == 0).mean())\n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"var\": var,\n",
    "        \"var_over_mean\": (var / mean) if mean > 0 else np.nan,\n",
    "        \"share_zero\": share_zero,\n",
    "        \"max\": float(y.max()),\n",
    "    }\n",
    "\n",
    "stats_def = outcome_dispersion_stats(df[OUTCOME_DEF])\n",
    "stats_off = outcome_dispersion_stats(df[OUTCOME_OFF])\n",
    "\n",
    "print(\"defense outcome\", OUTCOME_DEF)\n",
    "for k in [\"mean\", \"var\", \"var_over_mean\", \"share_zero\", \"max\"]:\n",
    "    print(k, stats_def[k])\n",
    "\n",
    "print()\n",
    "print(\"offense outcome\", OUTCOME_OFF)\n",
    "for k in [\"mean\", \"var\", \"var_over_mean\", \"share_zero\", \"max\"]:\n",
    "    print(k, stats_off[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47656532-8416-48b6-9c3c-2feeeb6222be",
   "metadata": {},
   "source": [
    "We fit Poisson and Negative Binomial versions of Models A and B using the same predictor blocks and fixed effects structure and store the preferred script spec that matches the existing selection rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c247ca-778a-441b-87bd-70e45c2e42a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit ok Inj_Def_Next_w points_for_diff\n",
      "fit ok Inj_Def_Next_w points_against_diff\n",
      "fit ok Inj_Def_Next_w points_for_against\n",
      "fit ok Inj_Off_Next_w points_for_diff\n",
      "fit ok Inj_Off_Next_w points_against_diff\n",
      "fit ok Inj_Off_Next_w points_for_against\n",
      "\n",
      "selected Model A spec points_for_diff\n",
      "Inj_Def_Next_w ~ shock_nonscore + shock_x_blowout + ST_Vol_NonScore_w + Cum_Shocks_NonScore_w + ST_Shock_NonScore_w_minus_1 + ST_Shock_NonScore_w_minus_2 + ST_Shock_NonScore_w_minus_3 + offensive_snaps_w + defensive_snaps_w + blowout_flag_w + short_week_flag_w + bye_last_week_flag_w + home_flag_w + off_yards_per_play_w + Inj_Def_Last_w + Cumulative_Workload_Index_w + points_for + score_diff_w + C(team) + C(season_week)\n",
      "\n",
      "selected Model B spec points_for_diff\n",
      "Inj_Off_Next_w ~ shock_nonscore + shock_x_blowout + ST_Vol_NonScore_w + Cum_Shocks_NonScore_w + ST_Shock_NonScore_w_minus_1 + ST_Shock_NonScore_w_minus_2 + ST_Shock_NonScore_w_minus_3 + offensive_snaps_w + defensive_snaps_w + blowout_flag_w + short_week_flag_w + bye_last_week_flag_w + home_flag_w + off_yards_per_play_w + Inj_Off_Last_w + Cumulative_Workload_Index_w + points_for + score_diff_w + C(team) + C(season_week)\n",
      "\n",
      "defense nb alpha hat 0.006968064664028101\n",
      "\n",
      "offense nb alpha hat 1e-08\n"
     ]
    }
   ],
   "source": [
    "FE_TEAM = \"C(team)\"\n",
    "FE_TIME = \"C(season_week)\"\n",
    "cluster_groups = df[\"team\"]\n",
    "\n",
    "OUTCOME_DEF_USED = OUTCOME_DEF\n",
    "OUTCOME_OFF_USED = OUTCOME_OFF\n",
    "\n",
    "exposure_terms = [\n",
    "    \"shock_nonscore\",\n",
    "    \"shock_x_blowout\",\n",
    "    \"ST_Vol_NonScore_w\",\n",
    "    \"Cum_Shocks_NonScore_w\",\n",
    "] + LAG_COLS\n",
    "\n",
    "control_terms_base_def = [\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    \"blowout_flag_w\",\n",
    "    \"short_week_flag_w\",\n",
    "    \"bye_last_week_flag_w\",\n",
    "    \"home_flag_w\",\n",
    "    \"off_yards_per_play_w\",\n",
    "    \"Inj_Def_Last_w\",\n",
    "    \"Cumulative_Workload_Index_w\",\n",
    "]\n",
    "\n",
    "control_terms_base_off = [\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    \"blowout_flag_w\",\n",
    "    \"short_week_flag_w\",\n",
    "    \"bye_last_week_flag_w\",\n",
    "    \"home_flag_w\",\n",
    "    \"off_yards_per_play_w\",\n",
    "    \"Inj_Off_Last_w\",\n",
    "    \"Cumulative_Workload_Index_w\",\n",
    "]\n",
    "\n",
    "script_specs = [\n",
    "    (\"points_for_diff\", [\"points_for\", \"score_diff_w\"]),\n",
    "    (\"points_against_diff\", [\"points_against\", \"score_diff_w\"]),\n",
    "    (\"points_for_against\", [\"points_for\", \"points_against\"]),\n",
    "]\n",
    "\n",
    "preferred_order = [\"points_for_diff\", \"points_against_diff\", \"points_for_against\"]\n",
    "\n",
    "def build_formula(outcome: str, base_controls: list[str], script_terms: list[str]) -> str:\n",
    "    rhs = exposure_terms + base_controls + script_terms + [FE_TEAM, FE_TIME]\n",
    "    return outcome + \" ~ \" + \" + \".join(rhs)\n",
    "\n",
    "def fit_count_model_poisson_glm(formula: str, data: pd.DataFrame, groups: pd.Series, maxiter: int = 200):\n",
    "    m = smf.glm(formula=formula, data=data, family=sm.families.Poisson())\n",
    "    r = m.fit(maxiter=maxiter, cov_type=\"cluster\", cov_kwds={\"groups\": groups})\n",
    "    return r\n",
    "\n",
    "def estimate_nb2_alpha_moments(y: np.ndarray, mu: np.ndarray) -> float:\n",
    "    y = y.astype(float)\n",
    "    mu = mu.astype(float)\n",
    "    den = float(np.sum(mu ** 2))\n",
    "    if den <= 0:\n",
    "        return 1e-8\n",
    "    num = float(np.sum((y - mu) ** 2 - mu))\n",
    "    alpha = num / den\n",
    "    if not np.isfinite(alpha):\n",
    "        alpha = 1e-8\n",
    "    alpha = float(max(alpha, 1e-8))\n",
    "    alpha = float(min(alpha, 50.0))\n",
    "    return alpha\n",
    "\n",
    "def fit_count_model_negative_binomial_glm_nb2(formula: str, data: pd.DataFrame, groups: pd.Series, alpha: float, maxiter: int = 200):\n",
    "    fam = sm.families.NegativeBinomial(alpha=alpha)\n",
    "    m = smf.glm(formula=formula, data=data, family=fam)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=HessianInversionWarning)\n",
    "        r = m.fit(maxiter=maxiter, cov_type=\"cluster\", cov_kwds={\"groups\": groups})\n",
    "\n",
    "    return r\n",
    "\n",
    "def fit_model_grid(outcome: str, base_controls: list[str]) -> tuple[str, str, object, object]:\n",
    "    fits = []\n",
    "    for tag, script_terms in script_specs:\n",
    "        f = build_formula(outcome, base_controls, script_terms)\n",
    "\n",
    "        pois = None\n",
    "        nb = None\n",
    "\n",
    "        try:\n",
    "            pois = fit_count_model_poisson_glm(f, df, cluster_groups)\n",
    "        except Exception as e:\n",
    "            print(\"poisson failed\", outcome, tag, str(e))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            y = df[outcome].to_numpy()\n",
    "            mu = np.asarray(pois.mu)\n",
    "            alpha_hat = estimate_nb2_alpha_moments(y, mu)\n",
    "\n",
    "            nb = fit_count_model_negative_binomial_glm_nb2(\n",
    "                f,\n",
    "                df,\n",
    "                cluster_groups,\n",
    "                alpha=alpha_hat,\n",
    "                maxiter=200,\n",
    "            )\n",
    "\n",
    "            nb._alpha_hat_mom = alpha_hat\n",
    "        except Exception as e:\n",
    "            print(\"negative binomial glm failed\", outcome, tag, str(e))\n",
    "\n",
    "        fits.append((tag, f, pois, nb))\n",
    "        print(\"fit ok\", outcome, tag)\n",
    "\n",
    "    if len(fits) == 0:\n",
    "        raise RuntimeError(f\"No specifications fit successfully for {outcome}\")\n",
    "\n",
    "    fits_sorted = sorted(\n",
    "        fits,\n",
    "        key=lambda x: preferred_order.index(x[0]) if x[0] in preferred_order else 999\n",
    "    )\n",
    "    return fits_sorted[0]\n",
    "\n",
    "spec_tag_def, formula_def_used, pois_def, nb_def = fit_model_grid(OUTCOME_DEF_USED, control_terms_base_def)\n",
    "spec_tag_off, formula_off_used, pois_off, nb_off = fit_model_grid(OUTCOME_OFF_USED, control_terms_base_off)\n",
    "\n",
    "print()\n",
    "print(\"selected Model A spec\", spec_tag_def)\n",
    "print(formula_def_used)\n",
    "print()\n",
    "print(\"selected Model B spec\", spec_tag_off)\n",
    "print(formula_off_used)\n",
    "\n",
    "if nb_def is not None:\n",
    "    print()\n",
    "    print(\"defense nb alpha hat\", float(getattr(nb_def, \"_alpha_hat_mom\", np.nan)))\n",
    "\n",
    "if nb_off is not None:\n",
    "    print()\n",
    "    print(\"offense nb alpha hat\", float(getattr(nb_off, \"_alpha_hat_mom\", np.nan)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd4a20-12a9-47f7-aedd-8ca061e75b39",
   "metadata": {},
   "source": [
    "We run model based overdispersion diagnostics for each Poisson fit using Pearson dispersion and an approximate z test so the decision is not based only on unconditional variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a6c5041-2151-4fa8-a306-4ac59cff32fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson overdispersion diagnostics, defense\n",
      "pearson_dispersion 1.0702385173098001\n",
      "pearson_z 3.745102989152402\n",
      "pearson_pvalue 0.0001803197892711328\n",
      "deviance_dispersion 1.2057215163718396\n",
      "aic 20851.390060074904\n",
      "bic 22617.85273568938\n",
      "llf -10161.695030037452\n",
      "nobs 5950\n",
      "\n",
      "poisson overdispersion diagnostics, offense\n",
      "pearson_dispersion 1.0460705408275417\n",
      "pearson_z 2.456471559672583\n",
      "pearson_pvalue 0.014030890765233117\n",
      "deviance_dispersion 1.1989179938122556\n",
      "aic 20223.29171279013\n",
      "bic 21989.754388404606\n",
      "llf -9847.645856395065\n",
      "nobs 5950\n"
     ]
    }
   ],
   "source": [
    "def poisson_overdispersion_diagnostics(res) -> dict:\n",
    "    chi2 = float(res.pearson_chi2)\n",
    "    df_resid = float(res.df_resid)\n",
    "    ratio = chi2 / df_resid if df_resid > 0 else np.nan\n",
    "\n",
    "    z = (chi2 - df_resid) / np.sqrt(2.0 * df_resid) if df_resid > 0 else np.nan\n",
    "    p = float(2.0 * (1.0 - stats.norm.cdf(abs(z)))) if np.isfinite(z) else np.nan\n",
    "\n",
    "    dev = float(res.deviance)\n",
    "    dev_ratio = dev / df_resid if df_resid > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"pearson_chi2\": chi2,\n",
    "        \"df_resid\": df_resid,\n",
    "        \"pearson_dispersion\": ratio,\n",
    "        \"pearson_z\": float(z) if np.isfinite(z) else np.nan,\n",
    "        \"pearson_pvalue\": p,\n",
    "        \"deviance\": dev,\n",
    "        \"deviance_dispersion\": dev_ratio,\n",
    "        \"aic\": float(getattr(res, \"aic\", np.nan)),\n",
    "        \"bic\": float(getattr(res, \"bic\", np.nan)),\n",
    "        \"llf\": float(getattr(res, \"llf\", np.nan)),\n",
    "        \"nobs\": int(getattr(res, \"nobs\", np.nan)),\n",
    "    }\n",
    "\n",
    "diag_def = poisson_overdispersion_diagnostics(pois_def)\n",
    "diag_off = poisson_overdispersion_diagnostics(pois_off)\n",
    "\n",
    "print(\"poisson overdispersion diagnostics, defense\")\n",
    "for k in [\"pearson_dispersion\", \"pearson_z\", \"pearson_pvalue\", \"deviance_dispersion\", \"aic\", \"bic\", \"llf\", \"nobs\"]:\n",
    "    print(k, diag_def[k])\n",
    "\n",
    "print()\n",
    "print(\"poisson overdispersion diagnostics, offense\")\n",
    "for k in [\"pearson_dispersion\", \"pearson_z\", \"pearson_pvalue\", \"deviance_dispersion\", \"aic\", \"bic\", \"llf\", \"nobs\"]:\n",
    "    print(k, diag_off[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001db89a-1738-4228-99fb-5274ed9768b0",
   "metadata": {},
   "source": [
    "We formalize the family choice rule and export a diagnostics table plus the selected family results for Models A and B to DuckDB and csv so that the later steps always reference a single preferred count model per side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2bb54c9-0120-4975-84f8-c1076fd22932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family choice defense poisson\n",
      "reason defense no strong overdispersion signal, or NB failed\n",
      "\n",
      "family choice offense poisson\n",
      "reason offense no strong overdispersion signal, or NB failed\n",
      "wrote duckdb table step16_overdispersion_diagnostics\n",
      "wrote duckdb table step16_selected_count_results\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step16_overdispersion_diagnostics.csv\n",
      "wrote csv /Users/ramko/Desktop/2025-26-NFLPA-Data-Analytics-Case-Competition/outputs/step16_selected_count_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>spec_tag</th>\n",
       "      <th>formula_used</th>\n",
       "      <th>outcome_mean</th>\n",
       "      <th>outcome_var</th>\n",
       "      <th>outcome_var_over_mean</th>\n",
       "      <th>poisson_pearson_dispersion</th>\n",
       "      <th>poisson_pearson_pvalue</th>\n",
       "      <th>poisson_deviance_dispersion</th>\n",
       "      <th>poisson_aic</th>\n",
       "      <th>poisson_bic</th>\n",
       "      <th>nb_aic</th>\n",
       "      <th>nb_bic</th>\n",
       "      <th>nb_alpha</th>\n",
       "      <th>family_choice</th>\n",
       "      <th>choice_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>defense</td>\n",
       "      <td>points_for_diff</td>\n",
       "      <td>Inj_Def_Next_w ~ shock_nonscore + shock_x_blow...</td>\n",
       "      <td>2.083866</td>\n",
       "      <td>2.380762</td>\n",
       "      <td>1.142474</td>\n",
       "      <td>1.070239</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>1.205722</td>\n",
       "      <td>20851.390060</td>\n",
       "      <td>22617.852736</td>\n",
       "      <td>20850.718178</td>\n",
       "      <td>22617.180853</td>\n",
       "      <td>6.968065e-03</td>\n",
       "      <td>poisson</td>\n",
       "      <td>no strong overdispersion signal, or NB failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offense</td>\n",
       "      <td>points_for_diff</td>\n",
       "      <td>Inj_Off_Next_w ~ shock_nonscore + shock_x_blow...</td>\n",
       "      <td>1.920168</td>\n",
       "      <td>2.161217</td>\n",
       "      <td>1.125535</td>\n",
       "      <td>1.046071</td>\n",
       "      <td>0.014031</td>\n",
       "      <td>1.198918</td>\n",
       "      <td>20223.291713</td>\n",
       "      <td>21989.754388</td>\n",
       "      <td>20223.292511</td>\n",
       "      <td>21989.755186</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>poisson</td>\n",
       "      <td>no strong overdispersion signal, or NB failed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      side         spec_tag  \\\n",
       "0  defense  points_for_diff   \n",
       "1  offense  points_for_diff   \n",
       "\n",
       "                                        formula_used  outcome_mean  \\\n",
       "0  Inj_Def_Next_w ~ shock_nonscore + shock_x_blow...      2.083866   \n",
       "1  Inj_Off_Next_w ~ shock_nonscore + shock_x_blow...      1.920168   \n",
       "\n",
       "   outcome_var  outcome_var_over_mean  poisson_pearson_dispersion  \\\n",
       "0     2.380762               1.142474                    1.070239   \n",
       "1     2.161217               1.125535                    1.046071   \n",
       "\n",
       "   poisson_pearson_pvalue  poisson_deviance_dispersion   poisson_aic  \\\n",
       "0                0.000180                     1.205722  20851.390060   \n",
       "1                0.014031                     1.198918  20223.291713   \n",
       "\n",
       "    poisson_bic        nb_aic        nb_bic      nb_alpha family_choice  \\\n",
       "0  22617.852736  20850.718178  22617.180853  6.968065e-03       poisson   \n",
       "1  21989.754388  20223.292511  21989.755186  1.000000e-08       poisson   \n",
       "\n",
       "                                   choice_reason  \n",
       "0  no strong overdispersion signal, or NB failed  \n",
       "1  no strong overdispersion signal, or NB failed  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_nb_alpha(res) -> float:\n",
    "    if res is None:\n",
    "        return np.nan\n",
    "    if hasattr(res, \"_alpha_hat_mom\"):\n",
    "        try:\n",
    "            return float(res._alpha_hat_mom)\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        fam = getattr(getattr(res, \"model\", None), \"family\", None)\n",
    "        if fam is not None and hasattr(fam, \"alpha\"):\n",
    "            return float(fam.alpha)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        if hasattr(res, \"params\") and (\"alpha\" in res.params.index):\n",
    "            return float(res.params[\"alpha\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.nan\n",
    "\n",
    "alpha_def = extract_nb_alpha(nb_def)\n",
    "alpha_off = extract_nb_alpha(nb_off)\n",
    "\n",
    "nb_meta_def = {\n",
    "    \"aic\": float(getattr(nb_def, \"aic\", np.nan)) if nb_def is not None else np.nan,\n",
    "    \"bic\": float(getattr(nb_def, \"bic\", np.nan)) if nb_def is not None else np.nan,\n",
    "    \"llf\": float(getattr(nb_def, \"llf\", np.nan)) if nb_def is not None else np.nan,\n",
    "    \"nobs\": int(getattr(nb_def, \"nobs\", np.nan)) if nb_def is not None else np.nan,\n",
    "    \"alpha\": alpha_def,\n",
    "}\n",
    "nb_meta_off = {\n",
    "    \"aic\": float(getattr(nb_off, \"aic\", np.nan)) if nb_off is not None else np.nan,\n",
    "    \"bic\": float(getattr(nb_off, \"bic\", np.nan)) if nb_off is not None else np.nan,\n",
    "    \"llf\": float(getattr(nb_off, \"llf\", np.nan)) if nb_off is not None else np.nan,\n",
    "    \"nobs\": int(getattr(nb_off, \"nobs\", np.nan)) if nb_off is not None else np.nan,\n",
    "    \"alpha\": alpha_off,\n",
    "}\n",
    "\n",
    "def choose_family(uncond_stats: dict, pois_diag: dict, nb_res) -> tuple[str, str]:\n",
    "    var_over_mean = float(uncond_stats.get(\"var_over_mean\", np.nan))\n",
    "    pearson_disp = float(pois_diag.get(\"pearson_dispersion\", np.nan))\n",
    "    pval = float(pois_diag.get(\"pearson_pvalue\", np.nan))\n",
    "\n",
    "    overdisp_uncond = np.isfinite(var_over_mean) and (var_over_mean >= 1.5)\n",
    "    overdisp_model = np.isfinite(pearson_disp) and np.isfinite(pval) and (pearson_disp >= 1.2) and (pval < 0.05)\n",
    "\n",
    "    if (overdisp_uncond or overdisp_model) and (nb_res is not None):\n",
    "        return \"negative_binomial\", \"overdispersion flagged by unconditional or model based test\"\n",
    "    return \"poisson\", \"no strong overdispersion signal, or NB failed\"\n",
    "\n",
    "choice_def, reason_def = choose_family(stats_def, diag_def, nb_def)\n",
    "choice_off, reason_off = choose_family(stats_off, diag_off, nb_off)\n",
    "\n",
    "print(\"family choice defense\", choice_def)\n",
    "print(\"reason defense\", reason_def)\n",
    "print()\n",
    "print(\"family choice offense\", choice_off)\n",
    "print(\"reason offense\", reason_off)\n",
    "\n",
    "def tidy_count_res(res, model_name: str, outcome_name: str, spec_tag: str, key_terms: list[str]) -> pd.DataFrame:\n",
    "    params = res.params.copy()\n",
    "    bse = res.bse.copy()\n",
    "    pvals = res.pvalues.copy()\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"model\": model_name,\n",
    "        \"spec_tag\": spec_tag,\n",
    "        \"outcome\": outcome_name,\n",
    "        \"term\": params.index.astype(str),\n",
    "        \"beta\": params.values.astype(float),\n",
    "        \"se_cluster\": bse.values.astype(float),\n",
    "        \"pvalue\": pvals.values.astype(float),\n",
    "    })\n",
    "\n",
    "    out[\"nobs\"] = int(getattr(res, \"nobs\", np.nan))\n",
    "    out[\"aic\"] = float(getattr(res, \"aic\", np.nan))\n",
    "    out[\"bic\"] = float(getattr(res, \"bic\", np.nan))\n",
    "    out[\"llf\"] = float(getattr(res, \"llf\", np.nan))\n",
    "\n",
    "    out[\"irr\"] = np.exp(out[\"beta\"].astype(float))\n",
    "    out[\"irr_ci_lo\"] = np.exp(out[\"beta\"].astype(float) - 1.96 * out[\"se_cluster\"].astype(float))\n",
    "    out[\"irr_ci_hi\"] = np.exp(out[\"beta\"].astype(float) + 1.96 * out[\"se_cluster\"].astype(float))\n",
    "\n",
    "    key_keep = set(key_terms)\n",
    "    out[\"is_key_term\"] = out[\"term\"].apply(lambda x: 1 if x in key_keep else 0)\n",
    "    return out\n",
    "\n",
    "key_terms = exposure_terms\n",
    "\n",
    "selected_def_res = nb_def if choice_def == \"negative_binomial\" else pois_def\n",
    "selected_off_res = nb_off if choice_off == \"negative_binomial\" else pois_off\n",
    "\n",
    "selected_def_name = f\"{choice_def}_modelA_selected\"\n",
    "selected_off_name = f\"{choice_off}_modelB_selected\"\n",
    "\n",
    "selected_def_df = tidy_count_res(selected_def_res, selected_def_name, OUTCOME_DEF_USED, spec_tag_def, key_terms)\n",
    "selected_off_df = tidy_count_res(selected_off_res, selected_off_name, OUTCOME_OFF_USED, spec_tag_off, key_terms)\n",
    "\n",
    "final_selected = pd.concat([selected_def_df, selected_off_df], ignore_index=True)\n",
    "\n",
    "diag_rows = []\n",
    "diag_rows.append({\n",
    "    \"side\": \"defense\",\n",
    "    \"spec_tag\": spec_tag_def,\n",
    "    \"formula_used\": formula_def_used,\n",
    "    \"outcome_mean\": stats_def[\"mean\"],\n",
    "    \"outcome_var\": stats_def[\"var\"],\n",
    "    \"outcome_var_over_mean\": stats_def[\"var_over_mean\"],\n",
    "    \"poisson_pearson_dispersion\": diag_def[\"pearson_dispersion\"],\n",
    "    \"poisson_pearson_pvalue\": diag_def[\"pearson_pvalue\"],\n",
    "    \"poisson_deviance_dispersion\": diag_def[\"deviance_dispersion\"],\n",
    "    \"poisson_aic\": diag_def[\"aic\"],\n",
    "    \"poisson_bic\": diag_def[\"bic\"],\n",
    "    \"nb_aic\": nb_meta_def[\"aic\"],\n",
    "    \"nb_bic\": nb_meta_def[\"bic\"],\n",
    "    \"nb_alpha\": nb_meta_def[\"alpha\"],\n",
    "    \"family_choice\": choice_def,\n",
    "    \"choice_reason\": reason_def,\n",
    "})\n",
    "diag_rows.append({\n",
    "    \"side\": \"offense\",\n",
    "    \"spec_tag\": spec_tag_off,\n",
    "    \"formula_used\": formula_off_used,\n",
    "    \"outcome_mean\": stats_off[\"mean\"],\n",
    "    \"outcome_var\": stats_off[\"var\"],\n",
    "    \"outcome_var_over_mean\": stats_off[\"var_over_mean\"],\n",
    "    \"poisson_pearson_dispersion\": diag_off[\"pearson_dispersion\"],\n",
    "    \"poisson_pearson_pvalue\": diag_off[\"pearson_pvalue\"],\n",
    "    \"poisson_deviance_dispersion\": diag_off[\"deviance_dispersion\"],\n",
    "    \"poisson_aic\": diag_off[\"aic\"],\n",
    "    \"poisson_bic\": diag_off[\"bic\"],\n",
    "    \"nb_aic\": nb_meta_off[\"aic\"],\n",
    "    \"nb_bic\": nb_meta_off[\"bic\"],\n",
    "    \"nb_alpha\": nb_meta_off[\"alpha\"],\n",
    "    \"family_choice\": choice_off,\n",
    "    \"choice_reason\": reason_off,\n",
    "})\n",
    "\n",
    "diag_df = pd.DataFrame(diag_rows)\n",
    "\n",
    "con.register(\"step16_overdisp_tmp\", diag_df)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step16_overdispersion_diagnostics AS SELECT * FROM step16_overdisp_tmp\")\n",
    "con.unregister(\"step16_overdisp_tmp\")\n",
    "\n",
    "con.register(\"step16_selected_tmp\", final_selected)\n",
    "con.execute(\"CREATE OR REPLACE TABLE step16_selected_count_results AS SELECT * FROM step16_selected_tmp\")\n",
    "con.unregister(\"step16_selected_tmp\")\n",
    "\n",
    "out_dir = Path(\"../outputs\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "diag_csv = out_dir / \"step16_overdispersion_diagnostics.csv\"\n",
    "sel_csv = out_dir / \"step16_selected_count_results.csv\"\n",
    "\n",
    "diag_df.to_csv(diag_csv, index=False)\n",
    "final_selected.to_csv(sel_csv, index=False)\n",
    "\n",
    "print(\"wrote duckdb table step16_overdispersion_diagnostics\")\n",
    "print(\"wrote duckdb table step16_selected_count_results\")\n",
    "print(\"wrote csv\", diag_csv.resolve())\n",
    "print(\"wrote csv\", sel_csv.resolve())\n",
    "\n",
    "diag_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029051af-d2e3-412f-8480-d87bf88cb5ce",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the outputs exist in DuckDB, the selected results table contains one selected model per side, and key exposure terms are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bc062c7-ccee-4260-a7f3-7f2786501eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>n_models</th>\n",
       "      <th>n_key_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inj_Def_Next_w</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inj_Off_Next_w</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          outcome  n_models  n_key_rows\n",
       "0  Inj_Def_Next_w         1         7.0\n",
       "1  Inj_Off_Next_w         1         7.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  table_name\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'main'\n",
    "  AND table_name IN ('step16_modeling_frame', 'step16_overdispersion_diagnostics', 'step16_selected_count_results')\n",
    "ORDER BY table_name\n",
    "\"\"\").df()\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  outcome,\n",
    "  COUNT(DISTINCT model) AS n_models,\n",
    "  SUM(CASE WHEN is_key_term = 1 THEN 1 ELSE 0 END) AS n_key_rows\n",
    "FROM step16_selected_count_results\n",
    "GROUP BY 1\n",
    "ORDER BY outcome\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c9cfe-77a2-49f0-ab47-a68a262aae86",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'ST_Shock_NonScore_w' is not using full season lookahead by comparing it to a prior weeks only shock rebuild. We also confirm that the Poisson choice rule is driven by dispersion ratios not just p values. We finally confirm the number of cluster groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb41983-3acb-49c2-b747-85bda089ecd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   n_rows  n_null_prior_only  n_comparable  n_mismatch  mismatch_rate\n",
       " 0    5950             1088.0        4862.0       379.0       0.077951,\n",
       "     season  week team  load_nonscore  mean_prior  sd_prior   z_prior  \\\n",
       " 0     2012     4  ARI           20.0   15.333333  2.309401  2.020726   \n",
       " 1     2012    14  ARI           20.0   17.090909  1.814086  1.603612   \n",
       " 2     2012    15  ARI           20.0   17.333333  1.922751  1.386902   \n",
       " 3     2012     4  ATL           16.0   11.000000  4.000000  1.250000   \n",
       " 4     2012     4  BAL           19.0   13.000000  2.645751  2.267787   \n",
       " 5     2012     9  BAL           17.0   13.666667  3.204164  1.040313   \n",
       " 6     2012    11  BAL           19.0   14.125000  2.948971  1.653119   \n",
       " 7     2012     4  BUF           18.0   16.333333  2.081666  0.800641   \n",
       " 8     2012    14  BUF           18.0   15.818182  2.400757  0.908804   \n",
       " 9     2012    10  CHI           17.0   14.000000  2.516611  1.192079   \n",
       " 10    2012    14  CHI           17.0   14.181818  2.442056  1.154020   \n",
       " 11    2012     3  CIN           17.0   14.000000  1.414214  2.121320   \n",
       " 12    2012    12  CLE           19.0   16.888889  2.420973  0.872009   \n",
       " 13    2012     6  DET           18.0   13.333333  1.154701  4.041452   \n",
       " 14    2012    10  DET           19.0   14.285714  4.029652  1.169899   \n",
       " 15    2012    13  DET           20.0   15.200000  4.237400  1.132770   \n",
       " 16    2012    14  HOU           19.0   16.636364  2.500909  0.945111   \n",
       " 17    2012     4  MIA           18.0   16.666667  2.886751  0.461880   \n",
       " 18    2012    10  MIA           18.0   16.000000  2.581989  0.774597   \n",
       " 19    2012    11  MIA           18.0   16.250000  2.492847  0.702009   \n",
       " 20    2012     7  MIN           16.0   13.666667  2.250926  1.036611   \n",
       " 21    2012    14  MIN           17.0   14.545455  2.544156  0.964778   \n",
       " 22    2012     3   NO           18.0   16.500000  2.121320  0.707107   \n",
       " 23    2012     6  PIT           14.0   12.000000  1.732051  1.154701   \n",
       " 24    2012     9  PIT           14.0   12.333333  1.505545  1.107019   \n",
       " \n",
       "     shock_current  shock_prior_only  \n",
       " 0               0                 1  \n",
       " 1               0                 1  \n",
       " 2               0                 1  \n",
       " 3               0                 1  \n",
       " 4               0                 1  \n",
       " 5               0                 1  \n",
       " 6               0                 1  \n",
       " 7               1                 0  \n",
       " 8               1                 0  \n",
       " 9               0                 1  \n",
       " 10              0                 1  \n",
       " 11              0                 1  \n",
       " 12              1                 0  \n",
       " 13              0                 1  \n",
       " 14              0                 1  \n",
       " 15              0                 1  \n",
       " 16              1                 0  \n",
       " 17              1                 0  \n",
       " 18              1                 0  \n",
       " 19              1                 0  \n",
       " 20              0                 1  \n",
       " 21              1                 0  \n",
       " 22              1                 0  \n",
       " 23              0                 1  \n",
       " 24              0                 1  ,\n",
       "       side  poisson_pearson_dispersion  poisson_pearson_pvalue  \\\n",
       " 0  defense                    1.070239                0.000180   \n",
       " 1  offense                    1.046071                0.014031   \n",
       " \n",
       "    poisson_deviance_dispersion      nb_alpha   poisson_aic        nb_aic  \\\n",
       " 0                     1.205722  6.968065e-03  20851.390060  20850.718178   \n",
       " 1                     1.198918  1.000000e-08  20223.291713  20223.292511   \n",
       " \n",
       "    overdisp_by_ratio_rule  would_flip_if_using_p_only  \n",
       " 0                       0                           1  \n",
       " 1                       0                           1  ,\n",
       "    n_clusters  min_rows_per_team  max_rows_per_team  avg_rows_per_team\n",
       " 0          35                 56                187              170.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "load_candidates = [\n",
    "    \"ST_Load_NonScore_w\",\n",
    "    \"ST_Load_NonScore\",\n",
    "    \"ST_NonScore_Load_w\",\n",
    "    \"st_load_nonscore_w\",\n",
    "]\n",
    "LOAD_COL = None\n",
    "for c in load_candidates:\n",
    "    if c in cols:\n",
    "        LOAD_COL = c\n",
    "        break\n",
    "\n",
    "if LOAD_COL is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not find a NonScore load column in the model view, expected one of \"\n",
    "        + \", \".join(load_candidates)\n",
    "        + \", search DESCRIBE output for the exact name and add it to load_candidates\"\n",
    "    )\n",
    "\n",
    "lookahead_check = con.execute(f\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    {LOAD_COL} AS load_nonscore,\n",
    "    ST_Shock_NonScore_w AS shock_current,\n",
    "    AVG({LOAD_COL}) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS mean_prior,\n",
    "    STDDEV_SAMP({LOAD_COL}) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS sd_prior\n",
    "  FROM {MODEL_VIEW}\n",
    "  WHERE has_next_week = 1\n",
    "),\n",
    "calc AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN sd_prior IS NULL OR sd_prior = 0 THEN NULL\n",
    "      ELSE (load_nonscore - mean_prior) / sd_prior\n",
    "    END AS z_prior\n",
    "  FROM base\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN z_prior IS NULL THEN NULL\n",
    "      WHEN z_prior >= 1 THEN 1\n",
    "      ELSE 0\n",
    "    END AS shock_prior_only\n",
    "  FROM calc\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(CASE WHEN shock_prior_only IS NULL THEN 1 ELSE 0 END) AS n_null_prior_only,\n",
    "  SUM(CASE WHEN shock_prior_only IS NOT NULL AND shock_current IS NOT NULL THEN 1 ELSE 0 END) AS n_comparable,\n",
    "  SUM(CASE WHEN shock_prior_only IS NOT NULL AND shock_current IS NOT NULL AND shock_prior_only != shock_current THEN 1 ELSE 0 END) AS n_mismatch,\n",
    "  CAST(SUM(CASE WHEN shock_prior_only IS NOT NULL AND shock_current IS NOT NULL AND shock_prior_only != shock_current THEN 1 ELSE 0 END) AS DOUBLE)\n",
    "    / NULLIF(SUM(CASE WHEN shock_prior_only IS NOT NULL AND shock_current IS NOT NULL THEN 1 ELSE 0 END), 0) AS mismatch_rate\n",
    "FROM final\n",
    "\"\"\").df()\n",
    "\n",
    "lookahead_examples = con.execute(f\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    {LOAD_COL} AS load_nonscore,\n",
    "    ST_Shock_NonScore_w AS shock_current,\n",
    "    AVG({LOAD_COL}) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS mean_prior,\n",
    "    STDDEV_SAMP({LOAD_COL}) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS sd_prior\n",
    "  FROM {MODEL_VIEW}\n",
    "  WHERE has_next_week = 1\n",
    "),\n",
    "calc AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN sd_prior IS NULL OR sd_prior = 0 THEN NULL\n",
    "      ELSE (load_nonscore - mean_prior) / sd_prior\n",
    "    END AS z_prior\n",
    "  FROM base\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN z_prior IS NULL THEN NULL\n",
    "      WHEN z_prior >= 1 THEN 1\n",
    "      ELSE 0\n",
    "    END AS shock_prior_only\n",
    "  FROM calc\n",
    ")\n",
    "SELECT\n",
    "  season,\n",
    "  week,\n",
    "  team,\n",
    "  load_nonscore,\n",
    "  mean_prior,\n",
    "  sd_prior,\n",
    "  z_prior,\n",
    "  shock_current,\n",
    "  shock_prior_only\n",
    "FROM final\n",
    "WHERE shock_prior_only IS NOT NULL\n",
    "  AND shock_current IS NOT NULL\n",
    "  AND shock_prior_only != shock_current\n",
    "ORDER BY season, team, week\n",
    "LIMIT 25\n",
    "\"\"\").df()\n",
    "\n",
    "disp_rule = con.execute(\"\"\"\n",
    "SELECT\n",
    "  side,\n",
    "  poisson_pearson_dispersion,\n",
    "  poisson_pearson_pvalue,\n",
    "  poisson_deviance_dispersion,\n",
    "  nb_alpha,\n",
    "  poisson_aic,\n",
    "  nb_aic,\n",
    "  CASE\n",
    "    WHEN poisson_pearson_dispersion >= 1.2 AND poisson_pearson_pvalue < 0.05 THEN 1\n",
    "    ELSE 0\n",
    "  END AS overdisp_by_ratio_rule,\n",
    "  CASE\n",
    "    WHEN poisson_pearson_pvalue < 0.05 THEN 1\n",
    "    ELSE 0\n",
    "  END AS would_flip_if_using_p_only\n",
    "FROM step16_overdispersion_diagnostics\n",
    "ORDER BY side\n",
    "\"\"\").df()\n",
    "\n",
    "cluster_check = con.execute(\"\"\"\n",
    "WITH per_team AS (\n",
    "  SELECT\n",
    "    team,\n",
    "    COUNT(*) AS n_rows\n",
    "  FROM step16_modeling_frame\n",
    "  GROUP BY 1\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n_clusters,\n",
    "  MIN(n_rows) AS min_rows_per_team,\n",
    "  MAX(n_rows) AS max_rows_per_team,\n",
    "  AVG(n_rows) AS avg_rows_per_team\n",
    "FROM per_team\n",
    "\"\"\").df()\n",
    "\n",
    "lookahead_check, lookahead_examples, disp_rule, cluster_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041458f-4906-4d68-9441-8cd607663fe6",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm whether 'ST_Shock_NonScore_w' matches a full season within team season z score definition, which would indicate lookahead leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "542d37a7-3efc-4317-bee4-b38226508d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   n_rows  n_null_fullseason  n_comparable  n_mismatch  mismatch_rate\n",
       " 0    5950              238.0        5712.0       141.0       0.024685,\n",
       "     season  week team  load_nonscore  mean_full   sd_full    z_full  \\\n",
       " 0     2012     4  ATL           16.0  12.000000  3.762160  1.063219   \n",
       " 1     2012     5  ATL           16.0  12.000000  3.762160  1.063219   \n",
       " 2     2012     2  BUF           18.0  15.857143  2.248320  0.953092   \n",
       " 3     2012     4  BUF           18.0  15.857143  2.248320  0.953092   \n",
       " 4     2012    14  BUF           18.0  15.857143  2.248320  0.953092   \n",
       " 5     2012     3  HOU           19.0  16.571429  2.502746  0.970363   \n",
       " 6     2012    13  HOU           19.0  16.571429  2.502746  0.970363   \n",
       " 7     2012    14  HOU           19.0  16.571429  2.502746  0.970363   \n",
       " 8     2012     4  MIA           18.0  15.071429  3.197698  0.915837   \n",
       " 9     2012    10  MIA           18.0  15.071429  3.197698  0.915837   \n",
       " 10    2012    11  MIA           18.0  15.071429  3.197698  0.915837   \n",
       " 11    2012     4  TEN           20.0  16.285714  4.195759  0.885248   \n",
       " 12    2012     5  WAS           17.0  14.142857  3.084880  0.926176   \n",
       " 13    2013     3  ARI           18.0  15.357143  2.871803  0.920278   \n",
       " 14    2013     4  ARI           18.0  15.357143  2.871803  0.920278   \n",
       " 15    2013     6  ARI           18.0  15.357143  2.871803  0.920278   \n",
       " 16    2013    13  ARI           18.0  15.357143  2.871803  0.920278   \n",
       " 17    2013     2  ATL           17.0  14.642857  2.437121  0.967183   \n",
       " 18    2013     1  BUF           21.0  17.642857  3.365141  0.997623   \n",
       " 19    2013    10  BUF           21.0  17.642857  3.365141  0.997623   \n",
       " 20    2013    14  BUF           21.0  17.642857  3.365141  0.997623   \n",
       " 21    2013     8  DAL           17.0  14.142857  2.684919  1.064145   \n",
       " 22    2013    12  DAL           17.0  14.142857  2.684919  1.064145   \n",
       " 23    2013     1   GB           18.0  14.500000  3.858058  0.907192   \n",
       " 24    2013     9   GB           18.0  14.500000  3.858058  0.907192   \n",
       " \n",
       "     shock_current  shock_fullseason  \n",
       " 0               0                 1  \n",
       " 1               0                 1  \n",
       " 2               1                 0  \n",
       " 3               1                 0  \n",
       " 4               1                 0  \n",
       " 5               1                 0  \n",
       " 6               1                 0  \n",
       " 7               1                 0  \n",
       " 8               1                 0  \n",
       " 9               1                 0  \n",
       " 10              1                 0  \n",
       " 11              1                 0  \n",
       " 12              1                 0  \n",
       " 13              1                 0  \n",
       " 14              1                 0  \n",
       " 15              1                 0  \n",
       " 16              1                 0  \n",
       " 17              1                 0  \n",
       " 18              1                 0  \n",
       " 19              1                 0  \n",
       " 20              1                 0  \n",
       " 21              0                 1  \n",
       " 22              0                 1  \n",
       " 23              1                 0  \n",
       " 24              1                 0  )"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = con.execute(f\"DESCRIBE {MODEL_VIEW}\").df()\n",
    "cols = set(desc[\"column_name\"].astype(str).tolist())\n",
    "\n",
    "load_candidates = [\n",
    "    \"ST_Load_NonScore_w\",\n",
    "    \"ST_Load_NonScore\",\n",
    "    \"ST_NonScore_Load_w\",\n",
    "    \"st_load_nonscore_w\",\n",
    "]\n",
    "LOAD_COL = None\n",
    "for c in load_candidates:\n",
    "    if c in cols:\n",
    "        LOAD_COL = c\n",
    "        break\n",
    "\n",
    "if LOAD_COL is None:\n",
    "    raise RuntimeError(\"NonScore load column not found, add the exact name from DESCRIBE into load_candidates\")\n",
    "\n",
    "fullseason_check = con.execute(f\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    {LOAD_COL} AS load_nonscore,\n",
    "    ST_Shock_NonScore_w AS shock_current,\n",
    "    AVG({LOAD_COL}) OVER (PARTITION BY season, team) AS mean_full,\n",
    "    STDDEV_SAMP({LOAD_COL}) OVER (PARTITION BY season, team) AS sd_full\n",
    "  FROM {MODEL_VIEW}\n",
    "  WHERE has_next_week = 1\n",
    "),\n",
    "calc AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN sd_full IS NULL OR sd_full = 0 THEN NULL\n",
    "      ELSE (load_nonscore - mean_full) / sd_full\n",
    "    END AS z_full\n",
    "  FROM base\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN z_full IS NULL THEN NULL\n",
    "      WHEN z_full >= 1 THEN 1\n",
    "      ELSE 0\n",
    "    END AS shock_fullseason\n",
    "  FROM calc\n",
    ")\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(CASE WHEN shock_fullseason IS NULL THEN 1 ELSE 0 END) AS n_null_fullseason,\n",
    "  SUM(CASE WHEN shock_fullseason IS NOT NULL AND shock_current IS NOT NULL THEN 1 ELSE 0 END) AS n_comparable,\n",
    "  SUM(CASE WHEN shock_fullseason IS NOT NULL AND shock_current IS NOT NULL AND shock_fullseason != shock_current THEN 1 ELSE 0 END) AS n_mismatch,\n",
    "  CAST(SUM(CASE WHEN shock_fullseason IS NOT NULL AND shock_current IS NOT NULL AND shock_fullseason != shock_current THEN 1 ELSE 0 END) AS DOUBLE)\n",
    "    / NULLIF(SUM(CASE WHEN shock_fullseason IS NOT NULL AND shock_current IS NOT NULL THEN 1 ELSE 0 END), 0) AS mismatch_rate\n",
    "FROM final\n",
    "\"\"\").df()\n",
    "\n",
    "fullseason_examples = con.execute(f\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    {LOAD_COL} AS load_nonscore,\n",
    "    ST_Shock_NonScore_w AS shock_current,\n",
    "    AVG({LOAD_COL}) OVER (PARTITION BY season, team) AS mean_full,\n",
    "    STDDEV_SAMP({LOAD_COL}) OVER (PARTITION BY season, team) AS sd_full\n",
    "  FROM {MODEL_VIEW}\n",
    "  WHERE has_next_week = 1\n",
    "),\n",
    "calc AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN sd_full IS NULL OR sd_full = 0 THEN NULL\n",
    "      ELSE (load_nonscore - mean_full) / sd_full\n",
    "    END AS z_full\n",
    "  FROM base\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN z_full IS NULL THEN NULL\n",
    "      WHEN z_full >= 1 THEN 1\n",
    "      ELSE 0\n",
    "    END AS shock_fullseason\n",
    "  FROM calc\n",
    ")\n",
    "SELECT\n",
    "  season,\n",
    "  week,\n",
    "  team,\n",
    "  load_nonscore,\n",
    "  mean_full,\n",
    "  sd_full,\n",
    "  z_full,\n",
    "  shock_current,\n",
    "  shock_fullseason\n",
    "FROM final\n",
    "WHERE shock_fullseason IS NOT NULL\n",
    "  AND shock_current IS NOT NULL\n",
    "  AND shock_fullseason != shock_current\n",
    "ORDER BY season, team, week\n",
    "LIMIT 25\n",
    "\"\"\").df()\n",
    "\n",
    "fullseason_check, fullseason_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b7dfb-ba92-42a2-b433-19290d62ccda",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm the patched table has the same row count as before, that the new shock is binary and non null, and taht the lags are binary and non null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcb78ccc-3b2d-49f1-bc35-0b00647fa457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_null_shock</th>\n",
       "      <th>n_bad_shock</th>\n",
       "      <th>n_null_m1</th>\n",
       "      <th>n_bad_m1</th>\n",
       "      <th>n_null_m2</th>\n",
       "      <th>n_bad_m2</th>\n",
       "      <th>n_null_m3</th>\n",
       "      <th>n_bad_m3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows  n_null_shock  n_bad_shock  n_null_m1  n_bad_m1  n_null_m2  \\\n",
       "0    5950           0.0          0.0        0.0       0.0        0.0   \n",
       "\n",
       "   n_bad_m2  n_null_m3  n_bad_m3  \n",
       "0       0.0        0.0       0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n_rows,\n",
    "  SUM(CASE WHEN ST_Shock_NonScore_w IS NULL THEN 1 ELSE 0 END) AS n_null_shock,\n",
    "  SUM(CASE WHEN ST_Shock_NonScore_w NOT IN (0, 1) THEN 1 ELSE 0 END) AS n_bad_shock,\n",
    "  SUM(CASE WHEN ST_Shock_NonScore_w_minus_1 IS NULL THEN 1 ELSE 0 END) AS n_null_m1,\n",
    "  SUM(CASE WHEN ST_Shock_NonScore_w_minus_1 NOT IN (0, 1) THEN 1 ELSE 0 END) AS n_bad_m1,\n",
    "  SUM(CASE WHEN ST_Shock_NonScore_w_minus_2 IS NULL THEN 1 ELSE 0 END) AS n_null_m2,\n",
    "  SUM(CASE WHEN ST_Shock_NonScore_w_minus_2 NOT IN (0, 1) THEN 1 ELSE 0 END) AS n_bad_m2,\n",
    "  SUM(CASE WHEN ST_Shock_NonScore_w_minus_3 IS NULL THEN 1 ELSE 0 END) AS n_null_m3,\n",
    "  SUM(CASE WHEN ST_Shock_NonScore_w_minus_3 NOT IN (0, 1) THEN 1 ELSE 0 END) AS n_bad_m3\n",
    "FROM step16_modeling_frame_nolookahead\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efc1f5-99ae-4255-a335-1fdc8f55dc87",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the patched shock matches the prior weeks only definition exactly and that the row count stays the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81e39b3-ba66-4d5d-b99f-55b3dd5d22fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   n_rows  n_null_shock  n_bad_values  n_mismatch  mismatch_rate\n",
       " 0    5950           0.0           0.0           0            0.0,\n",
       " Empty DataFrame\n",
       " Columns: [season, week, team, load_nonscore, mean_prior, sd_prior, z_prior, shock_patched, shock_prior_only]\n",
       " Index: [])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_summary = con.execute(\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    load_nonscore,\n",
    "    ST_Shock_NonScore_w AS shock_patched,\n",
    "    AVG(load_nonscore) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS mean_prior,\n",
    "    STDDEV_SAMP(load_nonscore) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS sd_prior\n",
    "  FROM step16_modeling_frame_nolookahead\n",
    "),\n",
    "calc AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN sd_prior IS NULL OR sd_prior = 0 THEN NULL\n",
    "      ELSE (load_nonscore - mean_prior) / sd_prior\n",
    "    END AS z_prior\n",
    "  FROM base\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN z_prior IS NULL THEN 0\n",
    "      WHEN z_prior >= 1 THEN 1\n",
    "      ELSE 0\n",
    "    END AS shock_prior_only\n",
    "  FROM calc\n",
    "),\n",
    "mismatches AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    load_nonscore,\n",
    "    mean_prior,\n",
    "    sd_prior,\n",
    "    z_prior,\n",
    "    shock_patched,\n",
    "    shock_prior_only\n",
    "  FROM final\n",
    "  WHERE shock_patched != shock_prior_only\n",
    ")\n",
    "SELECT\n",
    "  (SELECT COUNT(*) FROM step16_modeling_frame_nolookahead) AS n_rows,\n",
    "  (SELECT SUM(CASE WHEN ST_Shock_NonScore_w IS NULL THEN 1 ELSE 0 END) FROM step16_modeling_frame_nolookahead) AS n_null_shock,\n",
    "  (SELECT SUM(CASE WHEN ST_Shock_NonScore_w NOT IN (0, 1) THEN 1 ELSE 0 END) FROM step16_modeling_frame_nolookahead) AS n_bad_values,\n",
    "  COUNT(*) AS n_mismatch,\n",
    "  CAST(COUNT(*) AS DOUBLE) / NULLIF((SELECT COUNT(*) FROM step16_modeling_frame_nolookahead), 0) AS mismatch_rate\n",
    "FROM mismatches\n",
    "\"\"\").df()\n",
    "\n",
    "mismatch_examples = con.execute(\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    load_nonscore,\n",
    "    ST_Shock_NonScore_w AS shock_patched,\n",
    "    AVG(load_nonscore) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS mean_prior,\n",
    "    STDDEV_SAMP(load_nonscore) OVER (\n",
    "      PARTITION BY season, team\n",
    "      ORDER BY week\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS sd_prior\n",
    "  FROM step16_modeling_frame_nolookahead\n",
    "),\n",
    "calc AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN sd_prior IS NULL OR sd_prior = 0 THEN NULL\n",
    "      ELSE (load_nonscore - mean_prior) / sd_prior\n",
    "    END AS z_prior\n",
    "  FROM base\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN z_prior IS NULL THEN 0\n",
    "      WHEN z_prior >= 1 THEN 1\n",
    "      ELSE 0\n",
    "    END AS shock_prior_only\n",
    "  FROM calc\n",
    ")\n",
    "SELECT\n",
    "  season,\n",
    "  week,\n",
    "  team,\n",
    "  load_nonscore,\n",
    "  mean_prior,\n",
    "  sd_prior,\n",
    "  z_prior,\n",
    "  shock_patched,\n",
    "  shock_prior_only\n",
    "FROM final\n",
    "WHERE shock_patched != shock_prior_only\n",
    "ORDER BY season, team, week\n",
    "LIMIT 25\n",
    "\"\"\").df()\n",
    "\n",
    "mismatch_summary, mismatch_examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
