{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda5558b-48ad-4083-9305-ad26029016ad",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9c8ea-65f5-4dac-9442-66b700acf7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "\n",
    "print(\"cwd\", Path().resolve())\n",
    "\n",
    "candidates = []\n",
    "search_roots = [\n",
    "    Path(\".\"),\n",
    "    Path(\"..\"),\n",
    "    Path(\"./data\"),\n",
    "    Path(\"../data\"),\n",
    "    Path(\"../../data\"),\n",
    "]\n",
    "for root in search_roots:\n",
    "    if root.exists():\n",
    "        candidates.extend(list(root.glob(\"*.duckdb\")))\n",
    "        candidates.extend(list(root.glob(\"**/*.duckdb\")))\n",
    "\n",
    "seen = set()\n",
    "duckdb_files = []\n",
    "for f in candidates:\n",
    "    fp = str(f.resolve())\n",
    "    if fp not in seen:\n",
    "        seen.add(fp)\n",
    "        duckdb_files.append(f.resolve())\n",
    "\n",
    "print(\"duckdb files found\")\n",
    "for i, f in enumerate(duckdb_files[:25]):\n",
    "    print(i, f)\n",
    "\n",
    "db_file = None\n",
    "for f in duckdb_files:\n",
    "    if f.name == \"nflpa.duckdb\":\n",
    "        db_file = f\n",
    "        break\n",
    "\n",
    "if db_file is None and duckdb_files:\n",
    "    db_file = duckdb_files[0]\n",
    "\n",
    "if db_file is None:\n",
    "    raise RuntimeError(\"No duckdb file found near this notebook, rerun notebook 02 or check where you stored the database file\")\n",
    "\n",
    "con = duckdb.connect(str(db_file))\n",
    "print(\"connected db\", db_file)\n",
    "\n",
    "tables = con.execute(\"SHOW TABLES\").df()\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de6860-e756-42a7-91ef-4d08baad2315",
   "metadata": {},
   "source": [
    "We define small helpers for column discovery and strict required column checks so later sanity checks fail early if an upstream notebook was skipped or a column name drifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b309d3-3573-4423-b2de-ef1bf1aa62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SEASON_COL = \"season\"\n",
    "WEEK_COL = \"week\"\n",
    "TEAM_COL = \"team\"\n",
    "PANEL_TABLE = \"team_week_panel\"\n",
    "\n",
    "def _existing_cols(table_name: str) -> list[str]:\n",
    "    return con.execute(f\"DESCRIBE {table_name}\").df()[\"column_name\"].tolist()\n",
    "\n",
    "def _require_cols(table_name: str, required: list[str]) -> None:\n",
    "    cols = set(_existing_cols(table_name))\n",
    "    missing = [c for c in required if c not in cols]\n",
    "    print(\"Missing required columns\", missing)\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing columns in {table_name}, rerun earlier notebooks, missing, {missing}\")\n",
    "\n",
    "def _cols_matching(prefix: str = \"\", contains: str = \"\", suffix: str = \"\") -> list[str]:\n",
    "    cols = _existing_cols(PANEL_TABLE)\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        if prefix and not c.startswith(prefix):\n",
    "            continue\n",
    "        if contains and contains not in c:\n",
    "            continue\n",
    "        if suffix and not c.endswith(suffix):\n",
    "            continue\n",
    "        out.append(c)\n",
    "    return out\n",
    "\n",
    "print(\"team week panel columns\", len(_existing_cols(PANEL_TABLE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6106b1d-c40e-4688-b33b-7292d39b2598",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the wide-format structure correctly reflects the expected mix of injury, workload, and control features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2164ad5-8b80-4a93-854e-4fc1029e408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DESCRIBE team_week_panel\").df().head(30)\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  column_name,\n",
    "  column_type\n",
    "FROM (DESCRIBE team_week_panel)\n",
    "ORDER BY column_name\n",
    "LIMIT 30\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d77403-8c69-4cb9-ba0c-39e0372f43c0",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that both schema views contain the same columns and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7d7eb-5482-47f6-9222-29816bc98a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = con.execute(\"DESCRIBE team_week_panel\").df()\n",
    "df_b = con.execute(\"\"\"\n",
    "SELECT column_name, column_type\n",
    "FROM (DESCRIBE team_week_panel)\n",
    "ORDER BY column_name\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"rows describe\", len(df_a))\n",
    "print(\"rows sorted\", len(df_b))\n",
    "\n",
    "dupe_names = df_a[\"column_name\"].value_counts()\n",
    "dupe_names = dupe_names[dupe_names > 1]\n",
    "print(\"duplicate column names\", dupe_names.to_dict())\n",
    "\n",
    "mismatch = (\n",
    "    df_a[[\"column_name\", \"column_type\"]]\n",
    "    .drop_duplicates()\n",
    "    .merge(\n",
    "        df_b[[\"column_name\", \"column_type\"]].drop_duplicates(),\n",
    "        on=[\"column_name\", \"column_type\"],\n",
    "        how=\"outer\",\n",
    "        indicator=True,\n",
    "    )\n",
    ")\n",
    "mismatch = mismatch[mismatch[\"_merge\"] != \"both\"]\n",
    "mismatch.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8757c-7971-4166-b041-5d9f78ea2418",
   "metadata": {},
   "source": [
    "We verify the continuity of the dataset by aggregating the unique time periods present to ensure that the panel spans the full historical range required for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c2f00-985e-4e34-81d5-a50bb321015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN name = '{PANEL_TABLE}' THEN 1 ELSE 0 END) AS has_team_week_panel\n",
    "FROM (SHOW TABLES)\n",
    "\"\"\").df()\n",
    "\n",
    "_require_cols(\n",
    "    PANEL_TABLE,\n",
    "    [\n",
    "        SEASON_COL,\n",
    "        WEEK_COL,\n",
    "        TEAM_COL,\n",
    "        \"game_id\",\n",
    "        \"points_for\",\n",
    "        \"points_against\",\n",
    "        \"ST_Load_All_w\",\n",
    "        \"ST_Load_ScoreLinked_w\",\n",
    "        \"ST_Load_NonScore_w\",\n",
    "        \"ST_Punt_w\",\n",
    "        \"ST_PuntReturn_w\",\n",
    "        \"ST_Kickoff_w\",\n",
    "        \"ST_KickReturn_w\",\n",
    "        \"ST_FG_w\",\n",
    "        \"ST_XP_w\",\n",
    "        \"ST_Rare_w\",\n",
    "        \"Inj_Off_Next_w\",\n",
    "        \"Inj_Def_Next_w\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  COUNT(DISTINCT {SEASON_COL}) AS seasons,\n",
    "  MIN({SEASON_COL}) AS min_season,\n",
    "  MAX({SEASON_COL}) AS max_season,\n",
    "  MIN({WEEK_COL}) AS min_week,\n",
    "  MAX({WEEK_COL}) AS max_week\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdaacaf-de71-48e5-9220-6e0cd13e71e6",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'team_week_panel' exists in the connected database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d4172-96ca-496c-bc68-2a18e0884a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN name = 'team_week_panel' THEN 1 ELSE 0 END) AS has_team_week_panel\n",
    "FROM (SHOW TABLES)\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f934e02-3294-48f7-b2f9-4f43c20e1aa7",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'team_week_panel' has no duplicate season-week-team rows and that the key count equals the row count to ensure that the final modeling table is a perfectly unique panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63646b74-e77a-439a-9218-b7e176d0ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  COUNT(DISTINCT season || '-' || week || '-' || team) AS distinct_keys\n",
    "FROM team_week_panel\n",
    "\"\"\").df()\n",
    "\n",
    "dups = con.execute(\"\"\"\n",
    "SELECT\n",
    "  season,\n",
    "  week,\n",
    "  team,\n",
    "  COUNT(*) AS n\n",
    "FROM team_week_panel\n",
    "GROUP BY 1,2,3\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY n DESC, season, week, team\n",
    "LIMIT 50\n",
    "\"\"\").df()\n",
    "\n",
    "dups\n",
    "\n",
    "if len(dups) > 0:\n",
    "    raise RuntimeError(\"Duplicate season week team rows exist in team_week_panel, investigate joins before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3f95b-02a4-414d-9473-f52f8dbef559",
   "metadata": {},
   "source": [
    "We verify that the \"next game\" indicator accurately distinguishes between teams that play in the following calendar week and those heading into a bye to ensure that the 'w+a' outcome logic aligns with the physical game schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac15963-ef33-4c45-87bf-cafb0686839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP VIEW IF EXISTS panel_next_week_flags\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE TEMP VIEW panel_next_week_flags AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    {SEASON_COL} AS season,\n",
    "    {WEEK_COL} AS week,\n",
    "    CAST({TEAM_COL} AS VARCHAR) AS team_key\n",
    "  FROM {PANEL_TABLE}\n",
    "),\n",
    "nxt AS (\n",
    "  SELECT\n",
    "    {SEASON_COL} AS season,\n",
    "    {WEEK_COL} AS week,\n",
    "    CAST({TEAM_COL} AS VARCHAR) AS team_key\n",
    "  FROM {PANEL_TABLE}\n",
    ")\n",
    "SELECT\n",
    "  b.season,\n",
    "  b.week,\n",
    "  b.team_key,\n",
    "  CASE WHEN n.week IS NULL THEN 0 ELSE 1 END AS has_next_week\n",
    "FROM base b\n",
    "LEFT JOIN nxt n\n",
    "  ON n.season = b.season\n",
    " AND n.team_key = b.team_key\n",
    " AND n.week = b.week + 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  has_next_week,\n",
    "  COUNT(*) AS n_rows\n",
    "FROM panel_next_week_flags\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e360073-63b6-4f0c-a20b-4e8eb05e7a53",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that next week injury outcomes are only defined when week 'w+a' exists for that team season and that they are null when the next week row is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c76cb4-75e0-4dcf-acdb-23e807fce451",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_next_week_cols = [\"Inj_Off_Next_w\", \"Inj_Def_Next_w\"]\n",
    "cols_now = set(_existing_cols(PANEL_TABLE))\n",
    "inj_next_week_cols = [c for c in inj_next_week_cols if c in cols_now]\n",
    "\n",
    "if not inj_next_week_cols:\n",
    "    raise RuntimeError(\"No next week injury outcome columns found, expected Inj_Off_Next_w and Inj_Def_Next_w\")\n",
    "\n",
    "print(\"Next week injury columns checked\", inj_next_week_cols)\n",
    "\n",
    "select_any_defined = \" OR \".join([f\"p.{c} IS NOT NULL\" for c in inj_next_week_cols])\n",
    "\n",
    "bad_defined = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS bad_rows\n",
    "FROM {PANEL_TABLE} p\n",
    "JOIN panel_next_week_flags f\n",
    "  ON f.season = p.{SEASON_COL}\n",
    " AND f.week = p.{WEEK_COL}\n",
    " AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "WHERE f.has_next_week = 0\n",
    "  AND ({select_any_defined})\n",
    "\"\"\").df()\n",
    "\n",
    "bad_rows = int(bad_defined[\"bad_rows\"].iloc[0])\n",
    "print(bad_defined)\n",
    "\n",
    "if bad_rows != 0:\n",
    "    sample = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "      p.{SEASON_COL} AS season,\n",
    "      p.{WEEK_COL} AS week,\n",
    "      p.{TEAM_COL} AS team,\n",
    "      f.has_next_week,\n",
    "      {\", \".join([f\"p.{c}\" for c in inj_next_week_cols])}\n",
    "    FROM {PANEL_TABLE} p\n",
    "    JOIN panel_next_week_flags f\n",
    "      ON f.season = p.{SEASON_COL}\n",
    "     AND f.week = p.{WEEK_COL}\n",
    "     AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "    WHERE f.has_next_week = 0\n",
    "      AND ({select_any_defined})\n",
    "    ORDER BY p.{SEASON_COL} DESC, p.{WEEK_COL} DESC, p.{TEAM_COL}\n",
    "    LIMIT 50\n",
    "    \"\"\").df()\n",
    "    print(sample)\n",
    "    raise RuntimeError(\"Next week injury outcomes are populated when week plus 1 does not exist, fix notebook 09 logic or apply the step 11 repair cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54dc375-cece-4fd9-8b5b-fa0af2c45af4",
   "metadata": {},
   "source": [
    "We handle the undefined next week cases by creating a modeling view that drops all rows where week 'w+1' does not exist, which are the final game weeks and the pre bye game weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d7628-4753-4ceb-a8ff-c103fe377613",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP VIEW IF EXISTS team_week_panel_nextweek_model\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW team_week_panel_nextweek_model AS\n",
    "SELECT\n",
    "  p.*,\n",
    "  f.has_next_week\n",
    "FROM {PANEL_TABLE} p\n",
    "JOIN panel_next_week_flags f\n",
    "  ON f.season = p.{SEASON_COL}\n",
    " AND f.week = p.{WEEK_COL}\n",
    " AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "WHERE f.has_next_week = 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows_model,\n",
    "  COUNT(DISTINCT {SEASON_COL} || '-' || {WEEK_COL} || '-' || {TEAM_COL}) AS distinct_keys_model\n",
    "FROM team_week_panel_nextweek_model\n",
    "\"\"\").df()\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  p.{SEASON_COL} AS season,\n",
    "  COUNT(*) AS rows_total,\n",
    "  SUM(CASE WHEN f.has_next_week = 1 THEN 1 ELSE 0 END) AS rows_kept,\n",
    "  SUM(CASE WHEN f.has_next_week = 0 THEN 1 ELSE 0 END) AS rows_dropped\n",
    "FROM {PANEL_TABLE} p\n",
    "JOIN panel_next_week_flags f\n",
    "  ON f.season = p.{SEASON_COL}\n",
    " AND f.week = p.{WEEK_COL}\n",
    " AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbce616-f713-44aa-9d6d-994becaf427d",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the special teams totals exactly match the intended bucket identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6c819-4631-4b23-a0c2-a9b1309cced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_identity = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN ST_Load_All_w != (ST_Punt_w + ST_PuntReturn_w + ST_Kickoff_w + ST_KickReturn_w + ST_FG_w + ST_XP_w + ST_Rare_w) THEN 1 ELSE 0 END) AS bad_all_identity,\n",
    "  SUM(CASE WHEN ST_Load_ScoreLinked_w != (ST_Kickoff_w + ST_XP_w + ST_FG_w) THEN 1 ELSE 0 END) AS bad_scorelinked_identity,\n",
    "  SUM(CASE WHEN ST_Load_NonScore_w != (ST_Punt_w + ST_PuntReturn_w + ST_KickReturn_w + ST_Rare_w) THEN 1 ELSE 0 END) AS bad_nonscore_identity,\n",
    "  SUM(CASE WHEN ST_Load_All_w != (ST_Load_ScoreLinked_w + ST_Load_NonScore_w) THEN 1 ELSE 0 END) AS bad_partition_identity\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()\n",
    "\n",
    "print(st_identity)\n",
    "\n",
    "bad_all = int(st_identity[\"bad_all_identity\"].iloc[0])\n",
    "bad_sl = int(st_identity[\"bad_scorelinked_identity\"].iloc[0])\n",
    "bad_ns = int(st_identity[\"bad_nonscore_identity\"].iloc[0])\n",
    "bad_part = int(st_identity[\"bad_partition_identity\"].iloc[0])\n",
    "\n",
    "if bad_all or bad_sl or bad_ns or bad_part:\n",
    "    sample = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "      {SEASON_COL} AS season,\n",
    "      {WEEK_COL} AS week,\n",
    "      {TEAM_COL} AS team,\n",
    "      ST_Punt_w,\n",
    "      ST_PuntReturn_w,\n",
    "      ST_Kickoff_w,\n",
    "      ST_KickReturn_w,\n",
    "      ST_FG_w,\n",
    "      ST_XP_w,\n",
    "      ST_Rare_w,\n",
    "      ST_Load_All_w,\n",
    "      ST_Load_ScoreLinked_w,\n",
    "      ST_Load_NonScore_w\n",
    "    FROM {PANEL_TABLE}\n",
    "    WHERE\n",
    "      ST_Load_All_w != (ST_Punt_w + ST_PuntReturn_w + ST_Kickoff_w + ST_KickReturn_w + ST_FG_w + ST_XP_w + ST_Rare_w)\n",
    "      OR ST_Load_ScoreLinked_w != (ST_Kickoff_w + ST_XP_w + ST_FG_w)\n",
    "      OR ST_Load_NonScore_w != (ST_Punt_w + ST_PuntReturn_w + ST_KickReturn_w + ST_Rare_w)\n",
    "      OR ST_Load_All_w != (ST_Load_ScoreLinked_w + ST_Load_NonScore_w)\n",
    "    ORDER BY season DESC, week DESC, team\n",
    "    LIMIT 50\n",
    "    \"\"\").df()\n",
    "    print(sample)\n",
    "    raise RuntimeError(\"Special teams buckets do not satisfy the intended identities, investigate notebook 04 bucketing logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42b83d-4c71-4133-b504-b41081358a3d",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'ScoreLinked' moves with the points environment more than 'NonScore' by comparing correlations with total game points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693d8eb-210f-4e3d-bacd-4b96dfc8d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  {SEASON_COL} AS season,\n",
    "  {WEEK_COL} AS week,\n",
    "  {TEAM_COL} AS team,\n",
    "  points_for,\n",
    "  points_against,\n",
    "  ST_Load_ScoreLinked_w,\n",
    "  ST_Load_NonScore_w\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()\n",
    "\n",
    "df_points[\"total_points_game\"] = df_points[\"points_for\"] + df_points[\"points_against\"]\n",
    "\n",
    "df_corr = df_points.dropna(subset=[\"total_points_game\", \"ST_Load_ScoreLinked_w\", \"ST_Load_NonScore_w\"]).copy()\n",
    "\n",
    "corr_scorelinked = df_corr[\"ST_Load_ScoreLinked_w\"].corr(df_corr[\"total_points_game\"])\n",
    "corr_nonscore = df_corr[\"ST_Load_NonScore_w\"].corr(df_corr[\"total_points_game\"])\n",
    "\n",
    "print(\"corr ScoreLinked with total points game\", corr_scorelinked)\n",
    "print(\"corr NonScore with total points game\", corr_nonscore)\n",
    "\n",
    "if abs(corr_scorelinked) < abs(corr_nonscore):\n",
    "    raise RuntimeError(\"ScoreLinked is not more correlated with points environment than NonScore, investigate ScoreLinked definition and joins\")\n",
    "\n",
    "by_season = (\n",
    "    df_corr.groupby(\"season\", as_index=False)\n",
    "    .apply(\n",
    "        lambda g: pd.Series({\n",
    "            \"corr_scorelinked_total_points\": g[\"ST_Load_ScoreLinked_w\"].corr(g[\"total_points_game\"]),\n",
    "            \"corr_nonscore_total_points\": g[\"ST_Load_NonScore_w\"].corr(g[\"total_points_game\"]),\n",
    "            \"n_rows\": len(g),\n",
    "        }),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "by_season = by_season.reset_index(drop=True)\n",
    "by_season.sort_values(\"season\").tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb537a8-dc97-4f5c-95ef-d23a9dd17609",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'NonScore' correlates more with punts and returns than with touchdowns by constructing a touchdowns per team week table from play by play and comparing correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb318ac-d43e-4d51-a69e-aa5364f29357",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS team_week_tds_off\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE team_week_tds_off AS\n",
    "SELECT\n",
    "  season,\n",
    "  week,\n",
    "  CAST(posteam AS VARCHAR) AS team,\n",
    "  SUM(CASE WHEN touchdown = 1 THEN 1 ELSE 0 END) AS tds_off_w\n",
    "FROM pbp\n",
    "WHERE posteam IS NOT NULL\n",
    "GROUP BY 1,2,3\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  COUNT(DISTINCT season || '-' || week || '-' || team) AS distinct_keys,\n",
    "  MIN(tds_off_w) AS min_tds,\n",
    "  MAX(tds_off_w) AS max_tds,\n",
    "  AVG(tds_off_w) AS avg_tds\n",
    "FROM team_week_tds_off\n",
    "\"\"\").df()\n",
    "\n",
    "df_ns = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  p.{SEASON_COL} AS season,\n",
    "  p.{WEEK_COL} AS week,\n",
    "  p.{TEAM_COL} AS team,\n",
    "  p.ST_Load_NonScore_w,\n",
    "  p.ST_Punt_w,\n",
    "  p.ST_PuntReturn_w,\n",
    "  p.ST_KickReturn_w,\n",
    "  COALESCE(t.tds_off_w, 0) AS tds_off_w\n",
    "FROM {PANEL_TABLE} p\n",
    "LEFT JOIN team_week_tds_off t\n",
    "  ON t.season = p.{SEASON_COL}\n",
    " AND t.week = p.{WEEK_COL}\n",
    " AND t.team = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "\"\"\").df()\n",
    "\n",
    "df_ns[\"punt_return_proxy\"] = df_ns[\"ST_Punt_w\"] + df_ns[\"ST_PuntReturn_w\"] + df_ns[\"ST_KickReturn_w\"]\n",
    "\n",
    "df_ns_corr = df_ns.dropna(subset=[\"ST_Load_NonScore_w\", \"punt_return_proxy\", \"tds_off_w\"]).copy()\n",
    "\n",
    "corr_ns_punts = df_ns_corr[\"ST_Load_NonScore_w\"].corr(df_ns_corr[\"punt_return_proxy\"])\n",
    "corr_ns_tds = df_ns_corr[\"ST_Load_NonScore_w\"].corr(df_ns_corr[\"tds_off_w\"])\n",
    "\n",
    "print(\"corr NonScore with punts and returns proxy\", corr_ns_punts)\n",
    "print(\"corr NonScore with offensive touchdowns\", corr_ns_tds)\n",
    "\n",
    "if abs(corr_ns_punts) < abs(corr_ns_tds):\n",
    "    raise RuntimeError(\"NonScore is not more correlated with punts and returns than touchdowns, investigate NonScore definition and component mapping\")\n",
    "\n",
    "by_season_ns = (\n",
    "    df_ns_corr.groupby(\"season\", as_index=False)\n",
    "    .apply(\n",
    "        lambda g: pd.Series({\n",
    "            \"corr_nonscore_punts_returns\": g[\"ST_Load_NonScore_w\"].corr(g[\"punt_return_proxy\"]),\n",
    "            \"corr_nonscore_tds_off\": g[\"ST_Load_NonScore_w\"].corr(g[\"tds_off_w\"]),\n",
    "            \"n_rows\": len(g),\n",
    "        }),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "by_season_ns = by_season_ns.reset_index(drop=True)\n",
    "by_season_ns.sort_values(\"season\").tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c19c1a-b2fe-41e6-a5af-cab932b080d8",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the next week modeling view has no unexpected nulls in core exposures and controls, which protects against join failures that can potentially collapse sample size later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf57d0f-dcd2-4885-bf47-1fc554476472",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_cols = [\n",
    "    \"ST_Load_NonScore_w\",\n",
    "    \"ST_Load_ScoreLinked_w\",\n",
    "    \"ST_Load_All_w\",\n",
    "    \"Z_ST_NonScore_w\",\n",
    "    \"ST_Shock_NonScore_w\",\n",
    "    \"ST_Vol_NonScore_w\",\n",
    "    \"Cum_Shocks_NonScore_w\",\n",
    "    \"offensive_snaps_w\",\n",
    "    \"defensive_snaps_w\",\n",
    "    \"off_yards_per_play_w\",\n",
    "    \"points_for\",\n",
    "    \"points_against\",\n",
    "    \"score_diff_w\",\n",
    "    \"blowout_flag_w\",\n",
    "    \"days_rest_w\",\n",
    "    \"short_week_flag_w\",\n",
    "    \"bye_last_week_flag_w\",\n",
    "    \"home_flag_w\",\n",
    "    \"Inj_Off_Next_w\",\n",
    "    \"Inj_Def_Next_w\",\n",
    "    \"Inj_Off_Last_w\",\n",
    "    \"Inj_Def_Last_w\",\n",
    "]\n",
    "\n",
    "cols_now = set(_existing_cols(\"team_week_panel_nextweek_model\"))\n",
    "core_cols = [c for c in core_cols if c in cols_now]\n",
    "\n",
    "null_expr = \",\\n  \".join([f\"SUM(CASE WHEN {c} IS NULL THEN 1 ELSE 0 END) AS null_{c}\" for c in core_cols])\n",
    "\n",
    "nulls = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows_model,\n",
    "  {null_expr}\n",
    "FROM team_week_panel_nextweek_model\n",
    "\"\"\").df()\n",
    "\n",
    "nulls\n",
    "\n",
    "bad = []\n",
    "for c in core_cols:\n",
    "    v = int(nulls[f\"null_{c}\"].iloc[0])\n",
    "    if v != 0:\n",
    "        bad.append((c, v))\n",
    "\n",
    "print(\"Nonzero null counts in model view\", bad)\n",
    "\n",
    "if bad:\n",
    "    raise RuntimeError(\"Model view contains nulls in required exposures or controls, rerun upstream joins and inspect the listed columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddf89c-ff29-46b2-a37c-4ce2f631fe62",
   "metadata": {},
   "source": [
    "We aggregate the results of our structural and integrity tests into a single, high-level summary table, providing a centralized \"health report\" for the dataset before the final regression begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc54e6e-b781-423e-8426-57fec7460a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS panel_step11_diagnostics\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE TABLE panel_step11_diagnostics AS\n",
    "SELECT\n",
    "  CURRENT_TIMESTAMP AS created_at,\n",
    "  (SELECT COUNT(*) FROM {PANEL_TABLE}) AS rows_panel,\n",
    "  (SELECT COUNT(*) FROM team_week_panel_nextweek_model) AS rows_nextweek_model,\n",
    "  (SELECT COUNT(*) FROM {PANEL_TABLE}) - (SELECT COUNT(*) FROM team_week_panel_nextweek_model) AS rows_dropped_no_next_week,\n",
    "  {float(corr_scorelinked)} AS corr_scorelinked_total_points,\n",
    "  {float(corr_nonscore)} AS corr_nonscore_total_points,\n",
    "  {float(corr_ns_punts)} AS corr_nonscore_punts_returns,\n",
    "  {float(corr_ns_tds)} AS corr_nonscore_tds_off\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"SELECT * FROM panel_step11_diagnostics\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764495cb-d303-48a1-b618-7539f9c31179",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the rows missing 'w+1' behave like expected at the team season level, and that the 2017 and 2022 deviations are not a broken panel join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758bea0-c602-470c-a1c6-419a83caad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dist = con.execute(\"\"\"\n",
    "WITH per_team AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    team_key,\n",
    "    SUM(CASE WHEN has_next_week = 0 THEN 1 ELSE 0 END) AS n_no_next_week,\n",
    "    COUNT(*) AS n_rows\n",
    "  FROM panel_next_week_flags\n",
    "  GROUP BY 1,2\n",
    ")\n",
    "SELECT\n",
    "  season,\n",
    "  n_no_next_week,\n",
    "  COUNT(*) AS n_teams\n",
    "FROM per_team\n",
    "GROUP BY 1,2\n",
    "ORDER BY season, n_no_next_week\n",
    "\"\"\").df()\n",
    "\n",
    "print(missing_dist)\n",
    "\n",
    "odd_teams = con.execute(\"\"\"\n",
    "WITH per_team AS (\n",
    "  SELECT\n",
    "    season,\n",
    "    team_key,\n",
    "    SUM(CASE WHEN has_next_week = 0 THEN 1 ELSE 0 END) AS n_no_next_week,\n",
    "    COUNT(*) AS n_rows\n",
    "  FROM panel_next_week_flags\n",
    "  GROUP BY 1,2\n",
    ")\n",
    "SELECT *\n",
    "FROM per_team\n",
    "WHERE n_no_next_week NOT IN (1, 2, 3)\n",
    "ORDER BY season, team_key\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"team seasons with unexpected n_no_next_week\", len(odd_teams))\n",
    "if len(odd_teams) != 0:\n",
    "    print(odd_teams.head(50))\n",
    "    raise RuntimeError(\"Unexpected missing next week pattern, investigate schedule ingestion, canceled games, or missing team weeks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ad38c-6750-4a88-81dd-e94dd2238015",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the special teams bucket identities cannot pass if any contributing columns are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f2eef-f4e6-41b0-a74b-ab30acd934a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_identity_hardened = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(\n",
    "    CASE\n",
    "      WHEN ST_Load_All_w IS NULL\n",
    "        OR ST_Punt_w IS NULL\n",
    "        OR ST_PuntReturn_w IS NULL\n",
    "        OR ST_Kickoff_w IS NULL\n",
    "        OR ST_KickReturn_w IS NULL\n",
    "        OR ST_FG_w IS NULL\n",
    "        OR ST_XP_w IS NULL\n",
    "        OR ST_Rare_w IS NULL\n",
    "      THEN 1\n",
    "      WHEN ST_Load_All_w != (ST_Punt_w + ST_PuntReturn_w + ST_Kickoff_w + ST_KickReturn_w + ST_FG_w + ST_XP_w + ST_Rare_w)\n",
    "      THEN 1\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) AS bad_all_identity,\n",
    "  SUM(\n",
    "    CASE\n",
    "      WHEN ST_Load_ScoreLinked_w IS NULL\n",
    "        OR ST_Kickoff_w IS NULL\n",
    "        OR ST_XP_w IS NULL\n",
    "        OR ST_FG_w IS NULL\n",
    "      THEN 1\n",
    "      WHEN ST_Load_ScoreLinked_w != (ST_Kickoff_w + ST_XP_w + ST_FG_w)\n",
    "      THEN 1\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) AS bad_scorelinked_identity,\n",
    "  SUM(\n",
    "    CASE\n",
    "      WHEN ST_Load_NonScore_w IS NULL\n",
    "        OR ST_Punt_w IS NULL\n",
    "        OR ST_PuntReturn_w IS NULL\n",
    "        OR ST_KickReturn_w IS NULL\n",
    "        OR ST_Rare_w IS NULL\n",
    "      THEN 1\n",
    "      WHEN ST_Load_NonScore_w != (ST_Punt_w + ST_PuntReturn_w + ST_KickReturn_w + ST_Rare_w)\n",
    "      THEN 1\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) AS bad_nonscore_identity,\n",
    "  SUM(\n",
    "    CASE\n",
    "      WHEN ST_Load_All_w IS NULL\n",
    "        OR ST_Load_ScoreLinked_w IS NULL\n",
    "        OR ST_Load_NonScore_w IS NULL\n",
    "      THEN 1\n",
    "      WHEN ST_Load_All_w != (ST_Load_ScoreLinked_w + ST_Load_NonScore_w)\n",
    "      THEN 1\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) AS bad_partition_identity\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()\n",
    "\n",
    "print(st_identity_hardened)\n",
    "\n",
    "bad_any = int(st_identity_hardened[[\"bad_all_identity\",\"bad_scorelinked_identity\",\"bad_nonscore_identity\",\"bad_partition_identity\"]].sum(axis=1).iloc[0])\n",
    "if bad_any != 0:\n",
    "    raise RuntimeError(\"Special teams bucket identities failed or encountered null inputs, investigate notebook 04 bucketing and joins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc20ccf-9f79-410e-83a3-b3b4f5dba9b7",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the touchdown proxy join is actually matching the panel rows, and that 'NonScore' still relates more to punts and returns than to touchdowns using a 'game_id' based join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79942284-f17f-4051-b954-929476249e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP VIEW IF EXISTS game_team_tds_off\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE TEMP VIEW game_team_tds_off AS\n",
    "SELECT\n",
    "  game_id,\n",
    "  CAST(posteam AS VARCHAR) AS team_key,\n",
    "  SUM(CASE WHEN touchdown = 1 THEN 1 ELSE 0 END) AS tds_off_w\n",
    "FROM pbp\n",
    "WHERE posteam IS NOT NULL\n",
    "GROUP BY 1,2\n",
    "\"\"\")\n",
    "\n",
    "df_join_check = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN t.tds_off_w IS NULL THEN 1 ELSE 0 END) AS missing_rows,\n",
    "  COUNT(*) AS total_rows,\n",
    "  CAST(SUM(CASE WHEN t.tds_off_w IS NULL THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*) AS missing_rate\n",
    "FROM {PANEL_TABLE} p\n",
    "LEFT JOIN game_team_tds_off t\n",
    "  ON t.game_id = p.game_id\n",
    " AND t.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "\"\"\").df()\n",
    "\n",
    "df_join_check\n",
    "\n",
    "panel_codes = con.execute(f\"\"\"\n",
    "SELECT DISTINCT CAST({TEAM_COL} AS VARCHAR) AS team_code\n",
    "FROM {PANEL_TABLE}\n",
    "ORDER BY 1\n",
    "\"\"\").df()[\"team_code\"].tolist()\n",
    "\n",
    "pbp_codes = con.execute(\"\"\"\n",
    "SELECT DISTINCT CAST(posteam AS VARCHAR) AS team_code\n",
    "FROM pbp\n",
    "WHERE posteam IS NOT NULL\n",
    "ORDER BY 1\n",
    "\"\"\").df()[\"team_code\"].tolist()\n",
    "\n",
    "panel_set = set(panel_codes)\n",
    "pbp_set = set(pbp_codes)\n",
    "\n",
    "print(\"panel codes not in pbp posteam codes\", sorted(panel_set - pbp_set))\n",
    "print(\"pbp posteam codes not in panel codes\", sorted(pbp_set - panel_set))\n",
    "\n",
    "missing_breakdown = con.execute(f\"\"\"\n",
    "WITH tds_raw AS (\n",
    "  SELECT\n",
    "    game_id,\n",
    "    CAST(posteam AS VARCHAR) AS posteam_raw,\n",
    "    SUM(CASE WHEN touchdown = 1 THEN 1 ELSE 0 END) AS tds_off_w\n",
    "  FROM pbp\n",
    "  WHERE posteam IS NOT NULL\n",
    "  GROUP BY 1,2\n",
    "),\n",
    "joined AS (\n",
    "  SELECT\n",
    "    p.{SEASON_COL} AS season,\n",
    "    CAST(p.{TEAM_COL} AS VARCHAR) AS team_code,\n",
    "    CASE WHEN t.tds_off_w IS NULL THEN 1 ELSE 0 END AS missing_join\n",
    "  FROM {PANEL_TABLE} p\n",
    "  LEFT JOIN tds_raw t\n",
    "    ON t.game_id = p.game_id\n",
    "   AND t.posteam_raw = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    ")\n",
    "SELECT\n",
    "  season,\n",
    "  team_code,\n",
    "  SUM(missing_join) AS n_missing,\n",
    "  COUNT(*) AS n_rows\n",
    "FROM joined\n",
    "GROUP BY 1,2\n",
    "HAVING SUM(missing_join) > 0\n",
    "ORDER BY n_missing DESC, season, team_code\n",
    "LIMIT 50\n",
    "\"\"\").df()\n",
    "\n",
    "missing_breakdown\n",
    "\n",
    "candidate_aliases = {\n",
    "    \"STL\": \"LA\",\n",
    "    \"LAR\": \"LA\",\n",
    "    \"SD\": \"LAC\",\n",
    "    \"OAK\": \"LV\",\n",
    "    \"JAC\": \"JAX\",\n",
    "    \"WSH\": \"WAS\",\n",
    "}\n",
    "\n",
    "pbp_set = set(con.execute(\"\"\"\n",
    "SELECT DISTINCT CAST(posteam AS VARCHAR) AS team_code\n",
    "FROM pbp\n",
    "WHERE posteam IS NOT NULL\n",
    "\"\"\").df()[\"team_code\"].tolist())\n",
    "\n",
    "panel_set = set(con.execute(f\"\"\"\n",
    "SELECT DISTINCT CAST({TEAM_COL} AS VARCHAR) AS team_code\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()[\"team_code\"].tolist())\n",
    "\n",
    "final_pairs = []\n",
    "for src, dst in candidate_aliases.items():\n",
    "    if src in pbp_set and dst in panel_set and src not in panel_set:\n",
    "        final_pairs.append((src, dst))\n",
    "\n",
    "alias_df = pd.DataFrame(final_pairs, columns=[\"pbp_team\", \"panel_team\"])\n",
    "print(\"alias pairs used\", alias_df.to_dict(orient=\"records\"))\n",
    "\n",
    "con.register(\"team_key_alias_map\", alias_df)\n",
    "\n",
    "con.execute(\"DROP VIEW IF EXISTS game_team_tds_off\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE TEMP VIEW game_team_tds_off AS\n",
    "SELECT\n",
    "  p.game_id,\n",
    "  COALESCE(m.panel_team, CAST(p.posteam AS VARCHAR)) AS team_key,\n",
    "  SUM(CASE WHEN p.touchdown = 1 THEN 1 ELSE 0 END) AS tds_off_w\n",
    "FROM pbp p\n",
    "LEFT JOIN team_key_alias_map m\n",
    "  ON m.pbp_team = CAST(p.posteam AS VARCHAR)\n",
    "WHERE p.posteam IS NOT NULL\n",
    "GROUP BY 1,2\n",
    "\"\"\")\n",
    "\n",
    "df_join_check2 = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN t.tds_off_w IS NULL THEN 1 ELSE 0 END) AS missing_rows,\n",
    "  COUNT(*) AS total_rows,\n",
    "  CAST(SUM(CASE WHEN t.tds_off_w IS NULL THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*) AS missing_rate\n",
    "FROM {PANEL_TABLE} p\n",
    "LEFT JOIN game_team_tds_off t\n",
    "  ON t.game_id = p.game_id\n",
    " AND t.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "\"\"\").df()\n",
    "\n",
    "df_join_check2\n",
    "\n",
    "panel_to_pbp_aliases = {\n",
    "    \"STL\": \"LA\",\n",
    "    \"SD\": \"LAC\",\n",
    "    \"OAK\": \"LV\",\n",
    "}\n",
    "\n",
    "panel_set = set(con.execute(f\"\"\"\n",
    "SELECT DISTINCT CAST({TEAM_COL} AS VARCHAR) AS team_code\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()[\"team_code\"].tolist())\n",
    "\n",
    "pbp_set = set(con.execute(\"\"\"\n",
    "SELECT DISTINCT CAST(posteam AS VARCHAR) AS team_code\n",
    "FROM pbp\n",
    "WHERE posteam IS NOT NULL\n",
    "\"\"\").df()[\"team_code\"].tolist())\n",
    "\n",
    "final_pairs = []\n",
    "for src_panel, dst_pbp in panel_to_pbp_aliases.items():\n",
    "    if src_panel in panel_set and dst_pbp in pbp_set:\n",
    "        final_pairs.append((src_panel, dst_pbp))\n",
    "\n",
    "alias_df = pd.DataFrame(final_pairs, columns=[\"panel_team\", \"pbp_team\"])\n",
    "print(\"panel to pbp alias pairs used\", alias_df.to_dict(orient=\"records\"))\n",
    "\n",
    "con.register(\"panel_to_pbp_team_map\", alias_df)\n",
    "\n",
    "df_join_check3 = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN t.tds_off_w IS NULL THEN 1 ELSE 0 END) AS missing_rows,\n",
    "  COUNT(*) AS total_rows,\n",
    "  CAST(SUM(CASE WHEN t.tds_off_w IS NULL THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*) AS missing_rate\n",
    "FROM {PANEL_TABLE} p\n",
    "LEFT JOIN game_team_tds_off t\n",
    "  ON t.game_id = p.game_id\n",
    " AND t.team_key = COALESCE(\n",
    "   (SELECT pbp_team FROM panel_to_pbp_team_map m WHERE m.panel_team = CAST(p.{TEAM_COL} AS VARCHAR)),\n",
    "   CAST(p.{TEAM_COL} AS VARCHAR)\n",
    " )\n",
    "\"\"\").df()\n",
    "\n",
    "df_join_check3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cfd0a1-c409-4aed-b91e-008d9b504515",
   "metadata": {},
   "source": [
    "We recomputes the diagnostics inside SQL so that in the future, we don't need to depend on Python variables from earlier cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912abac2-462a-418c-b552-1c732c9b1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS panel_step11_diagnostics\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE TABLE panel_step11_diagnostics AS\n",
    "WITH joined AS (\n",
    "  SELECT\n",
    "    p.*,\n",
    "    t.tds_off_w,\n",
    "    CASE WHEN t.tds_off_w IS NULL THEN 1 ELSE 0 END AS missing_tds_join\n",
    "  FROM {PANEL_TABLE} p\n",
    "  LEFT JOIN panel_to_pbp_team_map m\n",
    "    ON m.panel_team = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "  LEFT JOIN game_team_tds_off t\n",
    "    ON t.game_id = p.game_id\n",
    "   AND t.team_key = COALESCE(m.pbp_team, CAST(p.{TEAM_COL} AS VARCHAR))\n",
    "),\n",
    "agg AS (\n",
    "  SELECT\n",
    "    CURRENT_TIMESTAMP AS created_at,\n",
    "    COUNT(*) AS rows_panel,\n",
    "    (SELECT COUNT(*) FROM team_week_panel_nextweek_model) AS rows_nextweek_model,\n",
    "    COUNT(*) - (SELECT COUNT(*) FROM team_week_panel_nextweek_model) AS rows_dropped_no_next_week,\n",
    "    corr(CAST(ST_Load_ScoreLinked_w AS DOUBLE), CAST(points_for + points_against AS DOUBLE)) AS corr_scorelinked_total_points,\n",
    "    corr(CAST(ST_Load_NonScore_w AS DOUBLE), CAST(points_for + points_against AS DOUBLE)) AS corr_nonscore_total_points,\n",
    "    corr(CAST(ST_Load_NonScore_w AS DOUBLE), CAST(ST_Punt_w + ST_PuntReturn_w + ST_KickReturn_w AS DOUBLE)) AS corr_nonscore_punts_returns,\n",
    "    corr(CAST(ST_Load_NonScore_w AS DOUBLE), CAST(COALESCE(tds_off_w, 0) AS DOUBLE)) AS corr_nonscore_tds_off,\n",
    "    AVG(CAST(missing_tds_join AS DOUBLE)) AS tds_join_missing_rate\n",
    "  FROM joined\n",
    ")\n",
    "SELECT * FROM agg\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"SELECT * FROM panel_step11_diagnostics\").df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
