{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda5558b-48ad-4083-9305-ad26029016ad",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9c8ea-65f5-4dac-9442-66b700acf7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "\n",
    "print(\"cwd\", Path().resolve())\n",
    "\n",
    "candidates = []\n",
    "search_roots = [\n",
    "    Path(\".\"),\n",
    "    Path(\"..\"),\n",
    "    Path(\"./data\"),\n",
    "    Path(\"../data\"),\n",
    "    Path(\"../../data\"),\n",
    "]\n",
    "for root in search_roots:\n",
    "    if root.exists():\n",
    "        candidates.extend(list(root.glob(\"*.duckdb\")))\n",
    "        candidates.extend(list(root.glob(\"**/*.duckdb\")))\n",
    "\n",
    "seen = set()\n",
    "duckdb_files = []\n",
    "for f in candidates:\n",
    "    fp = str(f.resolve())\n",
    "    if fp not in seen:\n",
    "        seen.add(fp)\n",
    "        duckdb_files.append(f.resolve())\n",
    "\n",
    "print(\"duckdb files found\")\n",
    "for i, f in enumerate(duckdb_files[:25]):\n",
    "    print(i, f)\n",
    "\n",
    "db_file = None\n",
    "for f in duckdb_files:\n",
    "    if f.name == \"nflpa.duckdb\":\n",
    "        db_file = f\n",
    "        break\n",
    "\n",
    "if db_file is None and duckdb_files:\n",
    "    db_file = duckdb_files[0]\n",
    "\n",
    "if db_file is None:\n",
    "    raise RuntimeError(\"No duckdb file found near this notebook, rerun notebook 02 or check where you stored the database file\")\n",
    "\n",
    "con = duckdb.connect(str(db_file))\n",
    "print(\"connected db\", db_file)\n",
    "\n",
    "tables = con.execute(\"SHOW TABLES\").df()\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de6860-e756-42a7-91ef-4d08baad2315",
   "metadata": {},
   "source": [
    "We define small helpers for column discovery and strict required column checks so later sanity checks fail early if an upstream notebook was skipped or a column name drifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b309d3-3573-4423-b2de-ef1bf1aa62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SEASON_COL = \"season\"\n",
    "WEEK_COL = \"week\"\n",
    "TEAM_COL = \"team\"\n",
    "PANEL_TABLE = \"team_week_panel\"\n",
    "\n",
    "def _existing_cols(table_name: str) -> list[str]:\n",
    "    return con.execute(f\"DESCRIBE {table_name}\").df()[\"column_name\"].tolist()\n",
    "\n",
    "def _require_cols(table_name: str, required: list[str]) -> None:\n",
    "    cols = set(_existing_cols(table_name))\n",
    "    missing = [c for c in required if c not in cols]\n",
    "    print(\"Missing required columns\", missing)\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing columns in {table_name}, rerun earlier notebooks, missing, {missing}\")\n",
    "\n",
    "def _cols_matching(prefix: str = \"\", contains: str = \"\", suffix: str = \"\") -> list[str]:\n",
    "    cols = _existing_cols(PANEL_TABLE)\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        if prefix and not c.startswith(prefix):\n",
    "            continue\n",
    "        if contains and contains not in c:\n",
    "            continue\n",
    "        if suffix and not c.endswith(suffix):\n",
    "            continue\n",
    "        out.append(c)\n",
    "    return out\n",
    "\n",
    "print(\"team week panel columns\", len(_existing_cols(PANEL_TABLE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6106b1d-c40e-4688-b33b-7292d39b2598",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the wide-format structure correctly reflects the expected mix of injury, workload, and control features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2164ad5-8b80-4a93-854e-4fc1029e408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DESCRIBE team_week_panel\").df().head(30)\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  column_name,\n",
    "  column_type\n",
    "FROM (DESCRIBE team_week_panel)\n",
    "ORDER BY column_name\n",
    "LIMIT 30\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d77403-8c69-4cb9-ba0c-39e0372f43c0",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that both schema views contain the same columns and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7d7eb-5482-47f6-9222-29816bc98a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = con.execute(\"DESCRIBE team_week_panel\").df()\n",
    "df_b = con.execute(\"\"\"\n",
    "SELECT column_name, column_type\n",
    "FROM (DESCRIBE team_week_panel)\n",
    "ORDER BY column_name\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"rows describe\", len(df_a))\n",
    "print(\"rows sorted\", len(df_b))\n",
    "\n",
    "dupe_names = df_a[\"column_name\"].value_counts()\n",
    "dupe_names = dupe_names[dupe_names > 1]\n",
    "print(\"duplicate column names\", dupe_names.to_dict())\n",
    "\n",
    "mismatch = (\n",
    "    df_a[[\"column_name\", \"column_type\"]]\n",
    "    .drop_duplicates()\n",
    "    .merge(\n",
    "        df_b[[\"column_name\", \"column_type\"]].drop_duplicates(),\n",
    "        on=[\"column_name\", \"column_type\"],\n",
    "        how=\"outer\",\n",
    "        indicator=True,\n",
    "    )\n",
    ")\n",
    "mismatch = mismatch[mismatch[\"_merge\"] != \"both\"]\n",
    "mismatch.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8757c-7971-4166-b041-5d9f78ea2418",
   "metadata": {},
   "source": [
    "We verify the continuity of the dataset by aggregating the unique time periods present to ensure that the panel spans the full historical range required for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c2f00-985e-4e34-81d5-a50bb321015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN name = '{PANEL_TABLE}' THEN 1 ELSE 0 END) AS has_team_week_panel\n",
    "FROM (SHOW TABLES)\n",
    "\"\"\").df()\n",
    "\n",
    "_require_cols(\n",
    "    PANEL_TABLE,\n",
    "    [\n",
    "        SEASON_COL,\n",
    "        WEEK_COL,\n",
    "        TEAM_COL,\n",
    "        \"game_id\",\n",
    "        \"points_for\",\n",
    "        \"points_against\",\n",
    "        \"ST_Load_All_w\",\n",
    "        \"ST_Load_ScoreLinked_w\",\n",
    "        \"ST_Load_NonScore_w\",\n",
    "        \"ST_Punt_w\",\n",
    "        \"ST_PuntReturn_w\",\n",
    "        \"ST_Kickoff_w\",\n",
    "        \"ST_KickReturn_w\",\n",
    "        \"ST_FG_w\",\n",
    "        \"ST_XP_w\",\n",
    "        \"ST_Rare_w\",\n",
    "        \"Inj_Off_Next_w\",\n",
    "        \"Inj_Def_Next_w\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  COUNT(DISTINCT {SEASON_COL}) AS seasons,\n",
    "  MIN({SEASON_COL}) AS min_season,\n",
    "  MAX({SEASON_COL}) AS max_season,\n",
    "  MIN({WEEK_COL}) AS min_week,\n",
    "  MAX({WEEK_COL}) AS max_week\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdaacaf-de71-48e5-9220-6e0cd13e71e6",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'team_week_panel' exists in the connected database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d4172-96ca-496c-bc68-2a18e0884a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN name = 'team_week_panel' THEN 1 ELSE 0 END) AS has_team_week_panel\n",
    "FROM (SHOW TABLES)\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f934e02-3294-48f7-b2f9-4f43c20e1aa7",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'team_week_panel' has no duplicate season-week-team rows and that the key count equals the row count to ensure that the final modeling table is a perfectly unique panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63646b74-e77a-439a-9218-b7e176d0ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  COUNT(DISTINCT season || '-' || week || '-' || team) AS distinct_keys\n",
    "FROM team_week_panel\n",
    "\"\"\").df()\n",
    "\n",
    "dups = con.execute(\"\"\"\n",
    "SELECT\n",
    "  season,\n",
    "  week,\n",
    "  team,\n",
    "  COUNT(*) AS n\n",
    "FROM team_week_panel\n",
    "GROUP BY 1,2,3\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY n DESC, season, week, team\n",
    "LIMIT 50\n",
    "\"\"\").df()\n",
    "\n",
    "dups\n",
    "\n",
    "if len(dups) > 0:\n",
    "    raise RuntimeError(\"Duplicate season week team rows exist in team_week_panel, investigate joins before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3f95b-02a4-414d-9473-f52f8dbef559",
   "metadata": {},
   "source": [
    "We verify that the \"next game\" indicator accurately distinguishes between teams that play in the following calendar week and those heading into a bye to ensure that the 'w+a' outcome logic aligns with the physical game schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac15963-ef33-4c45-87bf-cafb0686839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP VIEW IF EXISTS panel_next_week_flags\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE TEMP VIEW panel_next_week_flags AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    {SEASON_COL} AS season,\n",
    "    {WEEK_COL} AS week,\n",
    "    CAST({TEAM_COL} AS VARCHAR) AS team_key\n",
    "  FROM {PANEL_TABLE}\n",
    "),\n",
    "nxt AS (\n",
    "  SELECT\n",
    "    {SEASON_COL} AS season,\n",
    "    {WEEK_COL} AS week,\n",
    "    CAST({TEAM_COL} AS VARCHAR) AS team_key\n",
    "  FROM {PANEL_TABLE}\n",
    ")\n",
    "SELECT\n",
    "  b.season,\n",
    "  b.week,\n",
    "  b.team_key,\n",
    "  CASE WHEN n.week IS NULL THEN 0 ELSE 1 END AS has_next_week\n",
    "FROM base b\n",
    "LEFT JOIN nxt n\n",
    "  ON n.season = b.season\n",
    " AND n.team_key = b.team_key\n",
    " AND n.week = b.week + 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  has_next_week,\n",
    "  COUNT(*) AS n_rows\n",
    "FROM panel_next_week_flags\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e360073-63b6-4f0c-a20b-4e8eb05e7a53",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that next week injury outcomes are only defined when week 'w+a' exists for that team season and that they are null when the next week row is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c76cb4-75e0-4dcf-acdb-23e807fce451",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_next_week_cols = [\"Inj_Off_Next_w\", \"Inj_Def_Next_w\"]\n",
    "cols_now = set(_existing_cols(PANEL_TABLE))\n",
    "inj_next_week_cols = [c for c in inj_next_week_cols if c in cols_now]\n",
    "\n",
    "if not inj_next_week_cols:\n",
    "    raise RuntimeError(\"No next week injury outcome columns found, expected Inj_Off_Next_w and Inj_Def_Next_w\")\n",
    "\n",
    "print(\"Next week injury columns checked\", inj_next_week_cols)\n",
    "\n",
    "select_any_defined = \" OR \".join([f\"p.{c} IS NOT NULL\" for c in inj_next_week_cols])\n",
    "\n",
    "bad_defined = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS bad_rows\n",
    "FROM {PANEL_TABLE} p\n",
    "JOIN panel_next_week_flags f\n",
    "  ON f.season = p.{SEASON_COL}\n",
    " AND f.week = p.{WEEK_COL}\n",
    " AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "WHERE f.has_next_week = 0\n",
    "  AND ({select_any_defined})\n",
    "\"\"\").df()\n",
    "\n",
    "bad_rows = int(bad_defined[\"bad_rows\"].iloc[0])\n",
    "print(bad_defined)\n",
    "\n",
    "if bad_rows != 0:\n",
    "    sample = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "      p.{SEASON_COL} AS season,\n",
    "      p.{WEEK_COL} AS week,\n",
    "      p.{TEAM_COL} AS team,\n",
    "      f.has_next_week,\n",
    "      {\", \".join([f\"p.{c}\" for c in inj_next_week_cols])}\n",
    "    FROM {PANEL_TABLE} p\n",
    "    JOIN panel_next_week_flags f\n",
    "      ON f.season = p.{SEASON_COL}\n",
    "     AND f.week = p.{WEEK_COL}\n",
    "     AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "    WHERE f.has_next_week = 0\n",
    "      AND ({select_any_defined})\n",
    "    ORDER BY p.{SEASON_COL} DESC, p.{WEEK_COL} DESC, p.{TEAM_COL}\n",
    "    LIMIT 50\n",
    "    \"\"\").df()\n",
    "    print(sample)\n",
    "    raise RuntimeError(\"Next week injury outcomes are populated when week plus 1 does not exist, fix notebook 09 logic or apply the step 11 repair cell\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
