{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda5558b-48ad-4083-9305-ad26029016ad",
   "metadata": {},
   "source": [
    "We initialize Python imports and opens a DuckDB connection that every later cell reuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9c8ea-65f5-4dac-9442-66b700acf7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "\n",
    "print(\"cwd\", Path().resolve())\n",
    "\n",
    "candidates = []\n",
    "search_roots = [\n",
    "    Path(\".\"),\n",
    "    Path(\"..\"),\n",
    "    Path(\"./data\"),\n",
    "    Path(\"../data\"),\n",
    "    Path(\"../../data\"),\n",
    "]\n",
    "for root in search_roots:\n",
    "    if root.exists():\n",
    "        candidates.extend(list(root.glob(\"*.duckdb\")))\n",
    "        candidates.extend(list(root.glob(\"**/*.duckdb\")))\n",
    "\n",
    "seen = set()\n",
    "duckdb_files = []\n",
    "for f in candidates:\n",
    "    fp = str(f.resolve())\n",
    "    if fp not in seen:\n",
    "        seen.add(fp)\n",
    "        duckdb_files.append(f.resolve())\n",
    "\n",
    "print(\"duckdb files found\")\n",
    "for i, f in enumerate(duckdb_files[:25]):\n",
    "    print(i, f)\n",
    "\n",
    "db_file = None\n",
    "for f in duckdb_files:\n",
    "    if f.name == \"nflpa.duckdb\":\n",
    "        db_file = f\n",
    "        break\n",
    "\n",
    "if db_file is None and duckdb_files:\n",
    "    db_file = duckdb_files[0]\n",
    "\n",
    "if db_file is None:\n",
    "    raise RuntimeError(\"No duckdb file found near this notebook, rerun notebook 02 or check where you stored the database file\")\n",
    "\n",
    "con = duckdb.connect(str(db_file))\n",
    "print(\"connected db\", db_file)\n",
    "\n",
    "tables = con.execute(\"SHOW TABLES\").df()\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de6860-e756-42a7-91ef-4d08baad2315",
   "metadata": {},
   "source": [
    "We define small helpers for column discovery and strict required column checks so later sanity checks fail early if an upstream notebook was skipped or a column name drifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b309d3-3573-4423-b2de-ef1bf1aa62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SEASON_COL = \"season\"\n",
    "WEEK_COL = \"week\"\n",
    "TEAM_COL = \"team\"\n",
    "PANEL_TABLE = \"team_week_panel\"\n",
    "\n",
    "def _existing_cols(table_name: str) -> list[str]:\n",
    "    return con.execute(f\"DESCRIBE {table_name}\").df()[\"column_name\"].tolist()\n",
    "\n",
    "def _require_cols(table_name: str, required: list[str]) -> None:\n",
    "    cols = set(_existing_cols(table_name))\n",
    "    missing = [c for c in required if c not in cols]\n",
    "    print(\"Missing required columns\", missing)\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing columns in {table_name}, rerun earlier notebooks, missing, {missing}\")\n",
    "\n",
    "def _cols_matching(prefix: str = \"\", contains: str = \"\", suffix: str = \"\") -> list[str]:\n",
    "    cols = _existing_cols(PANEL_TABLE)\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        if prefix and not c.startswith(prefix):\n",
    "            continue\n",
    "        if contains and contains not in c:\n",
    "            continue\n",
    "        if suffix and not c.endswith(suffix):\n",
    "            continue\n",
    "        out.append(c)\n",
    "    return out\n",
    "\n",
    "print(\"team week panel columns\", len(_existing_cols(PANEL_TABLE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6106b1d-c40e-4688-b33b-7292d39b2598",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the wide-format structure correctly reflects the expected mix of injury, workload, and control features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2164ad5-8b80-4a93-854e-4fc1029e408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DESCRIBE team_week_panel\").df().head(30)\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  column_name,\n",
    "  column_type\n",
    "FROM (DESCRIBE team_week_panel)\n",
    "ORDER BY column_name\n",
    "LIMIT 30\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d77403-8c69-4cb9-ba0c-39e0372f43c0",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that both schema views contain the same columns and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7d7eb-5482-47f6-9222-29816bc98a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = con.execute(\"DESCRIBE team_week_panel\").df()\n",
    "df_b = con.execute(\"\"\"\n",
    "SELECT column_name, column_type\n",
    "FROM (DESCRIBE team_week_panel)\n",
    "ORDER BY column_name\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"rows describe\", len(df_a))\n",
    "print(\"rows sorted\", len(df_b))\n",
    "\n",
    "dupe_names = df_a[\"column_name\"].value_counts()\n",
    "dupe_names = dupe_names[dupe_names > 1]\n",
    "print(\"duplicate column names\", dupe_names.to_dict())\n",
    "\n",
    "mismatch = (\n",
    "    df_a[[\"column_name\", \"column_type\"]]\n",
    "    .drop_duplicates()\n",
    "    .merge(\n",
    "        df_b[[\"column_name\", \"column_type\"]].drop_duplicates(),\n",
    "        on=[\"column_name\", \"column_type\"],\n",
    "        how=\"outer\",\n",
    "        indicator=True,\n",
    "    )\n",
    ")\n",
    "mismatch = mismatch[mismatch[\"_merge\"] != \"both\"]\n",
    "mismatch.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8757c-7971-4166-b041-5d9f78ea2418",
   "metadata": {},
   "source": [
    "We verify the continuity of the dataset by aggregating the unique time periods present to ensure that the panel spans the full historical range required for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c2f00-985e-4e34-81d5-a50bb321015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN name = '{PANEL_TABLE}' THEN 1 ELSE 0 END) AS has_team_week_panel\n",
    "FROM (SHOW TABLES)\n",
    "\"\"\").df()\n",
    "\n",
    "_require_cols(\n",
    "    PANEL_TABLE,\n",
    "    [\n",
    "        SEASON_COL,\n",
    "        WEEK_COL,\n",
    "        TEAM_COL,\n",
    "        \"game_id\",\n",
    "        \"points_for\",\n",
    "        \"points_against\",\n",
    "        \"ST_Load_All_w\",\n",
    "        \"ST_Load_ScoreLinked_w\",\n",
    "        \"ST_Load_NonScore_w\",\n",
    "        \"ST_Punt_w\",\n",
    "        \"ST_PuntReturn_w\",\n",
    "        \"ST_Kickoff_w\",\n",
    "        \"ST_KickReturn_w\",\n",
    "        \"ST_FG_w\",\n",
    "        \"ST_XP_w\",\n",
    "        \"ST_Rare_w\",\n",
    "        \"Inj_Off_Next_w\",\n",
    "        \"Inj_Def_Next_w\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  COUNT(DISTINCT {SEASON_COL}) AS seasons,\n",
    "  MIN({SEASON_COL}) AS min_season,\n",
    "  MAX({SEASON_COL}) AS max_season,\n",
    "  MIN({WEEK_COL}) AS min_week,\n",
    "  MAX({WEEK_COL}) AS max_week\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdaacaf-de71-48e5-9220-6e0cd13e71e6",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'team_week_panel' exists in the connected database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d4172-96ca-496c-bc68-2a18e0884a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN name = 'team_week_panel' THEN 1 ELSE 0 END) AS has_team_week_panel\n",
    "FROM (SHOW TABLES)\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f934e02-3294-48f7-b2f9-4f43c20e1aa7",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'team_week_panel' has no duplicate season-week-team rows and that the key count equals the row count to ensure that the final modeling table is a perfectly unique panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63646b74-e77a-439a-9218-b7e176d0ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  COUNT(DISTINCT season || '-' || week || '-' || team) AS distinct_keys\n",
    "FROM team_week_panel\n",
    "\"\"\").df()\n",
    "\n",
    "dups = con.execute(\"\"\"\n",
    "SELECT\n",
    "  season,\n",
    "  week,\n",
    "  team,\n",
    "  COUNT(*) AS n\n",
    "FROM team_week_panel\n",
    "GROUP BY 1,2,3\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY n DESC, season, week, team\n",
    "LIMIT 50\n",
    "\"\"\").df()\n",
    "\n",
    "dups\n",
    "\n",
    "if len(dups) > 0:\n",
    "    raise RuntimeError(\"Duplicate season week team rows exist in team_week_panel, investigate joins before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3f95b-02a4-414d-9473-f52f8dbef559",
   "metadata": {},
   "source": [
    "We verify that the \"next game\" indicator accurately distinguishes between teams that play in the following calendar week and those heading into a bye to ensure that the 'w+a' outcome logic aligns with the physical game schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac15963-ef33-4c45-87bf-cafb0686839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP VIEW IF EXISTS panel_next_week_flags\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE TEMP VIEW panel_next_week_flags AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    {SEASON_COL} AS season,\n",
    "    {WEEK_COL} AS week,\n",
    "    CAST({TEAM_COL} AS VARCHAR) AS team_key\n",
    "  FROM {PANEL_TABLE}\n",
    "),\n",
    "nxt AS (\n",
    "  SELECT\n",
    "    {SEASON_COL} AS season,\n",
    "    {WEEK_COL} AS week,\n",
    "    CAST({TEAM_COL} AS VARCHAR) AS team_key\n",
    "  FROM {PANEL_TABLE}\n",
    ")\n",
    "SELECT\n",
    "  b.season,\n",
    "  b.week,\n",
    "  b.team_key,\n",
    "  CASE WHEN n.week IS NULL THEN 0 ELSE 1 END AS has_next_week\n",
    "FROM base b\n",
    "LEFT JOIN nxt n\n",
    "  ON n.season = b.season\n",
    " AND n.team_key = b.team_key\n",
    " AND n.week = b.week + 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  has_next_week,\n",
    "  COUNT(*) AS n_rows\n",
    "FROM panel_next_week_flags\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e360073-63b6-4f0c-a20b-4e8eb05e7a53",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that next week injury outcomes are only defined when week 'w+a' exists for that team season and that they are null when the next week row is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c76cb4-75e0-4dcf-acdb-23e807fce451",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_next_week_cols = [\"Inj_Off_Next_w\", \"Inj_Def_Next_w\"]\n",
    "cols_now = set(_existing_cols(PANEL_TABLE))\n",
    "inj_next_week_cols = [c for c in inj_next_week_cols if c in cols_now]\n",
    "\n",
    "if not inj_next_week_cols:\n",
    "    raise RuntimeError(\"No next week injury outcome columns found, expected Inj_Off_Next_w and Inj_Def_Next_w\")\n",
    "\n",
    "print(\"Next week injury columns checked\", inj_next_week_cols)\n",
    "\n",
    "select_any_defined = \" OR \".join([f\"p.{c} IS NOT NULL\" for c in inj_next_week_cols])\n",
    "\n",
    "bad_defined = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS bad_rows\n",
    "FROM {PANEL_TABLE} p\n",
    "JOIN panel_next_week_flags f\n",
    "  ON f.season = p.{SEASON_COL}\n",
    " AND f.week = p.{WEEK_COL}\n",
    " AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "WHERE f.has_next_week = 0\n",
    "  AND ({select_any_defined})\n",
    "\"\"\").df()\n",
    "\n",
    "bad_rows = int(bad_defined[\"bad_rows\"].iloc[0])\n",
    "print(bad_defined)\n",
    "\n",
    "if bad_rows != 0:\n",
    "    sample = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "      p.{SEASON_COL} AS season,\n",
    "      p.{WEEK_COL} AS week,\n",
    "      p.{TEAM_COL} AS team,\n",
    "      f.has_next_week,\n",
    "      {\", \".join([f\"p.{c}\" for c in inj_next_week_cols])}\n",
    "    FROM {PANEL_TABLE} p\n",
    "    JOIN panel_next_week_flags f\n",
    "      ON f.season = p.{SEASON_COL}\n",
    "     AND f.week = p.{WEEK_COL}\n",
    "     AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "    WHERE f.has_next_week = 0\n",
    "      AND ({select_any_defined})\n",
    "    ORDER BY p.{SEASON_COL} DESC, p.{WEEK_COL} DESC, p.{TEAM_COL}\n",
    "    LIMIT 50\n",
    "    \"\"\").df()\n",
    "    print(sample)\n",
    "    raise RuntimeError(\"Next week injury outcomes are populated when week plus 1 does not exist, fix notebook 09 logic or apply the step 11 repair cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54dc375-cece-4fd9-8b5b-fa0af2c45af4",
   "metadata": {},
   "source": [
    "We handle the undefined next week cases by creating a modeling view that drops all rows where week 'w+1' does not exist, which are the final game weeks and the pre bye game weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d7628-4753-4ceb-a8ff-c103fe377613",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP VIEW IF EXISTS team_week_panel_nextweek_model\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW team_week_panel_nextweek_model AS\n",
    "SELECT\n",
    "  p.*,\n",
    "  f.has_next_week\n",
    "FROM {PANEL_TABLE} p\n",
    "JOIN panel_next_week_flags f\n",
    "  ON f.season = p.{SEASON_COL}\n",
    " AND f.week = p.{WEEK_COL}\n",
    " AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "WHERE f.has_next_week = 1\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows_model,\n",
    "  COUNT(DISTINCT {SEASON_COL} || '-' || {WEEK_COL} || '-' || {TEAM_COL}) AS distinct_keys_model\n",
    "FROM team_week_panel_nextweek_model\n",
    "\"\"\").df()\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "SELECT\n",
    "  p.{SEASON_COL} AS season,\n",
    "  COUNT(*) AS rows_total,\n",
    "  SUM(CASE WHEN f.has_next_week = 1 THEN 1 ELSE 0 END) AS rows_kept,\n",
    "  SUM(CASE WHEN f.has_next_week = 0 THEN 1 ELSE 0 END) AS rows_dropped\n",
    "FROM {PANEL_TABLE} p\n",
    "JOIN panel_next_week_flags f\n",
    "  ON f.season = p.{SEASON_COL}\n",
    " AND f.week = p.{WEEK_COL}\n",
    " AND f.team_key = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbce616-f713-44aa-9d6d-994becaf427d",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that the special teams totals exactly match the intended bucket identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6c819-4631-4b23-a0c2-a9b1309cced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_identity = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  SUM(CASE WHEN ST_Load_All_w != (ST_Punt_w + ST_PuntReturn_w + ST_Kickoff_w + ST_KickReturn_w + ST_FG_w + ST_XP_w + ST_Rare_w) THEN 1 ELSE 0 END) AS bad_all_identity,\n",
    "  SUM(CASE WHEN ST_Load_ScoreLinked_w != (ST_Kickoff_w + ST_XP_w + ST_FG_w) THEN 1 ELSE 0 END) AS bad_scorelinked_identity,\n",
    "  SUM(CASE WHEN ST_Load_NonScore_w != (ST_Punt_w + ST_PuntReturn_w + ST_KickReturn_w + ST_Rare_w) THEN 1 ELSE 0 END) AS bad_nonscore_identity,\n",
    "  SUM(CASE WHEN ST_Load_All_w != (ST_Load_ScoreLinked_w + ST_Load_NonScore_w) THEN 1 ELSE 0 END) AS bad_partition_identity\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()\n",
    "\n",
    "print(st_identity)\n",
    "\n",
    "bad_all = int(st_identity[\"bad_all_identity\"].iloc[0])\n",
    "bad_sl = int(st_identity[\"bad_scorelinked_identity\"].iloc[0])\n",
    "bad_ns = int(st_identity[\"bad_nonscore_identity\"].iloc[0])\n",
    "bad_part = int(st_identity[\"bad_partition_identity\"].iloc[0])\n",
    "\n",
    "if bad_all or bad_sl or bad_ns or bad_part:\n",
    "    sample = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "      {SEASON_COL} AS season,\n",
    "      {WEEK_COL} AS week,\n",
    "      {TEAM_COL} AS team,\n",
    "      ST_Punt_w,\n",
    "      ST_PuntReturn_w,\n",
    "      ST_Kickoff_w,\n",
    "      ST_KickReturn_w,\n",
    "      ST_FG_w,\n",
    "      ST_XP_w,\n",
    "      ST_Rare_w,\n",
    "      ST_Load_All_w,\n",
    "      ST_Load_ScoreLinked_w,\n",
    "      ST_Load_NonScore_w\n",
    "    FROM {PANEL_TABLE}\n",
    "    WHERE\n",
    "      ST_Load_All_w != (ST_Punt_w + ST_PuntReturn_w + ST_Kickoff_w + ST_KickReturn_w + ST_FG_w + ST_XP_w + ST_Rare_w)\n",
    "      OR ST_Load_ScoreLinked_w != (ST_Kickoff_w + ST_XP_w + ST_FG_w)\n",
    "      OR ST_Load_NonScore_w != (ST_Punt_w + ST_PuntReturn_w + ST_KickReturn_w + ST_Rare_w)\n",
    "      OR ST_Load_All_w != (ST_Load_ScoreLinked_w + ST_Load_NonScore_w)\n",
    "    ORDER BY season DESC, week DESC, team\n",
    "    LIMIT 50\n",
    "    \"\"\").df()\n",
    "    print(sample)\n",
    "    raise RuntimeError(\"Special teams buckets do not satisfy the intended identities, investigate notebook 04 bucketing logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42b83d-4c71-4133-b504-b41081358a3d",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'ScoreLinked' moves with the points environment more than 'NonScore' by comparing correlations with total game points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693d8eb-210f-4e3d-bacd-4b96dfc8d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  {SEASON_COL} AS season,\n",
    "  {WEEK_COL} AS week,\n",
    "  {TEAM_COL} AS team,\n",
    "  points_for,\n",
    "  points_against,\n",
    "  ST_Load_ScoreLinked_w,\n",
    "  ST_Load_NonScore_w\n",
    "FROM {PANEL_TABLE}\n",
    "\"\"\").df()\n",
    "\n",
    "df_points[\"total_points_game\"] = df_points[\"points_for\"] + df_points[\"points_against\"]\n",
    "\n",
    "df_corr = df_points.dropna(subset=[\"total_points_game\", \"ST_Load_ScoreLinked_w\", \"ST_Load_NonScore_w\"]).copy()\n",
    "\n",
    "corr_scorelinked = df_corr[\"ST_Load_ScoreLinked_w\"].corr(df_corr[\"total_points_game\"])\n",
    "corr_nonscore = df_corr[\"ST_Load_NonScore_w\"].corr(df_corr[\"total_points_game\"])\n",
    "\n",
    "print(\"corr ScoreLinked with total points game\", corr_scorelinked)\n",
    "print(\"corr NonScore with total points game\", corr_nonscore)\n",
    "\n",
    "if abs(corr_scorelinked) < abs(corr_nonscore):\n",
    "    raise RuntimeError(\"ScoreLinked is not more correlated with points environment than NonScore, investigate ScoreLinked definition and joins\")\n",
    "\n",
    "by_season = (\n",
    "    df_corr.groupby(\"season\", as_index=False)\n",
    "    .apply(\n",
    "        lambda g: pd.Series({\n",
    "            \"corr_scorelinked_total_points\": g[\"ST_Load_ScoreLinked_w\"].corr(g[\"total_points_game\"]),\n",
    "            \"corr_nonscore_total_points\": g[\"ST_Load_NonScore_w\"].corr(g[\"total_points_game\"]),\n",
    "            \"n_rows\": len(g),\n",
    "        }),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "by_season = by_season.reset_index(drop=True)\n",
    "by_season.sort_values(\"season\").tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb537a8-dc97-4f5c-95ef-d23a9dd17609",
   "metadata": {},
   "source": [
    "Quick sanity check to confirm that 'NonScore' correlates more with punts and returns than with touchdowns by constructing a touchdowns per team week table from play by play and comparing correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb318ac-d43e-4d51-a69e-aa5364f29357",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE IF EXISTS team_week_tds_off\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE team_week_tds_off AS\n",
    "SELECT\n",
    "  season,\n",
    "  week,\n",
    "  CAST(posteam AS VARCHAR) AS team,\n",
    "  SUM(CASE WHEN touchdown = 1 THEN 1 ELSE 0 END) AS tds_off_w\n",
    "FROM pbp\n",
    "WHERE posteam IS NOT NULL\n",
    "GROUP BY 1,2,3\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  COUNT(DISTINCT season || '-' || week || '-' || team) AS distinct_keys,\n",
    "  MIN(tds_off_w) AS min_tds,\n",
    "  MAX(tds_off_w) AS max_tds,\n",
    "  AVG(tds_off_w) AS avg_tds\n",
    "FROM team_week_tds_off\n",
    "\"\"\").df()\n",
    "\n",
    "df_ns = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  p.{SEASON_COL} AS season,\n",
    "  p.{WEEK_COL} AS week,\n",
    "  p.{TEAM_COL} AS team,\n",
    "  p.ST_Load_NonScore_w,\n",
    "  p.ST_Punt_w,\n",
    "  p.ST_PuntReturn_w,\n",
    "  p.ST_KickReturn_w,\n",
    "  COALESCE(t.tds_off_w, 0) AS tds_off_w\n",
    "FROM {PANEL_TABLE} p\n",
    "LEFT JOIN team_week_tds_off t\n",
    "  ON t.season = p.{SEASON_COL}\n",
    " AND t.week = p.{WEEK_COL}\n",
    " AND t.team = CAST(p.{TEAM_COL} AS VARCHAR)\n",
    "\"\"\").df()\n",
    "\n",
    "df_ns[\"punt_return_proxy\"] = df_ns[\"ST_Punt_w\"] + df_ns[\"ST_PuntReturn_w\"] + df_ns[\"ST_KickReturn_w\"]\n",
    "\n",
    "df_ns_corr = df_ns.dropna(subset=[\"ST_Load_NonScore_w\", \"punt_return_proxy\", \"tds_off_w\"]).copy()\n",
    "\n",
    "corr_ns_punts = df_ns_corr[\"ST_Load_NonScore_w\"].corr(df_ns_corr[\"punt_return_proxy\"])\n",
    "corr_ns_tds = df_ns_corr[\"ST_Load_NonScore_w\"].corr(df_ns_corr[\"tds_off_w\"])\n",
    "\n",
    "print(\"corr NonScore with punts and returns proxy\", corr_ns_punts)\n",
    "print(\"corr NonScore with offensive touchdowns\", corr_ns_tds)\n",
    "\n",
    "if abs(corr_ns_punts) < abs(corr_ns_tds):\n",
    "    raise RuntimeError(\"NonScore is not more correlated with punts and returns than touchdowns, investigate NonScore definition and component mapping\")\n",
    "\n",
    "by_season_ns = (\n",
    "    df_ns_corr.groupby(\"season\", as_index=False)\n",
    "    .apply(lambda g: pd.Series({\n",
    "        \"corr_nonscore_punts_returns\": g[\"ST_Load_NonScore_w\"].corr(g[\"punt_return_proxy\"]),\n",
    "        \"corr_nonscore_tds_off\": g[\"ST_Load_NonScore_w\"].corr(g[\"tds_off_w\"]),\n",
    "        \"n_rows\": len(g),\n",
    "    }))\n",
    ")\n",
    "\n",
    "by_season_ns = by_season_ns.reset_index(drop=True)\n",
    "by_season_ns.sort_values(\"season\").tail(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
